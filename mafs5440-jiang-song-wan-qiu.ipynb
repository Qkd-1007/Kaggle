{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afb2324",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-15T15:10:16.466518Z",
     "iopub.status.busy": "2025-10-15T15:10:16.466136Z",
     "iopub.status.idle": "2025-10-15T15:11:11.794240Z",
     "shell.execute_reply": "2025-10-15T15:11:11.792748Z"
    },
    "papermill": {
     "duration": 55.34069,
     "end_time": "2025-10-15T15:11:11.796564",
     "exception": false,
     "start_time": "2025-10-15T15:10:16.455874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scorecardpy\r\n",
      "  Downloading scorecardpy-0.1.9.7.tar.gz (58 kB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m58.1/58.1 kB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scorecardpy) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scorecardpy) (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from scorecardpy) (3.7.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from scorecardpy) (1.2.2)\r\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from scorecardpy) (0.14.5)\r\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.11/dist-packages (from scorecardpy) (1.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->scorecardpy) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->scorecardpy) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->scorecardpy) (2025.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->scorecardpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->scorecardpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->scorecardpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->scorecardpy) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->scorecardpy) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->scorecardpy) (2.4.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->scorecardpy) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->scorecardpy) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->scorecardpy) (3.6.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scorecardpy) (3.0.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->scorecardpy) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->scorecardpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->scorecardpy) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->scorecardpy) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->scorecardpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->scorecardpy) (2024.2.0)\r\n",
      "Building wheels for collected packages: scorecardpy\r\n",
      "  Building wheel for scorecardpy (setup.py) ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Created wheel for scorecardpy: filename=scorecardpy-0.1.9.7-py3-none-any.whl size=60629 sha256=18623438a8983bbb9df6fa2ed603c1a776acae2fde1a7bd6113dc1a13b28047a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/88/65/58d6aa058698c47d7a24352952ea07a1409cc2eff3a8087c0c\r\n",
      "Successfully built scorecardpy\r\n",
      "Installing collected packages: scorecardpy\r\n",
      "Successfully installed scorecardpy-0.1.9.7\r\n",
      "Collecting autogluon.tabular\r\n",
      "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular) (1.26.4)\r\n",
      "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular) (1.15.3)\r\n",
      "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular) (2.2.3)\r\n",
      "Collecting scikit-learn<1.8.0,>=1.4.0 (from autogluon.tabular)\r\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular) (3.5)\r\n",
      "Collecting autogluon.core==1.4.0 (from autogluon.tabular)\r\n",
      "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting autogluon.features==1.4.0 (from autogluon.tabular)\r\n",
      "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.tabular) (4.67.1)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.tabular) (2.32.5)\r\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.tabular) (3.7.2)\r\n",
      "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.4.0->autogluon.tabular) (1.40.39)\r\n",
      "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.tabular)\r\n",
      "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: pyarrow<21.0.0,>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular) (19.0.1)\r\n",
      "Collecting psutil<7.1.0,>=5.7.3 (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular)\r\n",
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.tabular) (1.5.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.4.0,>=1.25.0->autogluon.tabular) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.4.0,>=1.25.0->autogluon.tabular) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.4.0,>=1.25.0->autogluon.tabular) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.4.0,>=1.25.0->autogluon.tabular) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.4.0,>=1.25.0->autogluon.tabular) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.4.0,>=1.25.0->autogluon.tabular) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.tabular) (2025.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.tabular) (3.6.0)\r\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.39 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular) (1.40.39)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.tabular) (0.14.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.tabular) (3.0.9)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=2.0.0->autogluon.tabular) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.4.0,>=1.25.0->autogluon.tabular) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.4.0,>=1.25.0->autogluon.tabular) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.4.0,>=1.25.0->autogluon.tabular) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.4.0,>=1.25.0->autogluon.tabular) (2024.2.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.4.0->autogluon.tabular) (2025.8.3)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.4.0,>=1.25.0->autogluon.tabular) (2024.2.0)\r\n",
      "Downloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m487.3/487.3 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m225.1/225.1 kB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m64.2/64.2 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m71.0/71.0 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m9.7/9.7 MB\u001B[0m \u001B[31m80.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m278.0/278.0 kB\u001B[0m \u001B[31m13.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: psutil, scikit-learn, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 7.1.0\r\n",
      "    Uninstalling psutil-7.1.0:\r\n",
      "      Successfully uninstalled psutil-7.1.0\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.tabular-1.4.0 psutil-7.0.0 scikit-learn-1.7.2\r\n",
      "Collecting scikit-learn==1.2\r\n",
      "  Downloading scikit_learn-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m9.5/9.5 MB\u001B[0m \u001B[31m45.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.7.2\r\n",
      "    Uninstalling scikit-learn-1.7.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.7.2\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "autogluon-core 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.2.0 which is incompatible.\r\n",
      "autogluon-tabular 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.2.0 which is incompatible.\r\n",
      "autogluon-features 1.4.0 requires scikit-learn<1.8.0,>=1.4.0, but you have scikit-learn 1.2.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed scikit-learn-1.2.0\r\n",
      "Collecting ray<2.45.0,>=2.10.0\r\n",
      "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (8.3.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (3.19.1)\r\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (4.25.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (1.1.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (6.0.3)\r\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (1.4.0)\r\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (1.7.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray<2.45.0,>=2.10.0) (2.32.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal->ray<2.45.0,>=2.10.0) (4.15.0)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.45.0,>=2.10.0) (25.3.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.45.0,>=2.10.0) (2025.4.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.45.0,>=2.10.0) (0.36.2)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.45.0,>=2.10.0) (0.26.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray<2.45.0,>=2.10.0) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray<2.45.0,>=2.10.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray<2.45.0,>=2.10.0) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray<2.45.0,>=2.10.0) (2025.8.3)\r\n",
      "Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m68.1/68.1 MB\u001B[0m \u001B[31m23.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: ray\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.49.2\r\n",
      "    Uninstalling ray-2.49.2:\r\n",
      "      Successfully uninstalled ray-2.49.2\r\n",
      "Successfully installed ray-2.44.1\r\n",
      "Collecting optuna-integration[lightgbm]\r\n",
      "  Downloading optuna_integration-4.5.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.5.0)\r\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.6.0)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (1.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (1.15.3)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (1.16.5)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (25.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (2.0.41)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.0.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (3.6.0)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (1.3.10)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (4.15.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2.4.1)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[lightgbm]) (3.2.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.0->lightgbm->optuna-integration[lightgbm]) (2024.2.0)\r\n",
      "Downloading optuna_integration-4.5.0-py3-none-any.whl (99 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: optuna-integration\r\n",
      "Successfully installed optuna-integration-4.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scorecardpy\n",
    "!pip install autogluon.tabular\n",
    "!pip install scikit-learn==1.2\n",
    "!pip install \"ray>=2.10.0,<2.45.0\"\n",
    "!pip install optuna-integration[lightgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b6b806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:11.823541Z",
     "iopub.status.busy": "2025-10-15T15:11:11.823173Z",
     "iopub.status.idle": "2025-10-15T15:11:24.411025Z",
     "shell.execute_reply": "2025-10-15T15:11:24.410029Z"
    },
    "papermill": {
     "duration": 12.603768,
     "end_time": "2025-10-15T15:11:24.413211",
     "exception": false,
     "start_time": "2025-10-15T15:11:11.809443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py  # è‹¥ä¸éœ€è¦äº¤äº’å›¾ï¼Œå¯æ³¨é‡Šæ‰\n",
    "import scorecardpy as sc     # é£æ§åˆ†æå¸¸ç”¨åˆ†ç®±ã€WOEã€IV\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,KFold,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "import lightgbm as lgb\n",
    "# ================== Pandasæ˜¾ç¤ºè®¾ç½® ==================\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fd6275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.439529Z",
     "iopub.status.busy": "2025-10-15T15:11:24.438886Z",
     "iopub.status.idle": "2025-10-15T15:11:24.452896Z",
     "shell.execute_reply": "2025-10-15T15:11:24.451517Z"
    },
    "papermill": {
     "duration": 0.029102,
     "end_time": "2025-10-15T15:11:24.454756",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.425654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Timer function\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "# One-hot encoder with missing value handling\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].fillna('MISSING')\n",
    "\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "\n",
    "# Function to clean numerical columns\n",
    "def clean_numerical_data(df, numerical_columns):\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    for col in numerical_columns:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].replace([np.inf, -np.inf], np.nan)\n",
    "            if df_clean[col].isnull().any():\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def _safe_div(numer, denom):\n",
    "    \"\"\"Safe element-wise division returning a Pandas Series.\"\"\"\n",
    "    numer = pd.Series(numer)\n",
    "    denom = pd.Series(denom)\n",
    "    result = np.nan\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        result = numer / denom\n",
    "        result[(denom == 0) | denom.isna()] = np.nan\n",
    "    return result\n",
    "\n",
    "\n",
    "# Label encoding helper\n",
    "def label_encode_categoricals(df):\n",
    "    df_encoded = df.copy()\n",
    "    cat_cols = [col for col in df_encoded.columns if df_encoded[col].dtype == 'object']\n",
    "    label_info = {}  # ä¿å­˜æ¯åˆ—çš„å”¯ä¸€å€¼ä¸ªæ•°\n",
    "\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = df_encoded[col].astype(str).fillna('MISSING')\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        label_info[col] = len(le.classes_)  # è®°å½•è¯¥åˆ—ç±»åˆ«æ•°\n",
    "\n",
    "    return df_encoded, label_info\n",
    "\n",
    "def safe_mode(series):\n",
    "    \"\"\"Return mode if available, else NaN.\"\"\"\n",
    "    try:\n",
    "        mode_vals = series.mode()\n",
    "        return mode_vals.iloc[0] if not mode_vals.empty else np.nan\n",
    "    except Exception:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0bf8e",
   "metadata": {
    "papermill": {
     "duration": 0.012018,
     "end_time": "2025-10-15T15:11:24.480151",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.468133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ccf5ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.508177Z",
     "iopub.status.busy": "2025-10-15T15:11:24.507597Z",
     "iopub.status.idle": "2025-10-15T15:11:24.521178Z",
     "shell.execute_reply": "2025-10-15T15:11:24.520184Z"
    },
    "papermill": {
     "duration": 0.029162,
     "end_time": "2025-10-15T15:11:24.522673",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.493511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows=None, nan_as_category=False):\n",
    "    # Read train, test, and external feature data\n",
    "    df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv', nrows=num_rows)\n",
    "    testdata = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv', nrows=num_rows)\n",
    "    previousdata = pd.read_csv('/kaggle/input/feature/krakowlublinzhabinka_feats.csv')\n",
    "    print(f\"Train samples: {len(df)}, test samples: {len(testdata)}\")\n",
    "\n",
    "    # Concatenate train and test vertically, then add extra feature set horizontally\n",
    "    df = pd.concat([df, testdata], ignore_index=True)\n",
    "    df = pd.concat([df, previousdata], axis=1)\n",
    "\n",
    "    # Remove the 4 rows with invalid gender code \"XNA\"\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "    # Binary categorical features (two unique values) - factorized to 0/1\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "\n",
    "    # Replace One-Hot encoding with Label Encoding for all remaining categorical features\n",
    "    df, label_info = label_encode_categoricals(df)\n",
    "\n",
    "    # Replace 365243 with NaN in DAYS_EMPLOYED (invalid placeholder)\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    # === Feature engineering ===\n",
    "    # Employment days to age ratio â€” proportion of life spent working\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "\n",
    "    # Total income to credit ratio â€” lower ratio = higher debt burden\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "\n",
    "    # Income per family member â€” indicates economic pressure\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "\n",
    "    # Annuity to income ratio â€” repayment burden from income\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # Annuity to credit ratio â€” repayment speed\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "    # Credit amount minus total income â€” over-borrowing indicator\n",
    "    df['CREDIT_INCOME_DIFF'] = df['AMT_CREDIT'] - df['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # Approximate loan term â€” how long to repay the credit\n",
    "    df['CREDIT_TERM'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "\n",
    "    # Income per child (+1 avoids division by zero)\n",
    "    df['INCOME_PER_CHILD'] = df['AMT_INCOME_TOTAL'] / (df['CNT_CHILDREN'] + 1)\n",
    "\n",
    "    # Credit to goods price ratio â€” checks if loan exceeds product cost\n",
    "    df['CREDIT_GOODS_PERC'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "\n",
    "    # Employment length to age ratio â€” career stability\n",
    "    df['EMPLOY_TO_AGE_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "\n",
    "    # Children to family members ratio â€” dependency load\n",
    "    df['CHILDREN_RATIO'] = df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS']\n",
    "\n",
    "    # Car age relative to personâ€™s age (years)\n",
    "    df['CAR_AGE_RATIO'] = df['OWN_CAR_AGE'] / (-df['DAYS_BIRTH'] / 365)\n",
    "\n",
    "    # Binary flag â€” owns both car and house\n",
    "    df['REALTY_AND_CAR_FLAG'] = df['FLAG_OWN_CAR'] * df['FLAG_OWN_REALTY']\n",
    "\n",
    "    # Log-transformed income â€” reduces skewness\n",
    "    df['LOG_INCOME'] = np.log1p(df['AMT_INCOME_TOTAL'])\n",
    "\n",
    "    # Log-transformed credit amount â€” reduces outlier impact\n",
    "    df['LOG_CREDIT'] = np.log1p(df['AMT_CREDIT'])\n",
    "\n",
    "    # Total lifetime earnings approximation (income Ã— employment days)\n",
    "    df['INCOME_X_EMPLOY'] = df['AMT_INCOME_TOTAL'] * (-df['DAYS_EMPLOYED'])\n",
    "\n",
    "    # Credit amount multiplied by family size â€” household debt load\n",
    "    df['CREDIT_X_FAMILY'] = df['AMT_CREDIT'] * df['CNT_FAM_MEMBERS']\n",
    "\n",
    "    # Credit per child â€” child-related debt pressure\n",
    "    df['CREDIT_PER_CHILD'] = df['AMT_CREDIT'] / (df['CNT_CHILDREN'] + 1)\n",
    "\n",
    "    # Mark train vs test samples\n",
    "    df['is_train'] = 0\n",
    "    df.loc[:len(pd.read_csv('../input/home-credit-default-risk/application_train.csv')) - 1, 'is_train'] = 1\n",
    "\n",
    "    # Clean up temporary data\n",
    "    del testdata\n",
    "    del previousdata\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Label-encoded categorical features: {len(label_info)} columns processed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca607f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.549585Z",
     "iopub.status.busy": "2025-10-15T15:11:24.549206Z",
     "iopub.status.idle": "2025-10-15T15:11:24.572203Z",
     "shell.execute_reply": "2025-10-15T15:11:24.571143Z"
    },
    "papermill": {
     "duration": 0.038687,
     "end_time": "2025-10-15T15:11:24.573811",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.535124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def safe_mode(series):\n",
    "    \"\"\"Return mode if available, else NaN.\"\"\"\n",
    "    try:\n",
    "        mode_vals = series.mode()\n",
    "        return mode_vals.iloc[0] if not mode_vals.empty else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def bureau_and_balance(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Safe and stable version of bureau_and_balance():\n",
    "    - Keeps original string values of CREDIT_ACTIVE (for Active/Closed split)\n",
    "    - Performs label encoding on other categorical columns\n",
    "    - Aggregates numeric and categorical features\n",
    "    - Adds derived ratio and recency features\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import gc\n",
    "\n",
    "    # === Load raw data ===\n",
    "    bureaudata = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv', nrows=num_rows)\n",
    "    balancedata = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau_balance.csv', nrows=num_rows)\n",
    "    print(f\"ğŸ“„ Bureau raw shape: {bureaudata.shape}, Bureau_balance raw shape: {balancedata.shape}\")\n",
    "\n",
    "    # === Backup original CREDIT_ACTIVE column before encoding ===\n",
    "    bureau_cat_backup = {}\n",
    "    if 'CREDIT_ACTIVE' in bureaudata.columns:\n",
    "        bureau_cat_backup['CREDIT_ACTIVE'] = bureaudata['CREDIT_ACTIVE'].copy()\n",
    "\n",
    "    # === Encode and aggregate bureau_balance ===\n",
    "    balancedata, bb_label_info = label_encode_categoricals(balancedata)\n",
    "\n",
    "    bb_num_agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n",
    "    bb_cat_agg = {}\n",
    "    for col, n_unique in bb_label_info.items():\n",
    "        if n_unique == 2:\n",
    "            bb_cat_agg[col] = ['mean']\n",
    "        elif n_unique > 2:\n",
    "            bb_cat_agg[col] = [safe_mode]\n",
    "\n",
    "    balancedata_aggregated = balancedata.groupby('SK_ID_BUREAU').agg({**bb_num_agg, **bb_cat_agg})\n",
    "    balancedata_aggregated.columns = pd.Index([\n",
    "        f\"BB_{col[0]}_BINARY_MEAN\" if col[1] == 'mean' and bb_label_info.get(col[0], 0) == 2\n",
    "        else (f\"BB_{col[0]}_MODE\" if col[1] == 'safe_mode' or 'lambda' in col[1] else f\"BB_{col[0]}_{col[1].upper()}\")\n",
    "        for col in balancedata_aggregated.columns\n",
    "    ])\n",
    "    print(f\"âœ… Bureau balance aggregated shape: {balancedata_aggregated.shape}\")\n",
    "\n",
    "    # === Merge aggregated bureau_balance with bureau ===\n",
    "    bureaudata = bureaudata.join(balancedata_aggregated, how='left', on='SK_ID_BUREAU')\n",
    "    del balancedata, balancedata_aggregated\n",
    "    gc.collect()\n",
    "\n",
    "    # === Label encode bureau (excluding CREDIT_ACTIVE) ===\n",
    "    bureau_encoded, bureau_label_info = label_encode_categoricals(\n",
    "        bureaudata.drop(columns=['CREDIT_ACTIVE'], errors='ignore')\n",
    "    )\n",
    "\n",
    "    # Restore original CREDIT_ACTIVE strings for Active/Closed filtering\n",
    "    if 'CREDIT_ACTIVE' in bureaudata.columns:\n",
    "        bureau_encoded['CREDIT_ACTIVE'] = bureau_cat_backup['CREDIT_ACTIVE']\n",
    "\n",
    "    bureaudata = bureau_encoded\n",
    "\n",
    "    # === Define numeric aggregations ===\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var', 'median'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean', 'var', 'median'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean', 'min', 'max', 'var'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean', 'sum', 'var', 'median'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max', 'sum', 'var'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum', 'var', 'median'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum', 'var', 'median'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean', 'max', 'sum', 'var'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum', 'max', 'var', 'median'],\n",
    "        'AMT_ANNUITY': ['max', 'mean', 'sum', 'var', 'median'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum', 'mean', 'max'],\n",
    "    }\n",
    "\n",
    "    # === Define categorical aggregations ===\n",
    "    cat_aggregations = {}\n",
    "    for col, n_unique in bureau_label_info.items():\n",
    "        if n_unique == 2:\n",
    "            cat_aggregations[col] = ['mean']\n",
    "        elif n_unique > 2:\n",
    "            cat_aggregations[col] = [safe_mode]\n",
    "\n",
    "    # === Main aggregation at SK_ID_CURR level ===\n",
    "    bureaudata_aggregated = bureaudata.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureaudata_aggregated.columns = pd.Index([\n",
    "        f\"BURO_{col[0]}_BINARY_MEAN\" if col[1] == 'mean' and bureau_label_info.get(col[0], 0) == 2\n",
    "        else (f\"BURO_{col[0]}_MODE\" if col[1] == 'safe_mode' or 'lambda' in col[1] else f\"BURO_{col[0]}_{col[1].upper()}\")\n",
    "        for col in bureaudata_aggregated.columns\n",
    "    ])\n",
    "    print(f\"âœ… Bureau aggregated shape: {bureaudata_aggregated.shape}\")\n",
    "\n",
    "    # === Separate Active and Closed credit records ===\n",
    "    if 'CREDIT_ACTIVE' in bureaudata.columns:\n",
    "        active = bureaudata[bureaudata['CREDIT_ACTIVE'] == 'Active']\n",
    "        closed = bureaudata[bureaudata['CREDIT_ACTIVE'] == 'Closed']\n",
    "\n",
    "        # Fallback: use mode if 'Active' or 'Closed' not found\n",
    "        if active.empty:\n",
    "            active = bureaudata[bureaudata['CREDIT_ACTIVE'] == bureaudata['CREDIT_ACTIVE'].mode().iloc[0]]\n",
    "        if closed.empty:\n",
    "            closed = bureaudata[bureaudata['CREDIT_ACTIVE'] != bureaudata['CREDIT_ACTIVE'].mode().iloc[0]]\n",
    "\n",
    "        # Aggregate active credits\n",
    "        active_aggeragated = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        active_aggeragated.columns = pd.Index([f\"ACTIVE_{e[0]}_{e[1].upper()}\" for e in active_aggeragated.columns])\n",
    "        bureaudata_aggregated = bureaudata_aggregated.join(active_aggeragated, how='left', on='SK_ID_CURR')\n",
    "        del active, active_aggeragated\n",
    "        gc.collect()\n",
    "\n",
    "        # Aggregate closed credits\n",
    "        closed_aggeragated = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        closed_aggeragated.columns = pd.Index([f\"CLOSED_{e[0]}_{e[1].upper()}\" for e in closed_aggeragated.columns])\n",
    "        bureaudata_aggregated = bureaudata_aggregated.join(closed_aggeragated, how='left', on='SK_ID_CURR')\n",
    "        del closed, closed_aggeragated\n",
    "        gc.collect()\n",
    "\n",
    "    # === Derived ratio & recency features ===\n",
    "    bureaudata_aggregated['BURO_DEBT_CREDIT_RATIO'] = _safe_div(\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_DEBT_SUM'),\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_SUM')\n",
    "    )\n",
    "\n",
    "    bureaudata_aggregated['BURO_LIMIT_USAGE_RATIO'] = _safe_div(\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_DEBT_SUM'),\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_LIMIT_SUM')\n",
    "    )\n",
    "\n",
    "    bureaudata_aggregated['BURO_OVERDUE_DEBT_RATIO'] = _safe_div(\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_OVERDUE_SUM'),\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_DEBT_SUM')\n",
    "    )\n",
    "\n",
    "    bureaudata_aggregated['BURO_MAX_OVERDUE_TO_CREDIT'] = _safe_div(\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_MAX_OVERDUE_MAX'),\n",
    "        bureaudata_aggregated.get('BURO_AMT_CREDIT_SUM_SUM')\n",
    "    )\n",
    "\n",
    "    bureaudata_aggregated['BURO_RECENT_CREDIT_DAYS'] = -bureaudata_aggregated.get('BURO_DAYS_CREDIT_MAX')\n",
    "\n",
    "    if 'BURO_CREDIT_ACTIVE_BINARY_MEAN' in bureaudata_aggregated.columns:\n",
    "        bureaudata_aggregated['BURO_ACTIVE_SHARE'] = bureaudata_aggregated['BURO_CREDIT_ACTIVE_BINARY_MEAN']\n",
    "\n",
    "    bureaudata_aggregated['ACTIVE_DEBT_CREDIT_RATIO'] = _safe_div(\n",
    "        bureaudata_aggregated.get('ACTIVE_AMT_CREDIT_SUM_DEBT_SUM'),\n",
    "        bureaudata_aggregated.get('ACTIVE_AMT_CREDIT_SUM_SUM')\n",
    "    )\n",
    "\n",
    "    bureaudata_aggregated['ACTIVE_LIMIT_USAGE_RATIO'] = _safe_div(\n",
    "        bureaudata_aggregated.get('ACTIVE_AMT_CREDIT_SUM_DEBT_SUM'),\n",
    "        bureaudata_aggregated.get('ACTIVE_AMT_CREDIT_SUM_LIMIT_SUM')\n",
    "    )\n",
    "\n",
    "    bureaudata_aggregated['ACTIVE_OVERDUE_DEBT_RATIO'] = _safe_div(\n",
    "        bureaudata_aggregated.get('ACTIVE_AMT_CREDIT_SUM_OVERDUE_SUM'),\n",
    "        bureaudata_aggregated.get('ACTIVE_AMT_CREDIT_SUM_DEBT_SUM')\n",
    "    )\n",
    "\n",
    "    # === Cleanup ===\n",
    "    del bureaudata\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"ğŸ¯ Final Bureau data shape: {bureaudata_aggregated.shape}\")\n",
    "    return bureaudata_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2376504b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.601167Z",
     "iopub.status.busy": "2025-10-15T15:11:24.600793Z",
     "iopub.status.idle": "2025-10-15T15:11:24.618992Z",
     "shell.execute_reply": "2025-10-15T15:11:24.617639Z"
    },
    "papermill": {
     "duration": 0.03419,
     "end_time": "2025-10-15T15:11:24.621149",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.586959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def credit_card_balance(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Process and aggregate credit_card_balance.csv\n",
    "\n",
    "    Steps:\n",
    "      - Label encode categorical columns\n",
    "      - Aggregate only the original numeric columns (min, max, mean, sum, var)\n",
    "      - Aggregate categorical columns (binary â†’ mean, multi-category â†’ mode)\n",
    "      - Create derived ratio features such as utilization and payment ratios\n",
    "      - Add count-based and recent-activity indicators\n",
    "    \"\"\"\n",
    "    creditcarddata = pd.read_csv('/kaggle/input/home-credit-default-risk/credit_card_balance.csv', nrows=num_rows)\n",
    "    print(f\"ğŸ“„ Credit card balance raw shape: {creditcarddata.shape}\")\n",
    "\n",
    "    # === Record original numeric columns BEFORE encoding ===\n",
    "    original_numeric = creditcarddata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    # Label encode categorical columns\n",
    "    creditcarddata, cc_label_info = label_encode_categoricals(creditcarddata)\n",
    "\n",
    "    # Drop SK_ID_PREV because it is just a grouping key\n",
    "    if 'SK_ID_PREV' in creditcarddata.columns:\n",
    "        creditcarddata.drop(['SK_ID_PREV'], axis=1, inplace=True)\n",
    "\n",
    "    # === Numeric aggregations (only on original numeric columns) ===\n",
    "    valid_num_cols = [col for col in original_numeric if col in creditcarddata.columns and col not in ['SK_ID_CURR']]\n",
    "    num_agg = creditcarddata[valid_num_cols + ['SK_ID_CURR']].groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    num_agg.columns = ['{}_{}'.format(col[0], col[1].upper()) for col in num_agg.columns]\n",
    "\n",
    "    # === Categorical aggregations: binary â†’ mean, multi â†’ mode ===\n",
    "    cat_agg_dict = {}\n",
    "    for col, n_unique in cc_label_info.items():\n",
    "        if col in valid_num_cols or col in ['SK_ID_CURR']:\n",
    "            continue\n",
    "        if n_unique == 2:\n",
    "            cat_agg_dict[col] = ['mean']\n",
    "        elif n_unique > 2:\n",
    "            # Mode aggregation for multi-category columns\n",
    "            cat_agg_dict[col] = [lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan]\n",
    "\n",
    "    # Combine numeric and categorical aggregations\n",
    "    if cat_agg_dict:\n",
    "        cat_agg = creditcarddata.groupby('SK_ID_CURR').agg(cat_agg_dict)\n",
    "        cat_agg.columns = pd.Index([\n",
    "            f\"{col[0]}_BINARY_MEAN\" if col[1] == 'mean' and cc_label_info.get(col[0], 0) == 2\n",
    "            else (f\"{col[0]}_MODE\" if 'lambda' in col[1] else f\"{col[0]}_{col[1].upper()}\")\n",
    "            for col in cat_agg.columns\n",
    "        ])\n",
    "        creditcarddata_aggregated = num_agg.join(cat_agg, how='left')\n",
    "    else:\n",
    "        creditcarddata_aggregated = num_agg\n",
    "\n",
    "    # Add CC_ prefix to all feature names\n",
    "    creditcarddata_aggregated.columns = pd.Index([\n",
    "        f\"CC_{col}\" if not col.startswith('CC_') else col\n",
    "        for col in creditcarddata_aggregated.columns\n",
    "    ])\n",
    "\n",
    "    # === Basic count features ===\n",
    "    creditcarddata_aggregated['CC_COUNT'] = creditcarddata.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    # Helper function to safely get a column (return NaN Series if missing)\n",
    "    def _col(name):\n",
    "        return creditcarddata_aggregated[name] if name in creditcarddata_aggregated.columns else pd.Series(np.nan, index=creditcarddata_aggregated.index)\n",
    "\n",
    "    # === Derived ratio features ===\n",
    "    # Average utilization ratio (balance / credit limit)\n",
    "    creditcarddata_aggregated['CC_UTILIZATION_MEAN'] = _safe_div(\n",
    "        _col('CC_AMT_BALANCE_MEAN'),\n",
    "        _col('CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN')\n",
    "    )\n",
    "    # Total utilization ratio\n",
    "    creditcarddata_aggregated['CC_UTILIZATION_SUM'] = _safe_div(\n",
    "        _col('CC_AMT_BALANCE_SUM'),\n",
    "        _col('CC_AMT_CREDIT_LIMIT_ACTUAL_SUM')\n",
    "    )\n",
    "\n",
    "    # Payment ratio = total paid / total receivable\n",
    "    total_receivable = _col('CC_AMT_TOTAL_RECEIVABLE_SUM').fillna(_col('CC_AMT_RECIVABLE_SUM'))\n",
    "    creditcarddata_aggregated['CC_PAYMENT_RATIO'] = _safe_div(\n",
    "        _col('CC_AMT_PAYMENT_TOTAL_CURRENT_SUM').fillna(_col('CC_AMT_PAYMENT_CURRENT_SUM')),\n",
    "        total_receivable\n",
    "    )\n",
    "\n",
    "    # Minimum regular payment ratio\n",
    "    creditcarddata_aggregated['CC_MIN_PAY_REG_RATIO'] = _safe_div(\n",
    "        _col('CC_AMT_INST_MIN_REGULARITY_MEAN'),\n",
    "        _col('CC_AMT_TOTAL_RECEIVABLE_MEAN').fillna(_col('CC_AMT_RECIVABLE_MEAN'))\n",
    "    )\n",
    "\n",
    "    # Drawings (cash or POS) relative to credit limit\n",
    "    creditcarddata_aggregated['CC_DRAWINGS_TO_LIMIT'] = _safe_div(\n",
    "        _col('CC_AMT_DRAWINGS_CURRENT_SUM'),\n",
    "        _col('CC_AMT_CREDIT_LIMIT_ACTUAL_SUM')\n",
    "    )\n",
    "\n",
    "    # ATM drawings share\n",
    "    creditcarddata_aggregated['CC_ATM_DRAW_SHARE'] = _safe_div(\n",
    "        _col('CC_AMT_DRAWINGS_ATM_CURRENT_SUM'),\n",
    "        _col('CC_AMT_DRAWINGS_CURRENT_SUM')\n",
    "    )\n",
    "\n",
    "    # POS drawings share\n",
    "    creditcarddata_aggregated['CC_POS_DRAW_SHARE'] = _safe_div(\n",
    "        _col('CC_AMT_DRAWINGS_POS_CURRENT_SUM'),\n",
    "        _col('CC_AMT_DRAWINGS_CURRENT_SUM')\n",
    "    )\n",
    "\n",
    "    # Flag: has any delinquency (DPD or DPD_DEF > 0)\n",
    "    any_dpd = _col('CC_SK_DPD_MAX').fillna(0).gt(0) | _col('CC_SK_DPD_DEF_MAX').fillna(0).gt(0)\n",
    "    creditcarddata_aggregated['CC_ANY_DPD_FLAG'] = any_dpd.astype(np.int8)\n",
    "\n",
    "    # Flag: recent activity within the last 3 months\n",
    "    creditcarddata_aggregated['CC_RECENT_ACTIVITY_FLAG'] = _col('CC_MONTHS_BALANCE_MAX').gt(-3).astype(float)\n",
    "\n",
    "    del creditcarddata\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"âœ… Credit card balance aggregation completed: {creditcarddata_aggregated.shape}\")\n",
    "    return creditcarddata_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94601573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.648577Z",
     "iopub.status.busy": "2025-10-15T15:11:24.648202Z",
     "iopub.status.idle": "2025-10-15T15:11:24.668683Z",
     "shell.execute_reply": "2025-10-15T15:11:24.667567Z"
    },
    "papermill": {
     "duration": 0.036705,
     "end_time": "2025-10-15T15:11:24.670358",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.633653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def previous_applications(num_rows=None, nan_as_category=True):\n",
    "    \"\"\"\n",
    "    Safe and enhanced version of previous_applications():\n",
    "    - Splits 'Approved' and 'Refused' applications BEFORE label encoding\n",
    "    - Cleans numeric columns and replaces placeholder values\n",
    "    - Performs label encoding for categorical columns\n",
    "    - Creates engineered features (ratios, timing, interest rate estimate)\n",
    "    - Aggregates numeric and categorical features\n",
    "    - Adds approval/refusal ratios and counts\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import gc\n",
    "\n",
    "    # === Load data ===\n",
    "    previousdata = pd.read_csv('/kaggle/input/home-credit-default-risk/previous_application.csv', nrows=num_rows)\n",
    "    print(f\"ğŸ“„ Previous applications raw data shape: {previousdata.shape}\")\n",
    "\n",
    "    # === Split 'Approved' and 'Refused' subsets BEFORE label encoding ===\n",
    "    approved, refused = None, None\n",
    "    if 'NAME_CONTRACT_STATUS' in previousdata.columns:\n",
    "        approved = previousdata[previousdata['NAME_CONTRACT_STATUS'] == 'Approved'].copy()\n",
    "        refused = previousdata[previousdata['NAME_CONTRACT_STATUS'] == 'Refused'].copy()\n",
    "\n",
    "    # === Clean numeric and date columns ===\n",
    "    numerical_columns = previousdata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    date_columns = [\n",
    "        'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION',\n",
    "        'DAYS_LAST_DUE', 'DAYS_TERMINATION'\n",
    "    ]\n",
    "\n",
    "    # Replace invalid placeholder 365243 with NaN\n",
    "    for col in date_columns:\n",
    "        if col in previousdata.columns:\n",
    "            previousdata[col] = previousdata[col].replace(365243, np.nan)\n",
    "\n",
    "    # Clean numeric columns (replace inf/-inf, fill missing with median)\n",
    "    previousdata = clean_numerical_data(previousdata, numerical_columns)\n",
    "\n",
    "    # === Label encode categorical columns ===\n",
    "    previousdata, prev_label_info = label_encode_categoricals(previousdata)\n",
    "\n",
    "    # === Feature engineering ===\n",
    "    previousdata['APP_CREDIT_PERC'] = _safe_div(previousdata['AMT_APPLICATION'], previousdata['AMT_CREDIT'])\n",
    "    previousdata['APP_GOODS_PERC'] = _safe_div(previousdata['AMT_APPLICATION'], previousdata['AMT_GOODS_PRICE'])\n",
    "    previousdata['CREDIT_GOODS_RATIO'] = _safe_div(previousdata['AMT_CREDIT'], previousdata['AMT_GOODS_PRICE'])\n",
    "    previousdata['ANNUITY_CREDIT_RATIO'] = _safe_div(previousdata['AMT_ANNUITY'], previousdata['AMT_CREDIT'])\n",
    "    previousdata['DOWN_PAYMENT_RATIO'] = _safe_div(previousdata['AMT_DOWN_PAYMENT'], previousdata['AMT_CREDIT'])\n",
    "    previousdata['DOWN_PAYMENT_GOODS_RATIO'] = _safe_div(previousdata['AMT_DOWN_PAYMENT'], previousdata['AMT_GOODS_PRICE'])\n",
    "    previousdata['APP_DECISION_TIMING'] = previousdata['DAYS_DECISION'] - previousdata['DAYS_FIRST_DRAWING']\n",
    "\n",
    "    # Estimated interest rate based on annuity, credit amount, and payment count\n",
    "    previousdata['INTEREST_RATE_EST'] = _safe_div(\n",
    "        (previousdata['AMT_ANNUITY'] * previousdata['CNT_PAYMENT'] / previousdata['AMT_CREDIT'].replace(0, np.nan) - 1),\n",
    "        previousdata['CNT_PAYMENT']\n",
    "    )\n",
    "    # === Debug check: ensure feature engineering columns exist ===\n",
    "    print(\"Feature engineered columns:\", [c for c in previousdata.columns if 'APP_' in c or 'RATIO' in c or 'INTEREST' in c])\n",
    "\n",
    "    # Clean the engineered features\n",
    "    feature_columns = [\n",
    "        'APP_CREDIT_PERC', 'APP_GOODS_PERC', 'CREDIT_GOODS_RATIO',\n",
    "        'ANNUITY_CREDIT_RATIO', 'DOWN_PAYMENT_RATIO', 'DOWN_PAYMENT_GOODS_RATIO',\n",
    "        'APP_DECISION_TIMING', 'INTEREST_RATE_EST'\n",
    "    ]\n",
    "    previousdata = clean_numerical_data(previousdata, feature_columns)\n",
    "\n",
    "    # === Numeric feature aggregations ===\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean', 'sum'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum', 'max'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'APP_GOODS_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'CREDIT_GOODS_RATIO': ['min', 'max', 'mean'],\n",
    "        'ANNUITY_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "        'DOWN_PAYMENT_RATIO': ['min', 'max', 'mean'],\n",
    "        'INTEREST_RATE_EST': ['min', 'max', 'mean'],\n",
    "        'APP_DECISION_TIMING': ['min', 'max', 'mean']\n",
    "    }\n",
    "\n",
    "    # === Categorical feature aggregations ===\n",
    "    cat_aggregations = {}\n",
    "    for col, n_unique in prev_label_info.items():\n",
    "        if n_unique == 2:\n",
    "            cat_aggregations[col] = ['mean']  # Binary features â†’ mean\n",
    "        elif n_unique > 2:\n",
    "            cat_aggregations[col] = [lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan]  # Multi-cat â†’ mode\n",
    "\n",
    "    # === Aggregate by SK_ID_CURR ===\n",
    "    previousdata_aggregated = previousdata.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    previousdata_aggregated.columns = pd.Index([\n",
    "        f\"PREV_{col[0]}_BINARY_MEAN\" if col[1] == 'mean' and prev_label_info.get(col[0], 0) == 2\n",
    "        else (f\"PREV_{col[0]}_MODE\" if 'lambda' in col[1] else f\"PREV_{col[0]}_{col[1].upper()}\")\n",
    "        for col in previousdata_aggregated.columns\n",
    "    ])\n",
    "\n",
    "    # === Approved / Refused aggregations (use the pre-encoded subsets) ===\n",
    "    if approved is not None and not approved.empty:\n",
    "        approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        approved_agg.columns = pd.Index([f\"APPROVED_{e[0]}_{e[1].upper()}\" for e in approved_agg.columns])\n",
    "        previousdata_aggregated = previousdata_aggregated.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    if refused is not None and not refused.empty:\n",
    "        refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "        refused_agg.columns = pd.Index([f\"REFUSED_{e[0]}_{e[1].upper()}\" for e in refused_agg.columns])\n",
    "        previousdata_aggregated = previousdata_aggregated.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    # === Count features ===\n",
    "    previousdata_aggregated['PREV_APP_COUNT'] = previousdata.groupby('SK_ID_CURR').size()\n",
    "    if approved is not None and not approved.empty:\n",
    "        previousdata_aggregated['PREV_APPROVED_COUNT'] = approved.groupby('SK_ID_CURR').size()\n",
    "    if refused is not None and not refused.empty:\n",
    "        previousdata_aggregated['PREV_REFUSED_COUNT'] = refused.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    # === Ratio features ===\n",
    "    if 'PREV_APPROVED_COUNT' in previousdata_aggregated.columns and 'PREV_APP_COUNT' in previousdata_aggregated.columns:\n",
    "        previousdata_aggregated['PREV_APPROVAL_RATE'] = _safe_div(\n",
    "            previousdata_aggregated['PREV_APPROVED_COUNT'], previousdata_aggregated['PREV_APP_COUNT']\n",
    "        ).fillna(0)\n",
    "\n",
    "    # === Cleanup ===\n",
    "    del previousdata, approved, refused\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"âœ… Previous applications aggregated shape: {previousdata_aggregated.shape}\")\n",
    "    return previousdata_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5648a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.697014Z",
     "iopub.status.busy": "2025-10-15T15:11:24.696195Z",
     "iopub.status.idle": "2025-10-15T15:11:24.711693Z",
     "shell.execute_reply": "2025-10-15T15:11:24.710487Z"
    },
    "papermill": {
     "duration": 0.030858,
     "end_time": "2025-10-15T15:11:24.713677",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.682819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_cash(num_rows=None, nan_as_category=True):\n",
    "    posdata = pd.read_csv('/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv', nrows=num_rows)\n",
    "    print(f\"POS_CASH balance raw data shape: {posdata.shape}\")\n",
    "\n",
    "    numerical_columns = posdata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    posdata = clean_numerical_data(posdata, numerical_columns)\n",
    "\n",
    "    # replaced one-hot with label encoding\n",
    "    posdata, pos_label_info = label_encode_categoricals(posdata)\n",
    "\n",
    "    # Feature Engineering\n",
    "    posdata['INSTALMENT_PROGRESS'] = posdata['CNT_INSTALMENT'] - posdata['CNT_INSTALMENT_FUTURE']\n",
    "    posdata['INSTALMENT_COMPLETION_RATIO'] = _safe_div(posdata['INSTALMENT_PROGRESS'], posdata['CNT_INSTALMENT'])\n",
    "\n",
    "    posdata['POS_IS_DPD'] = posdata['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    posdata['POS_IS_DPD_UNDER_30'] = posdata['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x <= 30) else 0)\n",
    "    posdata['POS_IS_DPD_OVER_30'] = posdata['SK_DPD'].apply(lambda x: 1 if x > 30 else 0)\n",
    "    posdata['POS_IS_DPD_OVER_120'] = posdata['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "    posdata['POS_IS_SEVERE_DPD'] = posdata['SK_DPD_DEF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    posdata = clean_numerical_data(posdata, ['INSTALMENT_COMPLETION_RATIO'])\n",
    "\n",
    "    # Numeric aggregations\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['min', 'max', 'mean', 'size'],\n",
    "        'SK_DPD': ['min', 'max', 'mean', 'sum'],\n",
    "        'SK_DPD_DEF': ['max', 'mean', 'sum'],\n",
    "        'CNT_INSTALMENT': ['min', 'max', 'mean'],\n",
    "        'CNT_INSTALMENT_FUTURE': ['min', 'max', 'mean'],\n",
    "        'POS_IS_DPD': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_UNDER_30': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_30': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "        'POS_IS_SEVERE_DPD': ['mean', 'sum'],\n",
    "        'INSTALMENT_PROGRESS': ['min', 'max', 'mean', 'sum'],\n",
    "        'INSTALMENT_COMPLETION_RATIO': ['min', 'max', 'mean']\n",
    "    }\n",
    "\n",
    "    # categorical aggregation logic (binary â†’ mean, multi â†’ mode)\n",
    "    for col, n_unique in pos_label_info.items():\n",
    "        if n_unique == 2:\n",
    "            aggregations[col] = ['mean']\n",
    "        elif n_unique > 2:\n",
    "            aggregations[col] = [lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan]\n",
    "\n",
    "    posdata_aggrgated = posdata.groupby('SK_ID_CURR').agg(aggregations)\n",
    "\n",
    "    # rename columns reflecting binary/multi\n",
    "    posdata_aggrgated.columns = pd.Index([\n",
    "        f\"POS_{col[0]}_BINARY_MEAN\" if col[1] == 'mean' and pos_label_info.get(col[0], 0) == 2\n",
    "        else (f\"POS_{col[0]}_MODE\" if 'lambda' in col[1] else f\"POS_{col[0]}_{col[1].upper()}\")\n",
    "        for col in posdata_aggrgated.columns\n",
    "    ])\n",
    "\n",
    "    # Counts\n",
    "    posdata_aggrgated['POS_COUNT'] = posdata.groupby('SK_ID_CURR').size()\n",
    "    posdata_aggrgated['POS_ACTIVE_COUNT'] = posdata.groupby('SK_ID_CURR')['SK_ID_PREV'].nunique()\n",
    "\n",
    "    # Recent behavior\n",
    "    recent_pos = posdata[posdata['MONTHS_BALANCE'] >= -12]\n",
    "    if len(recent_pos) > 0:\n",
    "        recent_agg = recent_pos.groupby('SK_ID_CURR').agg({\n",
    "            'SK_DPD': ['max', 'mean'],\n",
    "            'POS_IS_DPD': ['mean', 'sum'],\n",
    "            'POS_IS_DPD_OVER_30': ['mean', 'sum']\n",
    "        })\n",
    "        recent_agg.columns = pd.Index(['POS_RECENT_' + e[0] + \"_\" + e[1].upper() for e in recent_agg.columns.tolist()])\n",
    "        posdata_aggrgated = posdata_aggrgated.join(recent_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    del posdata\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"POS_CASH balance aggregated shape: {posdata_aggrgated.shape}\")\n",
    "    return posdata_aggrgated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aef1739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.740503Z",
     "iopub.status.busy": "2025-10-15T15:11:24.740178Z",
     "iopub.status.idle": "2025-10-15T15:11:24.758348Z",
     "shell.execute_reply": "2025-10-15T15:11:24.757359Z"
    },
    "papermill": {
     "duration": 0.033593,
     "end_time": "2025-10-15T15:11:24.760236",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.726643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def installments_payments(num_rows=None, nan_as_category=True):\n",
    "    installmentdata = pd.read_csv('/kaggle/input/home-credit-default-risk/installments_payments.csv', nrows=num_rows)\n",
    "    print(f\"Installments payments raw data shape: {installmentdata.shape}\")\n",
    "\n",
    "    numerical_columns = installmentdata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    installmentdata = clean_numerical_data(installmentdata, numerical_columns)\n",
    "\n",
    "    # replaced one-hot with label encoding\n",
    "    installmentdata, ins_label_info = label_encode_categoricals(installmentdata)\n",
    "\n",
    "    # Feature Engineering\n",
    "    installmentdata['PAYMENT_PERC'] = _safe_div(installmentdata['AMT_PAYMENT'], installmentdata['AMT_INSTALMENT'])\n",
    "    installmentdata['PAYMENT_DIFF'] = installmentdata['AMT_INSTALMENT'] - installmentdata['AMT_PAYMENT']\n",
    "\n",
    "    installmentdata['DPD'] = installmentdata['DAYS_ENTRY_PAYMENT'] - installmentdata['DAYS_INSTALMENT']\n",
    "    installmentdata['DBD'] = installmentdata['DAYS_INSTALMENT'] - installmentdata['DAYS_ENTRY_PAYMENT']\n",
    "    installmentdata['DPD'] = installmentdata['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    installmentdata['DBD'] = installmentdata['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    installmentdata['INS_IS_DPD'] = installmentdata['DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    installmentdata['INS_IS_DPD_UNDER_30'] = installmentdata['DPD'].apply(lambda x: 1 if (x > 0) & (x <= 30) else 0)\n",
    "    installmentdata['INS_IS_DPD_OVER_30'] = installmentdata['DPD'].apply(lambda x: 1 if x > 30 else 0)\n",
    "    installmentdata['INS_IS_EARLY_PAYMENT'] = installmentdata['DBD'].apply(lambda x: 1 if x > 7 else 0)\n",
    "\n",
    "    # Payment consistency\n",
    "    payment_variance = installmentdata.groupby('SK_ID_PREV')['PAYMENT_PERC'].var().reset_index()\n",
    "    payment_variance.columns = ['SK_ID_PREV', 'PAYMENT_VARIANCE']\n",
    "    installmentdata = installmentdata.merge(payment_variance, on='SK_ID_PREV', how='left')\n",
    "    installmentdata['PAYMENT_CONSISTENCY'] = 1 / (1 + installmentdata['PAYMENT_VARIANCE'].fillna(0))\n",
    "\n",
    "    installmentdata = clean_numerical_data(installmentdata, ['PAYMENT_PERC', 'PAYMENT_DIFF', 'DPD', 'DBD', 'PAYMENT_CONSISTENCY'])\n",
    "\n",
    "    # Numeric aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum'],\n",
    "        'DAYS_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'INS_IS_DPD': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_30': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_30': ['mean', 'sum'],\n",
    "        'INS_IS_EARLY_PAYMENT': ['mean', 'sum'],\n",
    "        'PAYMENT_CONSISTENCY': ['min', 'max', 'mean']\n",
    "    }\n",
    "\n",
    "    # categorical aggregation logic (binary â†’ mean, multi â†’ mode)\n",
    "    for col, n_unique in ins_label_info.items():\n",
    "        if n_unique == 2:\n",
    "            aggregations[col] = ['mean']\n",
    "        elif n_unique > 2:\n",
    "            aggregations[col] = [lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan]\n",
    "\n",
    "    installmentdata_aggregated = installmentdata.groupby('SK_ID_CURR').agg(aggregations)\n",
    "\n",
    "    # rename columns reflecting binary/multi\n",
    "    installmentdata_aggregated.columns = pd.Index([\n",
    "        f\"INSTAL_{col[0]}_BINARY_MEAN\" if col[1] == 'mean' and ins_label_info.get(col[0], 0) == 2\n",
    "        else (f\"INSTAL_{col[0]}_MODE\" if 'lambda' in col[1] else f\"INSTAL_{col[0]}_{col[1].upper()}\")\n",
    "        for col in installmentdata_aggregated.columns\n",
    "    ])\n",
    "\n",
    "    installmentdata_aggregated['INSTAL_COUNT'] = installmentdata.groupby('SK_ID_CURR').size()\n",
    "    installmentdata_aggregated['INSTAL_ACCOUNT_COUNT'] = installmentdata.groupby('SK_ID_CURR')['SK_ID_PREV'].nunique()\n",
    "\n",
    "    # Recent behavior\n",
    "    recent_ins = installmentdata[installmentdata['DAYS_ENTRY_PAYMENT'] >= -365]\n",
    "    if len(recent_ins) > 0:\n",
    "        recent_agg = recent_ins.groupby('SK_ID_CURR').agg({\n",
    "            'PAYMENT_PERC': ['mean', 'min'],\n",
    "            'DPD': ['max', 'mean'],\n",
    "            'INS_IS_DPD': ['mean', 'sum'],\n",
    "            'INS_IS_EARLY_PAYMENT': ['mean']\n",
    "        })\n",
    "        recent_agg.columns = pd.Index(\n",
    "            ['INSTAL_RECENT_' + e[0] + \"_\" + e[1].upper() for e in recent_agg.columns.tolist()])\n",
    "        installmentdata_aggregated = installmentdata_aggregated.join(recent_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    del installmentdata, payment_variance\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Installments payments aggregated shape: {installmentdata_aggregated.shape}\")\n",
    "    return installmentdata_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ccd4a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:11:24.787049Z",
     "iopub.status.busy": "2025-10-15T15:11:24.786595Z",
     "iopub.status.idle": "2025-10-15T15:38:41.717650Z",
     "shell.execute_reply": "2025-10-15T15:38:41.716465Z"
    },
    "papermill": {
     "duration": 1636.948011,
     "end_time": "2025-10-15T15:38:41.720792",
     "exception": false,
     "start_time": "2025-10-15T15:11:24.772781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Label-encoded categorical features: 13 columns processed.\n",
      "Starting with main dataframe: (356251, 199)\n",
      "ğŸ“„ Bureau raw shape: (1716428, 17), Bureau_balance raw shape: (27299925, 3)\n",
      "âœ… Bureau balance aggregated shape: (817395, 5)\n",
      "âœ… Bureau aggregated shape: (305811, 52)\n",
      "ğŸ¯ Final Bureau data shape: (305811, 160)\n",
      "After merging bureau data: (356251, 359)\n",
      "Merging bureau and balance data - done in 219s\n",
      "ğŸ“„ Credit card balance raw shape: (3840312, 23)\n",
      "âœ… Credit card balance aggregation completed: (103558, 111)\n",
      "After merging credit card data: (356251, 470)\n",
      "Merging credit card balance data - done in 50s\n",
      "ğŸ“„ Previous applications raw data shape: (1670214, 37)\n",
      "Feature engineered columns: ['RATE_INTEREST_PRIMARY', 'RATE_INTEREST_PRIVILEGED', 'APP_CREDIT_PERC', 'APP_GOODS_PERC', 'CREDIT_GOODS_RATIO', 'ANNUITY_CREDIT_RATIO', 'DOWN_PAYMENT_RATIO', 'DOWN_PAYMENT_GOODS_RATIO', 'APP_DECISION_TIMING', 'INTEREST_RATE_EST']\n",
      "âš ï¸ Skipping previous applications due to error: \"Column(s) ['ANNUITY_CREDIT_RATIO', 'APP_CREDIT_PERC', 'APP_DECISION_TIMING', 'APP_GOODS_PERC', 'CREDIT_GOODS_RATIO', 'DOWN_PAYMENT_RATIO', 'INTEREST_RATE_EST'] do not exist\"\n",
      "Merging previous applications - done in 1113s\n",
      "POS_CASH balance raw data shape: (10001358, 8)\n",
      "POS_CASH balance aggregated shape: (337252, 43)\n",
      "After merging POS-CASH balance: (356251, 513)\n",
      "Merging POS-CASH balance - done in 133s\n",
      "Installments payments raw data shape: (13605401, 8)\n",
      "Installments payments aggregated shape: (339587, 49)\n",
      "After merging installments payments: (356251, 562)\n",
      "Merging installments payments - done in 95s\n",
      "\n",
      "âœ… Final merged dataframe shape: (356251, 562)\n",
      "Final train shape: (307507, 561)\n",
      "Final test shape: (48744, 561)\n",
      "Full data processing pipeline - done in 1637s\n",
      "\n",
      "=== ğŸ‰ PROCESSING COMPLETE ===\n",
      "Final train data: 307,507 rows Ã— 561 columns\n",
      "Final test data:  48,744 rows Ã— 561 columns\n",
      "Full merged data: 356,251 rows Ã— 562 columns\n"
     ]
    }
   ],
   "source": [
    "# ========== MAIN TABLE PROCESSING AND MERGING ==========\n",
    "\n",
    "def merge_all_processed_tables(df, num_rows=None):\n",
    "    \"\"\"\n",
    "    Merge bureau_agg, cc_agg, prev_agg, pos_agg, ins_agg\n",
    "    into your preprocessed main dataframe (df).\n",
    "    Each step is timed, logged, and safely handled.\n",
    "    \"\"\"\n",
    "    print(f\"Starting with main dataframe: {df.shape}\")\n",
    "\n",
    "    with timer(\"Merging bureau and balance data\"):\n",
    "        try:\n",
    "            bureaudata_aggregated = bureau_and_balance(num_rows)\n",
    "            df = df.merge(bureaudata_aggregated, on='SK_ID_CURR', how='left')\n",
    "            print(f\"After merging bureau data: {df.shape}\")\n",
    "            del bureaudata_aggregated; gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping bureau data due to error: {e}\")\n",
    "\n",
    "    with timer(\"Merging credit card balance data\"):\n",
    "        try:\n",
    "            creditcarddata_aggregated = credit_card_balance(num_rows)\n",
    "            df = df.merge(creditcarddata_aggregated, on='SK_ID_CURR', how='left')\n",
    "            print(f\"After merging credit card data: {df.shape}\")\n",
    "            del creditcarddata_aggregated; gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping credit card data due to error: {e}\")\n",
    "\n",
    "    with timer(\"Merging previous applications\"):\n",
    "        try:\n",
    "            previousdata_aggregated = previous_applications(num_rows)\n",
    "            df = df.merge(previousdata_aggregated, on='SK_ID_CURR', how='left')\n",
    "            print(f\"After merging previous applications: {df.shape}\")\n",
    "            del previousdata_aggregated; gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping previous applications due to error: {e}\")\n",
    "\n",
    "    with timer(\"Merging POS-CASH balance\"):\n",
    "        try:\n",
    "            posdata_aggregated = pos_cash(num_rows)\n",
    "            df = df.merge(posdata_aggregated, on='SK_ID_CURR', how='left')\n",
    "            print(f\"After merging POS-CASH balance: {df.shape}\")\n",
    "            del posdata_aggregated; gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping POS-CASH balance due to error: {e}\")\n",
    "\n",
    "    with timer(\"Merging installments payments\"):\n",
    "        try:\n",
    "            installmentdata_aggregated = installments_payments(num_rows)\n",
    "            df = df.merge(installmentdata_aggregated, on='SK_ID_CURR', how='left')\n",
    "            print(f\"After merging installments payments: {df.shape}\")\n",
    "            del installmentdata_aggregated; gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Skipping installments payments due to error: {e}\")\n",
    "\n",
    "    print(f\"\\nâœ… Final merged dataframe shape: {df.shape}\")\n",
    "\n",
    "    # Split back into train and test\n",
    "    train_df = df[df['is_train'] == 1].drop('is_train', axis=1)\n",
    "    test_df = df[df['is_train'] == 0].drop('is_train', axis=1)\n",
    "\n",
    "    print(f\"Final train shape: {train_df.shape}\")\n",
    "    print(f\"Final test shape: {test_df.shape}\")\n",
    "\n",
    "    return train_df, test_df, df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with timer(\"Full data processing pipeline\"):\n",
    "        main_df = application_train_test(num_rows=None, nan_as_category=False)\n",
    "        train_df, test_df, full_df = merge_all_processed_tables(main_df, num_rows=None)\n",
    "\n",
    "    print(\"\\n=== ğŸ‰ PROCESSING COMPLETE ===\")\n",
    "    print(f\"Final train data: {train_df.shape[0]:,} rows Ã— {train_df.shape[1]:,} columns\")\n",
    "    print(f\"Final test data:  {test_df.shape[0]:,} rows Ã— {test_df.shape[1]:,} columns\")\n",
    "    print(f\"Full merged data: {full_df.shape[0]:,} rows Ã— {full_df.shape[1]:,} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3bc3f",
   "metadata": {
    "papermill": {
     "duration": 0.01404,
     "end_time": "2025-10-15T15:38:41.750581",
     "exception": false,
     "start_time": "2025-10-15T15:38:41.736541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Analyze Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a01890c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:41.782103Z",
     "iopub.status.busy": "2025-10-15T15:38:41.781719Z",
     "iopub.status.idle": "2025-10-15T15:38:41.811489Z",
     "shell.execute_reply": "2025-10-15T15:38:41.810379Z"
    },
    "papermill": {
     "duration": 0.047915,
     "end_time": "2025-10-15T15:38:41.813234",
     "exception": false,
     "start_time": "2025-10-15T15:38:41.765319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 307507 entries, 0 to 307506\n",
      "Columns: 561 entries, SK_ID_CURR to INSTAL_RECENT_INS_IS_EARLY_PAYMENT_MEAN\n",
      "dtypes: float64(505), int64(56)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160c4adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:41.843533Z",
     "iopub.status.busy": "2025-10-15T15:38:41.843165Z",
     "iopub.status.idle": "2025-10-15T15:38:42.064081Z",
     "shell.execute_reply": "2025-10-15T15:38:42.062558Z"
    },
    "papermill": {
     "duration": 0.24296,
     "end_time": "2025-10-15T15:38:42.070688",
     "exception": false,
     "start_time": "2025-10-15T15:38:41.827728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>buro_preds_TARGET_mean</th>\n",
       "      <th>buro_preds_TARGET_median</th>\n",
       "      <th>buro_preds_TARGET_min</th>\n",
       "      <th>buro_preds_TARGET_max</th>\n",
       "      <th>buro_preds_TARGET_dispersion</th>\n",
       "      <th>prapp_preds_TARGET_mean</th>\n",
       "      <th>prapp_preds_TARGET_median</th>\n",
       "      <th>prapp_preds_TARGET_min</th>\n",
       "      <th>prapp_preds_TARGET_max</th>\n",
       "      <th>prapp_preds_TARGET_dispersion</th>\n",
       "      <th>ip_preds_TARGET_amin</th>\n",
       "      <th>ip_preds_TARGET_amax</th>\n",
       "      <th>ip_preds_TARGET_mean</th>\n",
       "      <th>ip_preds_TARGET_std</th>\n",
       "      <th>ip_preds_TARGET_percentile_10</th>\n",
       "      <th>ip_preds_TARGET_percentile_20</th>\n",
       "      <th>ip_preds_TARGET_percentile_30</th>\n",
       "      <th>ip_preds_TARGET_percentile_40</th>\n",
       "      <th>ip_preds_TARGET_percentile_50</th>\n",
       "      <th>ip_preds_TARGET_percentile_60</th>\n",
       "      <th>ip_preds_TARGET_percentile_70</th>\n",
       "      <th>ip_preds_TARGET_percentile_80</th>\n",
       "      <th>ip_preds_TARGET_percentile_90</th>\n",
       "      <th>cc_bal_preds_TARGET_amin</th>\n",
       "      <th>cc_bal_preds_TARGET_amax</th>\n",
       "      <th>cc_bal_preds_TARGET_mean</th>\n",
       "      <th>cc_bal_preds_TARGET_std</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_10</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_20</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_30</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_40</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_50</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_60</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_70</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_80</th>\n",
       "      <th>cc_bal_preds_TARGET_percentile_90</th>\n",
       "      <th>pos_bal_preds_TARGET_amin</th>\n",
       "      <th>pos_bal_preds_TARGET_amax</th>\n",
       "      <th>pos_bal_preds_TARGET_mean</th>\n",
       "      <th>pos_bal_preds_TARGET_std</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_10</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_20</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_30</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_40</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_50</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_60</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_70</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_80</th>\n",
       "      <th>pos_bal_preds_TARGET_percentile_90</th>\n",
       "      <th>prapp_preds_TARGET_mean.1</th>\n",
       "      <th>prapp_preds_TARGET_median.1</th>\n",
       "      <th>prapp_preds_TARGET_min.1</th>\n",
       "      <th>prapp_preds_TARGET_max.1</th>\n",
       "      <th>prapp_preds_TARGET_dispersion.1</th>\n",
       "      <th>nn_oof_single_past</th>\n",
       "      <th>predicted_cnt</th>\n",
       "      <th>predicted_ir</th>\n",
       "      <th>cnt_cut</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_CREDIT_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <th>PAYMENT_RATE</th>\n",
       "      <th>CREDIT_INCOME_DIFF</th>\n",
       "      <th>CREDIT_TERM</th>\n",
       "      <th>INCOME_PER_CHILD</th>\n",
       "      <th>CREDIT_GOODS_PERC</th>\n",
       "      <th>EMPLOY_TO_AGE_RATIO</th>\n",
       "      <th>CHILDREN_RATIO</th>\n",
       "      <th>CAR_AGE_RATIO</th>\n",
       "      <th>REALTY_AND_CAR_FLAG</th>\n",
       "      <th>LOG_INCOME</th>\n",
       "      <th>LOG_CREDIT</th>\n",
       "      <th>INCOME_X_EMPLOY</th>\n",
       "      <th>CREDIT_X_FAMILY</th>\n",
       "      <th>CREDIT_PER_CHILD</th>\n",
       "      <th>BURO_DAYS_CREDIT_MIN</th>\n",
       "      <th>BURO_DAYS_CREDIT_MAX</th>\n",
       "      <th>BURO_DAYS_CREDIT_MEAN</th>\n",
       "      <th>BURO_DAYS_CREDIT_VAR</th>\n",
       "      <th>BURO_DAYS_CREDIT_MEDIAN</th>\n",
       "      <th>BURO_DAYS_CREDIT_ENDDATE_MIN</th>\n",
       "      <th>BURO_DAYS_CREDIT_ENDDATE_MAX</th>\n",
       "      <th>BURO_DAYS_CREDIT_ENDDATE_MEAN</th>\n",
       "      <th>BURO_DAYS_CREDIT_ENDDATE_VAR</th>\n",
       "      <th>BURO_DAYS_CREDIT_ENDDATE_MEDIAN</th>\n",
       "      <th>BURO_DAYS_CREDIT_UPDATE_MEAN</th>\n",
       "      <th>BURO_DAYS_CREDIT_UPDATE_MIN</th>\n",
       "      <th>BURO_DAYS_CREDIT_UPDATE_MAX</th>\n",
       "      <th>BURO_DAYS_CREDIT_UPDATE_VAR</th>\n",
       "      <th>BURO_CREDIT_DAY_OVERDUE_MAX</th>\n",
       "      <th>BURO_CREDIT_DAY_OVERDUE_MEAN</th>\n",
       "      <th>BURO_CREDIT_DAY_OVERDUE_SUM</th>\n",
       "      <th>BURO_CREDIT_DAY_OVERDUE_VAR</th>\n",
       "      <th>BURO_CREDIT_DAY_OVERDUE_MEDIAN</th>\n",
       "      <th>BURO_AMT_CREDIT_MAX_OVERDUE_MEAN</th>\n",
       "      <th>BURO_AMT_CREDIT_MAX_OVERDUE_MAX</th>\n",
       "      <th>BURO_AMT_CREDIT_MAX_OVERDUE_SUM</th>\n",
       "      <th>BURO_AMT_CREDIT_MAX_OVERDUE_VAR</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_MAX</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_MEAN</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_SUM</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_VAR</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_MEDIAN</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_DEBT_MAX</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_DEBT_MEAN</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_DEBT_SUM</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_DEBT_VAR</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_DEBT_MEDIAN</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_OVERDUE_MEAN</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_OVERDUE_MAX</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_OVERDUE_SUM</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_OVERDUE_VAR</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_LIMIT_MEAN</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_LIMIT_SUM</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_LIMIT_MAX</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_LIMIT_VAR</th>\n",
       "      <th>BURO_AMT_CREDIT_SUM_LIMIT_MEDIAN</th>\n",
       "      <th>BURO_AMT_ANNUITY_MAX</th>\n",
       "      <th>BURO_AMT_ANNUITY_MEAN</th>\n",
       "      <th>BURO_AMT_ANNUITY_SUM</th>\n",
       "      <th>BURO_AMT_ANNUITY_VAR</th>\n",
       "      <th>BURO_AMT_ANNUITY_MEDIAN</th>\n",
       "      <th>BURO_CNT_CREDIT_PROLONG_SUM</th>\n",
       "      <th>BURO_CNT_CREDIT_PROLONG_MEAN</th>\n",
       "      <th>BURO_CNT_CREDIT_PROLONG_MAX</th>\n",
       "      <th>BURO_CREDIT_CURRENCY_MODE</th>\n",
       "      <th>BURO_CREDIT_TYPE_MODE</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_MIN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_MAX</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_MEAN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_VAR</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_MEDIAN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_ENDDATE_MIN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_ENDDATE_MAX</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_ENDDATE_MEAN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_ENDDATE_VAR</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_ENDDATE_MEDIAN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_UPDATE_MEAN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_UPDATE_MIN</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_UPDATE_MAX</th>\n",
       "      <th>ACTIVE_DAYS_CREDIT_UPDATE_VAR</th>\n",
       "      <th>ACTIVE_CREDIT_DAY_OVERDUE_MAX</th>\n",
       "      <th>ACTIVE_CREDIT_DAY_OVERDUE_MEAN</th>\n",
       "      <th>ACTIVE_CREDIT_DAY_OVERDUE_SUM</th>\n",
       "      <th>ACTIVE_CREDIT_DAY_OVERDUE_VAR</th>\n",
       "      <th>ACTIVE_CREDIT_DAY_OVERDUE_MEDIAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_MAX_OVERDUE_MEAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_MAX_OVERDUE_MAX</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_MAX_OVERDUE_SUM</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_MAX_OVERDUE_VAR</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_MAX</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_MEAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_SUM</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_VAR</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_MEDIAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_DEBT_MAX</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_DEBT_MEAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_DEBT_SUM</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_DEBT_VAR</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_DEBT_MEDIAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_OVERDUE_MEAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_OVERDUE_MAX</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_OVERDUE_SUM</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_OVERDUE_VAR</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_LIMIT_MEAN</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_LIMIT_SUM</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_LIMIT_MAX</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_LIMIT_VAR</th>\n",
       "      <th>ACTIVE_AMT_CREDIT_SUM_LIMIT_MEDIAN</th>\n",
       "      <th>ACTIVE_AMT_ANNUITY_MAX</th>\n",
       "      <th>ACTIVE_AMT_ANNUITY_MEAN</th>\n",
       "      <th>ACTIVE_AMT_ANNUITY_SUM</th>\n",
       "      <th>ACTIVE_AMT_ANNUITY_VAR</th>\n",
       "      <th>ACTIVE_AMT_ANNUITY_MEDIAN</th>\n",
       "      <th>ACTIVE_CNT_CREDIT_PROLONG_SUM</th>\n",
       "      <th>ACTIVE_CNT_CREDIT_PROLONG_MEAN</th>\n",
       "      <th>ACTIVE_CNT_CREDIT_PROLONG_MAX</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_MIN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_MAX</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_MEAN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_VAR</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_MEDIAN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_ENDDATE_MIN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_ENDDATE_MAX</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_ENDDATE_MEAN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_ENDDATE_VAR</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_ENDDATE_MEDIAN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_UPDATE_MEAN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_UPDATE_MIN</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_UPDATE_MAX</th>\n",
       "      <th>CLOSED_DAYS_CREDIT_UPDATE_VAR</th>\n",
       "      <th>CLOSED_CREDIT_DAY_OVERDUE_MAX</th>\n",
       "      <th>CLOSED_CREDIT_DAY_OVERDUE_MEAN</th>\n",
       "      <th>CLOSED_CREDIT_DAY_OVERDUE_SUM</th>\n",
       "      <th>CLOSED_CREDIT_DAY_OVERDUE_VAR</th>\n",
       "      <th>CLOSED_CREDIT_DAY_OVERDUE_MEDIAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_MAX_OVERDUE_MEAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_MAX_OVERDUE_MAX</th>\n",
       "      <th>CLOSED_AMT_CREDIT_MAX_OVERDUE_SUM</th>\n",
       "      <th>CLOSED_AMT_CREDIT_MAX_OVERDUE_VAR</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_MAX</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_MEAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_SUM</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_VAR</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_MEDIAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_DEBT_MAX</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_DEBT_MEAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_DEBT_SUM</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_DEBT_VAR</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_DEBT_MEDIAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_OVERDUE_MEAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_OVERDUE_MAX</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_OVERDUE_SUM</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_OVERDUE_VAR</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_LIMIT_MEAN</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_LIMIT_SUM</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_LIMIT_MAX</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_LIMIT_VAR</th>\n",
       "      <th>CLOSED_AMT_CREDIT_SUM_LIMIT_MEDIAN</th>\n",
       "      <th>CLOSED_AMT_ANNUITY_MAX</th>\n",
       "      <th>CLOSED_AMT_ANNUITY_MEAN</th>\n",
       "      <th>CLOSED_AMT_ANNUITY_SUM</th>\n",
       "      <th>CLOSED_AMT_ANNUITY_VAR</th>\n",
       "      <th>CLOSED_AMT_ANNUITY_MEDIAN</th>\n",
       "      <th>CLOSED_CNT_CREDIT_PROLONG_SUM</th>\n",
       "      <th>CLOSED_CNT_CREDIT_PROLONG_MEAN</th>\n",
       "      <th>CLOSED_CNT_CREDIT_PROLONG_MAX</th>\n",
       "      <th>BURO_DEBT_CREDIT_RATIO</th>\n",
       "      <th>BURO_LIMIT_USAGE_RATIO</th>\n",
       "      <th>BURO_OVERDUE_DEBT_RATIO</th>\n",
       "      <th>BURO_MAX_OVERDUE_TO_CREDIT</th>\n",
       "      <th>BURO_RECENT_CREDIT_DAYS</th>\n",
       "      <th>ACTIVE_DEBT_CREDIT_RATIO</th>\n",
       "      <th>ACTIVE_LIMIT_USAGE_RATIO</th>\n",
       "      <th>ACTIVE_OVERDUE_DEBT_RATIO</th>\n",
       "      <th>CC_MONTHS_BALANCE_MIN</th>\n",
       "      <th>CC_MONTHS_BALANCE_MAX</th>\n",
       "      <th>CC_MONTHS_BALANCE_MEAN</th>\n",
       "      <th>CC_MONTHS_BALANCE_SUM</th>\n",
       "      <th>CC_MONTHS_BALANCE_VAR</th>\n",
       "      <th>CC_AMT_BALANCE_MIN</th>\n",
       "      <th>CC_AMT_BALANCE_MAX</th>\n",
       "      <th>CC_AMT_BALANCE_MEAN</th>\n",
       "      <th>CC_AMT_BALANCE_SUM</th>\n",
       "      <th>CC_AMT_BALANCE_VAR</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_MIN</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_MAX</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_SUM</th>\n",
       "      <th>CC_AMT_CREDIT_LIMIT_ACTUAL_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_MIN</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_MAX</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_MEAN</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_SUM</th>\n",
       "      <th>CC_AMT_INST_MIN_REGULARITY_VAR</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_PAYMENT_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_MIN</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_MAX</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_MEAN</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_SUM</th>\n",
       "      <th>CC_AMT_PAYMENT_TOTAL_CURRENT_VAR</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_MIN</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_MAX</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_MEAN</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_SUM</th>\n",
       "      <th>CC_AMT_RECEIVABLE_PRINCIPAL_VAR</th>\n",
       "      <th>CC_AMT_RECIVABLE_MIN</th>\n",
       "      <th>CC_AMT_RECIVABLE_MAX</th>\n",
       "      <th>CC_AMT_RECIVABLE_MEAN</th>\n",
       "      <th>CC_AMT_RECIVABLE_SUM</th>\n",
       "      <th>CC_AMT_RECIVABLE_VAR</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_MIN</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_MAX</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_MEAN</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_SUM</th>\n",
       "      <th>CC_AMT_TOTAL_RECEIVABLE_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_ATM_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_OTHER_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MIN</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MAX</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_MEAN</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_SUM</th>\n",
       "      <th>CC_CNT_DRAWINGS_POS_CURRENT_VAR</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_MIN</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_MAX</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_MEAN</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_SUM</th>\n",
       "      <th>CC_CNT_INSTALMENT_MATURE_CUM_VAR</th>\n",
       "      <th>CC_SK_DPD_MIN</th>\n",
       "      <th>CC_SK_DPD_MAX</th>\n",
       "      <th>CC_SK_DPD_MEAN</th>\n",
       "      <th>CC_SK_DPD_SUM</th>\n",
       "      <th>CC_SK_DPD_VAR</th>\n",
       "      <th>CC_SK_DPD_DEF_MIN</th>\n",
       "      <th>CC_SK_DPD_DEF_MAX</th>\n",
       "      <th>CC_SK_DPD_DEF_MEAN</th>\n",
       "      <th>CC_SK_DPD_DEF_SUM</th>\n",
       "      <th>CC_SK_DPD_DEF_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_MODE</th>\n",
       "      <th>CC_COUNT</th>\n",
       "      <th>CC_UTILIZATION_MEAN</th>\n",
       "      <th>CC_UTILIZATION_SUM</th>\n",
       "      <th>CC_PAYMENT_RATIO</th>\n",
       "      <th>CC_MIN_PAY_REG_RATIO</th>\n",
       "      <th>CC_DRAWINGS_TO_LIMIT</th>\n",
       "      <th>CC_ATM_DRAW_SHARE</th>\n",
       "      <th>CC_POS_DRAW_SHARE</th>\n",
       "      <th>CC_ANY_DPD_FLAG</th>\n",
       "      <th>CC_RECENT_ACTIVITY_FLAG</th>\n",
       "      <th>POS_MONTHS_BALANCE_MIN</th>\n",
       "      <th>POS_MONTHS_BALANCE_MAX</th>\n",
       "      <th>POS_MONTHS_BALANCE_MEAN</th>\n",
       "      <th>POS_MONTHS_BALANCE_SIZE</th>\n",
       "      <th>POS_SK_DPD_MIN</th>\n",
       "      <th>POS_SK_DPD_MAX</th>\n",
       "      <th>POS_SK_DPD_MEAN</th>\n",
       "      <th>POS_SK_DPD_SUM</th>\n",
       "      <th>POS_SK_DPD_DEF_MAX</th>\n",
       "      <th>POS_SK_DPD_DEF_MEAN</th>\n",
       "      <th>POS_SK_DPD_DEF_SUM</th>\n",
       "      <th>POS_CNT_INSTALMENT_MIN</th>\n",
       "      <th>POS_CNT_INSTALMENT_MAX</th>\n",
       "      <th>POS_CNT_INSTALMENT_MEAN</th>\n",
       "      <th>POS_CNT_INSTALMENT_FUTURE_MIN</th>\n",
       "      <th>POS_CNT_INSTALMENT_FUTURE_MAX</th>\n",
       "      <th>POS_CNT_INSTALMENT_FUTURE_MEAN</th>\n",
       "      <th>POS_POS_IS_DPD_MEAN</th>\n",
       "      <th>POS_POS_IS_DPD_SUM</th>\n",
       "      <th>POS_POS_IS_DPD_UNDER_30_MEAN</th>\n",
       "      <th>POS_POS_IS_DPD_UNDER_30_SUM</th>\n",
       "      <th>POS_POS_IS_DPD_OVER_30_MEAN</th>\n",
       "      <th>POS_POS_IS_DPD_OVER_30_SUM</th>\n",
       "      <th>POS_POS_IS_DPD_OVER_120_MEAN</th>\n",
       "      <th>POS_POS_IS_DPD_OVER_120_SUM</th>\n",
       "      <th>POS_POS_IS_SEVERE_DPD_MEAN</th>\n",
       "      <th>POS_POS_IS_SEVERE_DPD_SUM</th>\n",
       "      <th>POS_INSTALMENT_PROGRESS_MIN</th>\n",
       "      <th>POS_INSTALMENT_PROGRESS_MAX</th>\n",
       "      <th>POS_INSTALMENT_PROGRESS_MEAN</th>\n",
       "      <th>POS_INSTALMENT_PROGRESS_SUM</th>\n",
       "      <th>POS_INSTALMENT_COMPLETION_RATIO_MIN</th>\n",
       "      <th>POS_INSTALMENT_COMPLETION_RATIO_MAX</th>\n",
       "      <th>POS_INSTALMENT_COMPLETION_RATIO_MEAN</th>\n",
       "      <th>POS_NAME_CONTRACT_STATUS_MODE</th>\n",
       "      <th>POS_COUNT</th>\n",
       "      <th>POS_ACTIVE_COUNT</th>\n",
       "      <th>POS_RECENT_SK_DPD_MAX</th>\n",
       "      <th>POS_RECENT_SK_DPD_MEAN</th>\n",
       "      <th>POS_RECENT_POS_IS_DPD_MEAN</th>\n",
       "      <th>POS_RECENT_POS_IS_DPD_SUM</th>\n",
       "      <th>POS_RECENT_POS_IS_DPD_OVER_30_MEAN</th>\n",
       "      <th>POS_RECENT_POS_IS_DPD_OVER_30_SUM</th>\n",
       "      <th>INSTAL_NUM_INSTALMENT_VERSION_NUNIQUE</th>\n",
       "      <th>INSTAL_DPD_MAX</th>\n",
       "      <th>INSTAL_DPD_MEAN</th>\n",
       "      <th>INSTAL_DPD_SUM</th>\n",
       "      <th>INSTAL_DBD_MAX</th>\n",
       "      <th>INSTAL_DBD_MEAN</th>\n",
       "      <th>INSTAL_DBD_SUM</th>\n",
       "      <th>INSTAL_PAYMENT_PERC_MIN</th>\n",
       "      <th>INSTAL_PAYMENT_PERC_MAX</th>\n",
       "      <th>INSTAL_PAYMENT_PERC_MEAN</th>\n",
       "      <th>INSTAL_PAYMENT_PERC_VAR</th>\n",
       "      <th>INSTAL_PAYMENT_DIFF_MAX</th>\n",
       "      <th>INSTAL_PAYMENT_DIFF_MEAN</th>\n",
       "      <th>INSTAL_PAYMENT_DIFF_SUM</th>\n",
       "      <th>INSTAL_PAYMENT_DIFF_VAR</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_MIN</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_MAX</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_SUM</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MIN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_DAYS_INSTALMENT_MAX</th>\n",
       "      <th>INSTAL_DAYS_INSTALMENT_MEAN</th>\n",
       "      <th>INSTAL_DAYS_INSTALMENT_SUM</th>\n",
       "      <th>INSTAL_INS_IS_DPD_MEAN</th>\n",
       "      <th>INSTAL_INS_IS_DPD_SUM</th>\n",
       "      <th>INSTAL_INS_IS_DPD_UNDER_30_MEAN</th>\n",
       "      <th>INSTAL_INS_IS_DPD_UNDER_30_SUM</th>\n",
       "      <th>INSTAL_INS_IS_DPD_OVER_30_MEAN</th>\n",
       "      <th>INSTAL_INS_IS_DPD_OVER_30_SUM</th>\n",
       "      <th>INSTAL_INS_IS_EARLY_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_INS_IS_EARLY_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_PAYMENT_CONSISTENCY_MIN</th>\n",
       "      <th>INSTAL_PAYMENT_CONSISTENCY_MAX</th>\n",
       "      <th>INSTAL_PAYMENT_CONSISTENCY_MEAN</th>\n",
       "      <th>INSTAL_COUNT</th>\n",
       "      <th>INSTAL_ACCOUNT_COUNT</th>\n",
       "      <th>INSTAL_RECENT_PAYMENT_PERC_MEAN</th>\n",
       "      <th>INSTAL_RECENT_PAYMENT_PERC_MIN</th>\n",
       "      <th>INSTAL_RECENT_DPD_MAX</th>\n",
       "      <th>INSTAL_RECENT_DPD_MEAN</th>\n",
       "      <th>INSTAL_RECENT_INS_IS_DPD_MEAN</th>\n",
       "      <th>INSTAL_RECENT_INS_IS_DPD_SUM</th>\n",
       "      <th>INSTAL_RECENT_INS_IS_EARLY_PAYMENT_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.000000</td>\n",
       "      <td>406597.500000</td>\n",
       "      <td>24700.500000</td>\n",
       "      <td>351000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637.000000</td>\n",
       "      <td>-3648.000000</td>\n",
       "      <td>-2120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.619200</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.634100</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.624300</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1134.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.073827</td>\n",
       "      <td>0.055314</td>\n",
       "      <td>0.125877</td>\n",
       "      <td>0.070563</td>\n",
       "      <td>0.115326</td>\n",
       "      <td>0.115326</td>\n",
       "      <td>0.115326</td>\n",
       "      <td>0.115326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>0.231424</td>\n",
       "      <td>0.088302</td>\n",
       "      <td>0.050297</td>\n",
       "      <td>0.062960</td>\n",
       "      <td>0.065978</td>\n",
       "      <td>0.067363</td>\n",
       "      <td>0.067847</td>\n",
       "      <td>0.068004</td>\n",
       "      <td>0.069859</td>\n",
       "      <td>0.071795</td>\n",
       "      <td>0.072461</td>\n",
       "      <td>0.169680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.407448</td>\n",
       "      <td>0.408973</td>\n",
       "      <td>0.408531</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.407448</td>\n",
       "      <td>0.408179</td>\n",
       "      <td>0.408627</td>\n",
       "      <td>0.408627</td>\n",
       "      <td>0.408627</td>\n",
       "      <td>0.408917</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.408973</td>\n",
       "      <td>0.242670</td>\n",
       "      <td>0.242670</td>\n",
       "      <td>0.242670</td>\n",
       "      <td>0.242670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>35.406710</td>\n",
       "      <td>0.293229</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.498036</td>\n",
       "      <td>202500.000000</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>204097.500000</td>\n",
       "      <td>16.461104</td>\n",
       "      <td>202500.000000</td>\n",
       "      <td>1.158397</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.218500</td>\n",
       "      <td>12.915581</td>\n",
       "      <td>128992500.000000</td>\n",
       "      <td>406597.500000</td>\n",
       "      <td>406597.500000</td>\n",
       "      <td>-1437.000000</td>\n",
       "      <td>-103.000000</td>\n",
       "      <td>-874.000000</td>\n",
       "      <td>186150.000000</td>\n",
       "      <td>-1042.500000</td>\n",
       "      <td>-1072.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>-349.000000</td>\n",
       "      <td>589042.400000</td>\n",
       "      <td>-424.500000</td>\n",
       "      <td>-499.875000</td>\n",
       "      <td>-1185.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>268865.553571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1681.029000</td>\n",
       "      <td>5043.645000</td>\n",
       "      <td>8405.145000</td>\n",
       "      <td>5584935.910455</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>108131.945625</td>\n",
       "      <td>865055.565000</td>\n",
       "      <td>21338068480.082222</td>\n",
       "      <td>54130.500000</td>\n",
       "      <td>245781.000000</td>\n",
       "      <td>49156.200000</td>\n",
       "      <td>245781.000000</td>\n",
       "      <td>12081659992.199999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7997.141250</td>\n",
       "      <td>31988.565000</td>\n",
       "      <td>31988.565000</td>\n",
       "      <td>255817072.689806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1042.000000</td>\n",
       "      <td>-103.000000</td>\n",
       "      <td>-572.500000</td>\n",
       "      <td>440860.500000</td>\n",
       "      <td>-572.500000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>-15.500000</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>144.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>240994.282500</td>\n",
       "      <td>481988.565000</td>\n",
       "      <td>87366779895.379608</td>\n",
       "      <td>240994.282500</td>\n",
       "      <td>245781.000000</td>\n",
       "      <td>122890.500000</td>\n",
       "      <td>245781.000000</td>\n",
       "      <td>30204149980.500000</td>\n",
       "      <td>122890.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15994.282500</td>\n",
       "      <td>31988.565000</td>\n",
       "      <td>31988.565000</td>\n",
       "      <td>511634145.379612</td>\n",
       "      <td>15994.282500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1437.000000</td>\n",
       "      <td>-476.000000</td>\n",
       "      <td>-974.500000</td>\n",
       "      <td>123956.700000</td>\n",
       "      <td>-1082.000000</td>\n",
       "      <td>-1072.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>-574.800000</td>\n",
       "      <td>353910.700000</td>\n",
       "      <td>-911.000000</td>\n",
       "      <td>-661.333333</td>\n",
       "      <td>-1185.000000</td>\n",
       "      <td>-34.000000</td>\n",
       "      <td>251252.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2091.161250</td>\n",
       "      <td>5043.645000</td>\n",
       "      <td>8364.645000</td>\n",
       "      <td>6325191.464006</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>63844.500000</td>\n",
       "      <td>383067.000000</td>\n",
       "      <td>2985326261.100000</td>\n",
       "      <td>54130.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284122</td>\n",
       "      <td>7.683402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.509931</td>\n",
       "      <td>7.683402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>20.421053</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9251.775000</td>\n",
       "      <td>53093.745000</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695000</td>\n",
       "      <td>9251.775000</td>\n",
       "      <td>53093.745000</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695000</td>\n",
       "      <td>-49.000000</td>\n",
       "      <td>-315.421053</td>\n",
       "      <td>-5993.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-295.000000</td>\n",
       "      <td>-5605.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>1293502.500000</td>\n",
       "      <td>35698.500000</td>\n",
       "      <td>1129500.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188.000000</td>\n",
       "      <td>-1186.000000</td>\n",
       "      <td>-291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>0.798700</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-828.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066107</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.058203</td>\n",
       "      <td>0.071608</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.042031</td>\n",
       "      <td>0.038881</td>\n",
       "      <td>0.034235</td>\n",
       "      <td>0.052976</td>\n",
       "      <td>0.018740</td>\n",
       "      <td>0.041079</td>\n",
       "      <td>0.085932</td>\n",
       "      <td>0.056199</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.044155</td>\n",
       "      <td>0.047996</td>\n",
       "      <td>0.049825</td>\n",
       "      <td>0.062692</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>0.063837</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.065294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.407562</td>\n",
       "      <td>0.409480</td>\n",
       "      <td>0.408266</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.407562</td>\n",
       "      <td>0.407585</td>\n",
       "      <td>0.407585</td>\n",
       "      <td>0.407585</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408524</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408963</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>0.029498</td>\n",
       "      <td>0.044649</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>59.992584</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.208736</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>0.132217</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>1023502.500000</td>\n",
       "      <td>36.234085</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>1.145199</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.506181</td>\n",
       "      <td>14.072865</td>\n",
       "      <td>320760000.000000</td>\n",
       "      <td>2587005.000000</td>\n",
       "      <td>1293502.500000</td>\n",
       "      <td>-2586.000000</td>\n",
       "      <td>-606.000000</td>\n",
       "      <td>-1400.750000</td>\n",
       "      <td>827783.583333</td>\n",
       "      <td>-1205.500000</td>\n",
       "      <td>-2434.000000</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>-544.500000</td>\n",
       "      <td>2228363.666667</td>\n",
       "      <td>-480.000000</td>\n",
       "      <td>-816.000000</td>\n",
       "      <td>-2131.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>824562.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>254350.125000</td>\n",
       "      <td>1017400.500000</td>\n",
       "      <td>138584554970.062500</td>\n",
       "      <td>92576.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202500.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>164025000000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-606.000000</td>\n",
       "      <td>-606.000000</td>\n",
       "      <td>-606.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-606.000000</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>810000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2586.000000</td>\n",
       "      <td>-775.000000</td>\n",
       "      <td>-1665.666667</td>\n",
       "      <td>820590.333333</td>\n",
       "      <td>-1636.000000</td>\n",
       "      <td>-2434.000000</td>\n",
       "      <td>-420.000000</td>\n",
       "      <td>-1131.333333</td>\n",
       "      <td>1276305.333333</td>\n",
       "      <td>-540.000000</td>\n",
       "      <td>-1073.666667</td>\n",
       "      <td>-2131.000000</td>\n",
       "      <td>-540.000000</td>\n",
       "      <td>838490.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>69133.500000</td>\n",
       "      <td>207400.500000</td>\n",
       "      <td>2045643396.750000</td>\n",
       "      <td>72652.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>606.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>-43.785714</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.107143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.321429</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6662.970000</td>\n",
       "      <td>560835.360000</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650000</td>\n",
       "      <td>6662.970000</td>\n",
       "      <td>560835.360000</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650000</td>\n",
       "      <td>-544.000000</td>\n",
       "      <td>-1385.320000</td>\n",
       "      <td>-34633.000000</td>\n",
       "      <td>-536.000000</td>\n",
       "      <td>-1378.160000</td>\n",
       "      <td>-34454.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.000000</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225.000000</td>\n",
       "      <td>-4260.000000</td>\n",
       "      <td>-2531</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-815.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055627</td>\n",
       "      <td>0.055627</td>\n",
       "      <td>0.055240</td>\n",
       "      <td>0.056014</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.100814</td>\n",
       "      <td>0.100814</td>\n",
       "      <td>0.100814</td>\n",
       "      <td>0.100814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080846</td>\n",
       "      <td>0.083812</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.081405</td>\n",
       "      <td>0.081963</td>\n",
       "      <td>0.082522</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.083639</td>\n",
       "      <td>0.083674</td>\n",
       "      <td>0.083708</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.083777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.409048</td>\n",
       "      <td>0.408648</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.408568</td>\n",
       "      <td>0.408728</td>\n",
       "      <td>0.408888</td>\n",
       "      <td>0.087997</td>\n",
       "      <td>0.087997</td>\n",
       "      <td>0.087997</td>\n",
       "      <td>0.087997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063182</td>\n",
       "      <td>39.938152</td>\n",
       "      <td>0.220374</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>67500.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>67500.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>67500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498267</td>\n",
       "      <td>0</td>\n",
       "      <td>11.119898</td>\n",
       "      <td>11.813037</td>\n",
       "      <td>15187500.000000</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>-1326.000000</td>\n",
       "      <td>-408.000000</td>\n",
       "      <td>-867.000000</td>\n",
       "      <td>421362.000000</td>\n",
       "      <td>-867.000000</td>\n",
       "      <td>-595.000000</td>\n",
       "      <td>-382.000000</td>\n",
       "      <td>-488.500000</td>\n",
       "      <td>22684.500000</td>\n",
       "      <td>-488.500000</td>\n",
       "      <td>-532.000000</td>\n",
       "      <td>-682.000000</td>\n",
       "      <td>-382.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94537.800000</td>\n",
       "      <td>94518.900000</td>\n",
       "      <td>189037.800000</td>\n",
       "      <td>714.420000</td>\n",
       "      <td>94518.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1326.000000</td>\n",
       "      <td>-408.000000</td>\n",
       "      <td>-867.000000</td>\n",
       "      <td>421362.000000</td>\n",
       "      <td>-867.000000</td>\n",
       "      <td>-595.000000</td>\n",
       "      <td>-382.000000</td>\n",
       "      <td>-488.500000</td>\n",
       "      <td>22684.500000</td>\n",
       "      <td>-488.500000</td>\n",
       "      <td>-532.000000</td>\n",
       "      <td>-682.000000</td>\n",
       "      <td>-382.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94537.800000</td>\n",
       "      <td>94518.900000</td>\n",
       "      <td>189037.800000</td>\n",
       "      <td>714.420000</td>\n",
       "      <td>94518.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-25.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5357.250000</td>\n",
       "      <td>10573.965000</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465000</td>\n",
       "      <td>5357.250000</td>\n",
       "      <td>10573.965000</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465000</td>\n",
       "      <td>-727.000000</td>\n",
       "      <td>-761.666667</td>\n",
       "      <td>-2285.000000</td>\n",
       "      <td>-724.000000</td>\n",
       "      <td>-754.000000</td>\n",
       "      <td>-2262.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>312682.500000</td>\n",
       "      <td>29686.500000</td>\n",
       "      <td>297000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039.000000</td>\n",
       "      <td>-9833.000000</td>\n",
       "      <td>-2437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-617.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.085832</td>\n",
       "      <td>0.084895</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.136436</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.062860</td>\n",
       "      <td>0.091372</td>\n",
       "      <td>0.079552</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.069728</td>\n",
       "      <td>0.073627</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.075424</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.083440</td>\n",
       "      <td>0.084575</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.089776</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.048022</td>\n",
       "      <td>0.046657</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.046559</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.047413</td>\n",
       "      <td>0.047717</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.416247</td>\n",
       "      <td>0.409406</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.409480</td>\n",
       "      <td>0.409570</td>\n",
       "      <td>0.085381</td>\n",
       "      <td>0.084566</td>\n",
       "      <td>0.050775</td>\n",
       "      <td>0.133477</td>\n",
       "      <td>0.082702</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>11.939259</td>\n",
       "      <td>0.136568</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.159905</td>\n",
       "      <td>0.431748</td>\n",
       "      <td>67500.000000</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>177682.500000</td>\n",
       "      <td>10.532818</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>1.052803</td>\n",
       "      <td>0.159905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.813037</td>\n",
       "      <td>12.652947</td>\n",
       "      <td>410265000.000000</td>\n",
       "      <td>625365.000000</td>\n",
       "      <td>312682.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>1620000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-9.619048</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2482.920000</td>\n",
       "      <td>691786.890000</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415000</td>\n",
       "      <td>2482.920000</td>\n",
       "      <td>691786.890000</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-271.625000</td>\n",
       "      <td>-4346.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>-252.250000</td>\n",
       "      <td>-4036.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>513000.000000</td>\n",
       "      <td>21865.500000</td>\n",
       "      <td>513000.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038.000000</td>\n",
       "      <td>-4311.000000</td>\n",
       "      <td>-3458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1106.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065581</td>\n",
       "      <td>0.065581</td>\n",
       "      <td>0.065581</td>\n",
       "      <td>0.065581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090374</td>\n",
       "      <td>0.086043</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>0.148522</td>\n",
       "      <td>0.096024</td>\n",
       "      <td>0.059070</td>\n",
       "      <td>0.105224</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.067455</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>0.078387</td>\n",
       "      <td>0.081660</td>\n",
       "      <td>0.082955</td>\n",
       "      <td>0.085789</td>\n",
       "      <td>0.091488</td>\n",
       "      <td>0.094914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.408992</td>\n",
       "      <td>0.408312</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.407336</td>\n",
       "      <td>0.407712</td>\n",
       "      <td>0.408084</td>\n",
       "      <td>0.408084</td>\n",
       "      <td>0.408566</td>\n",
       "      <td>0.408627</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.408935</td>\n",
       "      <td>0.085461</td>\n",
       "      <td>0.083017</td>\n",
       "      <td>0.050695</td>\n",
       "      <td>0.138102</td>\n",
       "      <td>0.087407</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>36.393482</td>\n",
       "      <td>0.156790</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>391500.000000</td>\n",
       "      <td>23.461618</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11.707678</td>\n",
       "      <td>13.148033</td>\n",
       "      <td>369117000.000000</td>\n",
       "      <td>513000.000000</td>\n",
       "      <td>513000.000000</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1149.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>-783.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-33.636364</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>8.969697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.442439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.590909</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.043995</td>\n",
       "      <td>22655.655000</td>\n",
       "      <td>452.384318</td>\n",
       "      <td>29857.365000</td>\n",
       "      <td>8084829.772595</td>\n",
       "      <td>1821.780000</td>\n",
       "      <td>22678.785000</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>835985.340000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>22678.785000</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>806127.975000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-1032.242424</td>\n",
       "      <td>-68128.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-1028.606061</td>\n",
       "      <td>-67888.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.883609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961271</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR   TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "0      100002 1.000000                   0            0             0   \n",
       "1      100003 0.000000                   0            1             0   \n",
       "2      100004 0.000000                   1            0             1   \n",
       "3      100006 0.000000                   0            1             0   \n",
       "4      100007 0.000000                   0            0             0   \n",
       "\n",
       "   FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL     AMT_CREDIT  \\\n",
       "0                0             0     202500.000000  406597.500000   \n",
       "1                1             0     270000.000000 1293502.500000   \n",
       "2                0             0      67500.000000  135000.000000   \n",
       "3                0             0     135000.000000  312682.500000   \n",
       "4                0             0     121500.000000  513000.000000   \n",
       "\n",
       "   AMT_ANNUITY  AMT_GOODS_PRICE  NAME_TYPE_SUITE  NAME_INCOME_TYPE  \\\n",
       "0 24700.500000    351000.000000                6                 7   \n",
       "1 35698.500000   1129500.000000                1                 4   \n",
       "2  6750.000000    135000.000000                6                 7   \n",
       "3 29686.500000    297000.000000                6                 7   \n",
       "4 21865.500000    513000.000000                6                 7   \n",
       "\n",
       "   NAME_EDUCATION_TYPE  NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
       "0                    4                   3                  1   \n",
       "1                    1                   1                  1   \n",
       "2                    4                   3                  1   \n",
       "3                    4                   0                  1   \n",
       "4                    4                   3                  1   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                    0.018801       -9461    -637.000000       -3648.000000   \n",
       "1                    0.003541      -16765   -1188.000000       -1186.000000   \n",
       "2                    0.010032      -19046    -225.000000       -4260.000000   \n",
       "3                    0.008019      -19005   -3039.000000       -9833.000000   \n",
       "4                    0.028663      -19932   -3038.000000       -4311.000000   \n",
       "\n",
       "   DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  \\\n",
       "0            -2120          NaN           1               1                0   \n",
       "1             -291          NaN           1               1                0   \n",
       "2            -2531    26.000000           1               1                1   \n",
       "3            -2437          NaN           1               1                0   \n",
       "4            -3458          NaN           1               1                0   \n",
       "\n",
       "   FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL  OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
       "0                 1           1           0                8         1.000000   \n",
       "1                 1           1           0                3         2.000000   \n",
       "2                 1           1           0                8         1.000000   \n",
       "3                 1           0           0                8         2.000000   \n",
       "4                 1           0           0                3         1.000000   \n",
       "\n",
       "   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
       "0                     2                            2   \n",
       "1                     1                            1   \n",
       "2                     2                            2   \n",
       "3                     2                            2   \n",
       "4                     2                            2   \n",
       "\n",
       "   WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
       "0                           6                       10   \n",
       "1                           1                       11   \n",
       "2                           1                        9   \n",
       "3                           6                       17   \n",
       "4                           4                       11   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "4                            0                       0   \n",
       "\n",
       "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY  ORGANIZATION_TYPE  \\\n",
       "0                       0                        0                  5   \n",
       "1                       0                        0                 39   \n",
       "2                       0                        0                 11   \n",
       "3                       0                        0                  5   \n",
       "4                       1                        1                 37   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
       "0      0.083037      0.262949      0.139376        0.024700          0.036900   \n",
       "1      0.311267      0.622246           NaN        0.095900          0.052900   \n",
       "2           NaN      0.555912      0.729567             NaN               NaN   \n",
       "3           NaN      0.650442           NaN             NaN               NaN   \n",
       "4           NaN      0.322738           NaN             NaN               NaN   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
       "0                     0.972200         0.619200        0.014300   \n",
       "1                     0.985100         0.796000        0.060500   \n",
       "2                          NaN              NaN             NaN   \n",
       "3                          NaN              NaN             NaN   \n",
       "4                          NaN              NaN             NaN   \n",
       "\n",
       "   ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  \\\n",
       "0       0.000000       0.069000       0.083300       0.125000      0.036900   \n",
       "1       0.080000       0.034500       0.291700       0.333300      0.013000   \n",
       "2            NaN            NaN            NaN            NaN           NaN   \n",
       "3            NaN            NaN            NaN            NaN           NaN   \n",
       "4            NaN            NaN            NaN            NaN           NaN   \n",
       "\n",
       "   LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  \\\n",
       "0              0.020200        0.019000                 0.000000   \n",
       "1              0.077300        0.054900                 0.003900   \n",
       "2                   NaN             NaN                      NaN   \n",
       "3                   NaN             NaN                      NaN   \n",
       "4                   NaN             NaN                      NaN   \n",
       "\n",
       "   NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  \\\n",
       "0           0.000000         0.025200           0.038300   \n",
       "1           0.009800         0.092400           0.053800   \n",
       "2                NaN              NaN                NaN   \n",
       "3                NaN              NaN                NaN   \n",
       "4                NaN              NaN                NaN   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  \\\n",
       "0                      0.972200          0.634100         0.014400   \n",
       "1                      0.985100          0.804000         0.049700   \n",
       "2                           NaN               NaN              NaN   \n",
       "3                           NaN               NaN              NaN   \n",
       "4                           NaN               NaN              NaN   \n",
       "\n",
       "   ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  \\\n",
       "0        0.000000        0.069000        0.083300        0.125000   \n",
       "1        0.080600        0.034500        0.291700        0.333300   \n",
       "2             NaN             NaN             NaN             NaN   \n",
       "3             NaN             NaN             NaN             NaN   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  \\\n",
       "0       0.037700               0.022000         0.019800   \n",
       "1       0.012800               0.079000         0.055400   \n",
       "2            NaN                    NaN              NaN   \n",
       "3            NaN                    NaN              NaN   \n",
       "4            NaN                    NaN              NaN   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  \\\n",
       "0                  0.000000            0.000000         0.025000   \n",
       "1                  0.000000            0.000000         0.096800   \n",
       "2                       NaN                 NaN              NaN   \n",
       "3                       NaN                 NaN              NaN   \n",
       "4                       NaN                 NaN              NaN   \n",
       "\n",
       "   BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  \\\n",
       "0           0.036900                      0.972200          0.624300   \n",
       "1           0.052900                      0.985100          0.798700   \n",
       "2                NaN                           NaN               NaN   \n",
       "3                NaN                           NaN               NaN   \n",
       "4                NaN                           NaN               NaN   \n",
       "\n",
       "   COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  \\\n",
       "0         0.014400        0.000000        0.069000        0.083300   \n",
       "1         0.060800        0.080000        0.034500        0.291700   \n",
       "2              NaN             NaN             NaN             NaN   \n",
       "3              NaN             NaN             NaN             NaN   \n",
       "4              NaN             NaN             NaN             NaN   \n",
       "\n",
       "   FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
       "0        0.125000       0.037500               0.020500         0.019300   \n",
       "1        0.333300       0.013200               0.078700         0.055800   \n",
       "2             NaN            NaN                    NaN              NaN   \n",
       "3             NaN            NaN                    NaN              NaN   \n",
       "4             NaN            NaN                    NaN              NaN   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI  FONDKAPREMONT_MODE  \\\n",
       "0                  0.000000            0.000000                   3   \n",
       "1                  0.003900            0.010000                   3   \n",
       "2                       NaN                 NaN                   0   \n",
       "3                       NaN                 NaN                   0   \n",
       "4                       NaN                 NaN                   0   \n",
       "\n",
       "   HOUSETYPE_MODE  TOTALAREA_MODE  WALLSMATERIAL_MODE  EMERGENCYSTATE_MODE  \\\n",
       "0               0        0.014900                   5                    0   \n",
       "1               0        0.071400                   0                    0   \n",
       "2               1             NaN                   7                    2   \n",
       "3               1             NaN                   7                    2   \n",
       "4               1             NaN                   7                    2   \n",
       "\n",
       "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0                  2.000000                  2.000000   \n",
       "1                  1.000000                  0.000000   \n",
       "2                  0.000000                  0.000000   \n",
       "3                  2.000000                  0.000000   \n",
       "4                  0.000000                  0.000000   \n",
       "\n",
       "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0                  2.000000                  2.000000            -1134.000000   \n",
       "1                  1.000000                  0.000000             -828.000000   \n",
       "2                  0.000000                  0.000000             -815.000000   \n",
       "3                  2.000000                  0.000000             -617.000000   \n",
       "4                  0.000000                  0.000000            -1106.000000   \n",
       "\n",
       "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                1                0   \n",
       "\n",
       "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                    0.000000                   0.000000   \n",
       "1                    0.000000                   0.000000   \n",
       "2                    0.000000                   0.000000   \n",
       "3                         NaN                        NaN   \n",
       "4                    0.000000                   0.000000   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                    0.000000                   0.000000   \n",
       "1                    0.000000                   0.000000   \n",
       "2                    0.000000                   0.000000   \n",
       "3                         NaN                        NaN   \n",
       "4                    0.000000                   0.000000   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
       "0                   0.000000                    1.000000   \n",
       "1                   0.000000                    0.000000   \n",
       "2                   0.000000                    0.000000   \n",
       "3                        NaN                         NaN   \n",
       "4                   0.000000                    0.000000   \n",
       "\n",
       "   buro_preds_TARGET_mean  buro_preds_TARGET_median  buro_preds_TARGET_min  \\\n",
       "0                0.083333                  0.073827               0.055314   \n",
       "1                0.066107                  0.067309               0.058203   \n",
       "2                0.055627                  0.055627               0.055240   \n",
       "3                     NaN                       NaN                    NaN   \n",
       "4                0.065581                  0.065581               0.065581   \n",
       "\n",
       "   buro_preds_TARGET_max  buro_preds_TARGET_dispersion  \\\n",
       "0               0.125877                      0.070563   \n",
       "1               0.071608                      0.013406   \n",
       "2               0.056014                      0.000774   \n",
       "3                    NaN                           NaN   \n",
       "4               0.065581                      0.000000   \n",
       "\n",
       "   prapp_preds_TARGET_mean  prapp_preds_TARGET_median  prapp_preds_TARGET_min  \\\n",
       "0                 0.115326                   0.115326                0.115326   \n",
       "1                 0.042031                   0.038881                0.034235   \n",
       "2                 0.100814                   0.100814                0.100814   \n",
       "3                 0.085832                   0.084895                0.051335   \n",
       "4                 0.090374                   0.086043                0.052497   \n",
       "\n",
       "   prapp_preds_TARGET_max  prapp_preds_TARGET_dispersion  \\\n",
       "0                0.115326                       0.000000   \n",
       "1                0.052976                       0.018740   \n",
       "2                0.100814                       0.000000   \n",
       "3                0.136436                       0.085100   \n",
       "4                0.148522                       0.096024   \n",
       "\n",
       "   ip_preds_TARGET_amin  ip_preds_TARGET_amax  ip_preds_TARGET_mean  \\\n",
       "0              0.060329              0.231424              0.088302   \n",
       "1              0.041079              0.085932              0.056199   \n",
       "2              0.080846              0.083812              0.082766   \n",
       "3              0.062860              0.091372              0.079552   \n",
       "4              0.059070              0.105224              0.080302   \n",
       "\n",
       "   ip_preds_TARGET_std  ip_preds_TARGET_percentile_10  \\\n",
       "0             0.050297                       0.062960   \n",
       "1             0.011464                       0.042248   \n",
       "2             0.001665                       0.081405   \n",
       "3             0.008527                       0.069728   \n",
       "4             0.011544                       0.064196   \n",
       "\n",
       "   ip_preds_TARGET_percentile_20  ip_preds_TARGET_percentile_30  \\\n",
       "0                       0.065978                       0.067363   \n",
       "1                       0.044155                       0.047996   \n",
       "2                       0.081963                       0.082522   \n",
       "3                       0.073627                       0.075202   \n",
       "4                       0.067455                       0.073097   \n",
       "\n",
       "   ip_preds_TARGET_percentile_40  ip_preds_TARGET_percentile_50  \\\n",
       "0                       0.067847                       0.068004   \n",
       "1                       0.049825                       0.062692   \n",
       "2                       0.083081                       0.083639   \n",
       "3                       0.075424                       0.078943   \n",
       "4                       0.078387                       0.081660   \n",
       "\n",
       "   ip_preds_TARGET_percentile_60  ip_preds_TARGET_percentile_70  \\\n",
       "0                       0.069859                       0.071795   \n",
       "1                       0.063324                       0.063837   \n",
       "2                       0.083674                       0.083708   \n",
       "3                       0.083440                       0.084575   \n",
       "4                       0.082955                       0.085789   \n",
       "\n",
       "   ip_preds_TARGET_percentile_80  ip_preds_TARGET_percentile_90  \\\n",
       "0                       0.072461                       0.169680   \n",
       "1                       0.064803                       0.065294   \n",
       "2                       0.083743                       0.083777   \n",
       "3                       0.089665                       0.089776   \n",
       "4                       0.091488                       0.094914   \n",
       "\n",
       "   cc_bal_preds_TARGET_amin  cc_bal_preds_TARGET_amax  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       NaN                       NaN   \n",
       "3                  0.045984                  0.048022   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   cc_bal_preds_TARGET_mean  cc_bal_preds_TARGET_std  \\\n",
       "0                       NaN                      NaN   \n",
       "1                       NaN                      NaN   \n",
       "2                       NaN                      NaN   \n",
       "3                  0.046657                 0.000872   \n",
       "4                       NaN                      NaN   \n",
       "\n",
       "   cc_bal_preds_TARGET_percentile_10  cc_bal_preds_TARGET_percentile_20  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                           0.045984                           0.045984   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   cc_bal_preds_TARGET_percentile_30  cc_bal_preds_TARGET_percentile_40  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                           0.045984                           0.045984   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   cc_bal_preds_TARGET_percentile_50  cc_bal_preds_TARGET_percentile_60  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                           0.046271                           0.046559   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   cc_bal_preds_TARGET_percentile_70  cc_bal_preds_TARGET_percentile_80  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                           0.046986                           0.047413   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   cc_bal_preds_TARGET_percentile_90  pos_bal_preds_TARGET_amin  \\\n",
       "0                                NaN                   0.407448   \n",
       "1                                NaN                   0.407562   \n",
       "2                                NaN                   0.408515   \n",
       "3                           0.047717                   0.408741   \n",
       "4                                NaN                   0.407313   \n",
       "\n",
       "   pos_bal_preds_TARGET_amax  pos_bal_preds_TARGET_mean  \\\n",
       "0                   0.408973                   0.408531   \n",
       "1                   0.409480                   0.408266   \n",
       "2                   0.409048                   0.408648   \n",
       "3                   0.416247                   0.409406   \n",
       "4                   0.408992                   0.408312   \n",
       "\n",
       "   pos_bal_preds_TARGET_std  pos_bal_preds_TARGET_percentile_10  \\\n",
       "0                  0.000574                            0.407448   \n",
       "1                  0.000666                            0.407562   \n",
       "2                  0.000267                            0.408515   \n",
       "3                  0.001740                            0.408741   \n",
       "4                  0.000561                            0.407336   \n",
       "\n",
       "   pos_bal_preds_TARGET_percentile_20  pos_bal_preds_TARGET_percentile_30  \\\n",
       "0                            0.408179                            0.408627   \n",
       "1                            0.407585                            0.407585   \n",
       "2                            0.408515                            0.408515   \n",
       "3                            0.408741                            0.408741   \n",
       "4                            0.407712                            0.408084   \n",
       "\n",
       "   pos_bal_preds_TARGET_percentile_40  pos_bal_preds_TARGET_percentile_50  \\\n",
       "0                            0.408627                            0.408627   \n",
       "1                            0.407585                            0.408515   \n",
       "2                            0.408515                            0.408515   \n",
       "3                            0.408741                            0.408741   \n",
       "4                            0.408084                            0.408566   \n",
       "\n",
       "   pos_bal_preds_TARGET_percentile_60  pos_bal_preds_TARGET_percentile_70  \\\n",
       "0                            0.408917                            0.408935   \n",
       "1                            0.408524                            0.408696   \n",
       "2                            0.408515                            0.408568   \n",
       "3                            0.408741                            0.408741   \n",
       "4                            0.408627                            0.408741   \n",
       "\n",
       "   pos_bal_preds_TARGET_percentile_80  pos_bal_preds_TARGET_percentile_90  \\\n",
       "0                            0.408935                            0.408973   \n",
       "1                            0.408741                            0.408963   \n",
       "2                            0.408728                            0.408888   \n",
       "3                            0.409480                            0.409570   \n",
       "4                            0.408741                            0.408935   \n",
       "\n",
       "   prapp_preds_TARGET_mean.1  prapp_preds_TARGET_median.1  \\\n",
       "0                   0.242670                     0.242670   \n",
       "1                   0.036519                     0.035411   \n",
       "2                   0.087997                     0.087997   \n",
       "3                   0.085381                     0.084566   \n",
       "4                   0.085461                     0.083017   \n",
       "\n",
       "   prapp_preds_TARGET_min.1  prapp_preds_TARGET_max.1  \\\n",
       "0                  0.242670                  0.242670   \n",
       "1                  0.029498                  0.044649   \n",
       "2                  0.087997                  0.087997   \n",
       "3                  0.050775                  0.133477   \n",
       "4                  0.050695                  0.138102   \n",
       "\n",
       "   prapp_preds_TARGET_dispersion.1  nn_oof_single_past  predicted_cnt  \\\n",
       "0                         0.000000            0.062069      35.406710   \n",
       "1                         0.015151            0.026292      59.992584   \n",
       "2                         0.000000            0.063182      39.938152   \n",
       "3                         0.082702            0.036214      11.939259   \n",
       "4                         0.087407            0.032584      36.393482   \n",
       "\n",
       "   predicted_ir   cnt_cut  DAYS_EMPLOYED_PERC  INCOME_CREDIT_PERC  \\\n",
       "0      0.293229 36.000000            0.067329            0.498036   \n",
       "1      0.105881 60.000000            0.070862            0.208736   \n",
       "2      0.220374 42.000000            0.011814            0.500000   \n",
       "3      0.136568 12.000000            0.159905            0.431748   \n",
       "4      0.156790 36.000000            0.152418            0.236842   \n",
       "\n",
       "   INCOME_PER_PERSON  ANNUITY_INCOME_PERC  PAYMENT_RATE  CREDIT_INCOME_DIFF  \\\n",
       "0      202500.000000             0.121978      0.060749       204097.500000   \n",
       "1      135000.000000             0.132217      0.027598      1023502.500000   \n",
       "2       67500.000000             0.100000      0.050000        67500.000000   \n",
       "3       67500.000000             0.219900      0.094941       177682.500000   \n",
       "4      121500.000000             0.179963      0.042623       391500.000000   \n",
       "\n",
       "   CREDIT_TERM  INCOME_PER_CHILD  CREDIT_GOODS_PERC  EMPLOY_TO_AGE_RATIO  \\\n",
       "0    16.461104     202500.000000           1.158397             0.067329   \n",
       "1    36.234085     270000.000000           1.145199             0.070862   \n",
       "2    20.000000      67500.000000           1.000000             0.011814   \n",
       "3    10.532818     135000.000000           1.052803             0.159905   \n",
       "4    23.461618     121500.000000           1.000000             0.152418   \n",
       "\n",
       "   CHILDREN_RATIO  CAR_AGE_RATIO  REALTY_AND_CAR_FLAG  LOG_INCOME  LOG_CREDIT  \\\n",
       "0        0.000000            NaN                    0   12.218500   12.915581   \n",
       "1        0.000000            NaN                    0   12.506181   14.072865   \n",
       "2        0.000000       0.498267                    0   11.119898   11.813037   \n",
       "3        0.000000            NaN                    0   11.813037   12.652947   \n",
       "4        0.000000            NaN                    0   11.707678   13.148033   \n",
       "\n",
       "   INCOME_X_EMPLOY  CREDIT_X_FAMILY  CREDIT_PER_CHILD  BURO_DAYS_CREDIT_MIN  \\\n",
       "0 128992500.000000    406597.500000     406597.500000          -1437.000000   \n",
       "1 320760000.000000   2587005.000000    1293502.500000          -2586.000000   \n",
       "2  15187500.000000    135000.000000     135000.000000          -1326.000000   \n",
       "3 410265000.000000    625365.000000     312682.500000                   NaN   \n",
       "4 369117000.000000    513000.000000     513000.000000          -1149.000000   \n",
       "\n",
       "   BURO_DAYS_CREDIT_MAX  BURO_DAYS_CREDIT_MEAN  BURO_DAYS_CREDIT_VAR  \\\n",
       "0           -103.000000            -874.000000         186150.000000   \n",
       "1           -606.000000           -1400.750000         827783.583333   \n",
       "2           -408.000000            -867.000000         421362.000000   \n",
       "3                   NaN                    NaN                   NaN   \n",
       "4          -1149.000000           -1149.000000                   NaN   \n",
       "\n",
       "   BURO_DAYS_CREDIT_MEDIAN  BURO_DAYS_CREDIT_ENDDATE_MIN  \\\n",
       "0             -1042.500000                  -1072.000000   \n",
       "1             -1205.500000                  -2434.000000   \n",
       "2              -867.000000                   -595.000000   \n",
       "3                      NaN                           NaN   \n",
       "4             -1149.000000                   -783.000000   \n",
       "\n",
       "   BURO_DAYS_CREDIT_ENDDATE_MAX  BURO_DAYS_CREDIT_ENDDATE_MEAN  \\\n",
       "0                    780.000000                    -349.000000   \n",
       "1                   1216.000000                    -544.500000   \n",
       "2                   -382.000000                    -488.500000   \n",
       "3                           NaN                            NaN   \n",
       "4                   -783.000000                    -783.000000   \n",
       "\n",
       "   BURO_DAYS_CREDIT_ENDDATE_VAR  BURO_DAYS_CREDIT_ENDDATE_MEDIAN  \\\n",
       "0                 589042.400000                      -424.500000   \n",
       "1                2228363.666667                      -480.000000   \n",
       "2                  22684.500000                      -488.500000   \n",
       "3                           NaN                              NaN   \n",
       "4                           NaN                      -783.000000   \n",
       "\n",
       "   BURO_DAYS_CREDIT_UPDATE_MEAN  BURO_DAYS_CREDIT_UPDATE_MIN  \\\n",
       "0                   -499.875000                 -1185.000000   \n",
       "1                   -816.000000                 -2131.000000   \n",
       "2                   -532.000000                  -682.000000   \n",
       "3                           NaN                          NaN   \n",
       "4                   -783.000000                  -783.000000   \n",
       "\n",
       "   BURO_DAYS_CREDIT_UPDATE_MAX  BURO_DAYS_CREDIT_UPDATE_VAR  \\\n",
       "0                    -7.000000                268865.553571   \n",
       "1                   -43.000000                824562.000000   \n",
       "2                  -382.000000                 45000.000000   \n",
       "3                          NaN                          NaN   \n",
       "4                  -783.000000                          NaN   \n",
       "\n",
       "   BURO_CREDIT_DAY_OVERDUE_MAX  BURO_CREDIT_DAY_OVERDUE_MEAN  \\\n",
       "0                     0.000000                      0.000000   \n",
       "1                     0.000000                      0.000000   \n",
       "2                     0.000000                      0.000000   \n",
       "3                          NaN                           NaN   \n",
       "4                     0.000000                      0.000000   \n",
       "\n",
       "   BURO_CREDIT_DAY_OVERDUE_SUM  BURO_CREDIT_DAY_OVERDUE_VAR  \\\n",
       "0                     0.000000                     0.000000   \n",
       "1                     0.000000                     0.000000   \n",
       "2                     0.000000                     0.000000   \n",
       "3                          NaN                          NaN   \n",
       "4                     0.000000                          NaN   \n",
       "\n",
       "   BURO_CREDIT_DAY_OVERDUE_MEDIAN  BURO_AMT_CREDIT_MAX_OVERDUE_MEAN  \\\n",
       "0                        0.000000                       1681.029000   \n",
       "1                        0.000000                          0.000000   \n",
       "2                        0.000000                          0.000000   \n",
       "3                             NaN                               NaN   \n",
       "4                        0.000000                          0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_MAX_OVERDUE_MAX  BURO_AMT_CREDIT_MAX_OVERDUE_SUM  \\\n",
       "0                      5043.645000                      8405.145000   \n",
       "1                         0.000000                         0.000000   \n",
       "2                         0.000000                         0.000000   \n",
       "3                              NaN                              NaN   \n",
       "4                         0.000000                         0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_MAX_OVERDUE_VAR  BURO_AMT_CREDIT_SUM_MAX  \\\n",
       "0                   5584935.910455            450000.000000   \n",
       "1                         0.000000            810000.000000   \n",
       "2                              NaN             94537.800000   \n",
       "3                              NaN                      NaN   \n",
       "4                              NaN            146250.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_MEAN  BURO_AMT_CREDIT_SUM_SUM  BURO_AMT_CREDIT_SUM_VAR  \\\n",
       "0             108131.945625            865055.565000       21338068480.082222   \n",
       "1             254350.125000           1017400.500000      138584554970.062500   \n",
       "2              94518.900000            189037.800000               714.420000   \n",
       "3                       NaN                      NaN                      NaN   \n",
       "4             146250.000000            146250.000000                      NaN   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_MEDIAN  BURO_AMT_CREDIT_SUM_DEBT_MAX  \\\n",
       "0                54130.500000                 245781.000000   \n",
       "1                92576.250000                      0.000000   \n",
       "2                94518.900000                      0.000000   \n",
       "3                         NaN                           NaN   \n",
       "4               146250.000000                      0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_DEBT_MEAN  BURO_AMT_CREDIT_SUM_DEBT_SUM  \\\n",
       "0                   49156.200000                 245781.000000   \n",
       "1                       0.000000                      0.000000   \n",
       "2                       0.000000                      0.000000   \n",
       "3                            NaN                           NaN   \n",
       "4                       0.000000                      0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_DEBT_VAR  BURO_AMT_CREDIT_SUM_DEBT_MEDIAN  \\\n",
       "0            12081659992.199999                         0.000000   \n",
       "1                      0.000000                         0.000000   \n",
       "2                      0.000000                         0.000000   \n",
       "3                           NaN                              NaN   \n",
       "4                           NaN                         0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_OVERDUE_MEAN  BURO_AMT_CREDIT_SUM_OVERDUE_MAX  \\\n",
       "0                          0.000000                         0.000000   \n",
       "1                          0.000000                         0.000000   \n",
       "2                          0.000000                         0.000000   \n",
       "3                               NaN                              NaN   \n",
       "4                          0.000000                         0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_OVERDUE_SUM  BURO_AMT_CREDIT_SUM_OVERDUE_VAR  \\\n",
       "0                         0.000000                         0.000000   \n",
       "1                         0.000000                         0.000000   \n",
       "2                         0.000000                         0.000000   \n",
       "3                              NaN                              NaN   \n",
       "4                         0.000000                              NaN   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_LIMIT_MEAN  BURO_AMT_CREDIT_SUM_LIMIT_SUM  \\\n",
       "0                     7997.141250                   31988.565000   \n",
       "1                   202500.000000                  810000.000000   \n",
       "2                        0.000000                       0.000000   \n",
       "3                             NaN                            NaN   \n",
       "4                        0.000000                       0.000000   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_LIMIT_MAX  BURO_AMT_CREDIT_SUM_LIMIT_VAR  \\\n",
       "0                   31988.565000               255817072.689806   \n",
       "1                  810000.000000            164025000000.000000   \n",
       "2                       0.000000                       0.000000   \n",
       "3                            NaN                            NaN   \n",
       "4                       0.000000                            NaN   \n",
       "\n",
       "   BURO_AMT_CREDIT_SUM_LIMIT_MEDIAN  BURO_AMT_ANNUITY_MAX  \\\n",
       "0                          0.000000              0.000000   \n",
       "1                          0.000000                   NaN   \n",
       "2                          0.000000                   NaN   \n",
       "3                               NaN                   NaN   \n",
       "4                          0.000000                   NaN   \n",
       "\n",
       "   BURO_AMT_ANNUITY_MEAN  BURO_AMT_ANNUITY_SUM  BURO_AMT_ANNUITY_VAR  \\\n",
       "0               0.000000              0.000000              0.000000   \n",
       "1                    NaN              0.000000                   NaN   \n",
       "2                    NaN              0.000000                   NaN   \n",
       "3                    NaN                   NaN                   NaN   \n",
       "4                    NaN              0.000000                   NaN   \n",
       "\n",
       "   BURO_AMT_ANNUITY_MEDIAN  BURO_CNT_CREDIT_PROLONG_SUM  \\\n",
       "0                 0.000000                     0.000000   \n",
       "1                      NaN                     0.000000   \n",
       "2                      NaN                     0.000000   \n",
       "3                      NaN                          NaN   \n",
       "4                      NaN                     0.000000   \n",
       "\n",
       "   BURO_CNT_CREDIT_PROLONG_MEAN  BURO_CNT_CREDIT_PROLONG_MAX  \\\n",
       "0                      0.000000                     0.000000   \n",
       "1                      0.000000                     0.000000   \n",
       "2                      0.000000                     0.000000   \n",
       "3                           NaN                          NaN   \n",
       "4                      0.000000                     0.000000   \n",
       "\n",
       "   BURO_CREDIT_CURRENCY_MODE  BURO_CREDIT_TYPE_MODE  ACTIVE_DAYS_CREDIT_MIN  \\\n",
       "0                   0.000000               3.000000            -1042.000000   \n",
       "1                   0.000000               3.000000             -606.000000   \n",
       "2                   0.000000               3.000000                     NaN   \n",
       "3                        NaN                    NaN                     NaN   \n",
       "4                   0.000000               3.000000                     NaN   \n",
       "\n",
       "   ACTIVE_DAYS_CREDIT_MAX  ACTIVE_DAYS_CREDIT_MEAN  ACTIVE_DAYS_CREDIT_VAR  \\\n",
       "0             -103.000000              -572.500000           440860.500000   \n",
       "1             -606.000000              -606.000000                     NaN   \n",
       "2                     NaN                      NaN                     NaN   \n",
       "3                     NaN                      NaN                     NaN   \n",
       "4                     NaN                      NaN                     NaN   \n",
       "\n",
       "   ACTIVE_DAYS_CREDIT_MEDIAN  ACTIVE_DAYS_CREDIT_ENDDATE_MIN  \\\n",
       "0                -572.500000                      780.000000   \n",
       "1                -606.000000                     1216.000000   \n",
       "2                        NaN                             NaN   \n",
       "3                        NaN                             NaN   \n",
       "4                        NaN                             NaN   \n",
       "\n",
       "   ACTIVE_DAYS_CREDIT_ENDDATE_MAX  ACTIVE_DAYS_CREDIT_ENDDATE_MEAN  \\\n",
       "0                      780.000000                       780.000000   \n",
       "1                     1216.000000                      1216.000000   \n",
       "2                             NaN                              NaN   \n",
       "3                             NaN                              NaN   \n",
       "4                             NaN                              NaN   \n",
       "\n",
       "   ACTIVE_DAYS_CREDIT_ENDDATE_VAR  ACTIVE_DAYS_CREDIT_ENDDATE_MEDIAN  \\\n",
       "0                             NaN                         780.000000   \n",
       "1                             NaN                        1216.000000   \n",
       "2                             NaN                                NaN   \n",
       "3                             NaN                                NaN   \n",
       "4                             NaN                                NaN   \n",
       "\n",
       "   ACTIVE_DAYS_CREDIT_UPDATE_MEAN  ACTIVE_DAYS_CREDIT_UPDATE_MIN  \\\n",
       "0                      -15.500000                     -24.000000   \n",
       "1                      -43.000000                     -43.000000   \n",
       "2                             NaN                            NaN   \n",
       "3                             NaN                            NaN   \n",
       "4                             NaN                            NaN   \n",
       "\n",
       "   ACTIVE_DAYS_CREDIT_UPDATE_MAX  ACTIVE_DAYS_CREDIT_UPDATE_VAR  \\\n",
       "0                      -7.000000                     144.500000   \n",
       "1                     -43.000000                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   ACTIVE_CREDIT_DAY_OVERDUE_MAX  ACTIVE_CREDIT_DAY_OVERDUE_MEAN  \\\n",
       "0                       0.000000                        0.000000   \n",
       "1                       0.000000                        0.000000   \n",
       "2                            NaN                             NaN   \n",
       "3                            NaN                             NaN   \n",
       "4                            NaN                             NaN   \n",
       "\n",
       "   ACTIVE_CREDIT_DAY_OVERDUE_SUM  ACTIVE_CREDIT_DAY_OVERDUE_VAR  \\\n",
       "0                       0.000000                       0.000000   \n",
       "1                       0.000000                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   ACTIVE_CREDIT_DAY_OVERDUE_MEDIAN  ACTIVE_AMT_CREDIT_MAX_OVERDUE_MEAN  \\\n",
       "0                          0.000000                           40.500000   \n",
       "1                          0.000000                            0.000000   \n",
       "2                               NaN                                 NaN   \n",
       "3                               NaN                                 NaN   \n",
       "4                               NaN                                 NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_MAX_OVERDUE_MAX  ACTIVE_AMT_CREDIT_MAX_OVERDUE_SUM  \\\n",
       "0                          40.500000                          40.500000   \n",
       "1                           0.000000                           0.000000   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_MAX_OVERDUE_VAR  ACTIVE_AMT_CREDIT_SUM_MAX  \\\n",
       "0                                NaN              450000.000000   \n",
       "1                                NaN              810000.000000   \n",
       "2                                NaN                        NaN   \n",
       "3                                NaN                        NaN   \n",
       "4                                NaN                        NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_MEAN  ACTIVE_AMT_CREDIT_SUM_SUM  \\\n",
       "0               240994.282500              481988.565000   \n",
       "1               810000.000000              810000.000000   \n",
       "2                         NaN                        NaN   \n",
       "3                         NaN                        NaN   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_VAR  ACTIVE_AMT_CREDIT_SUM_MEDIAN  \\\n",
       "0         87366779895.379608                 240994.282500   \n",
       "1                        NaN                 810000.000000   \n",
       "2                        NaN                           NaN   \n",
       "3                        NaN                           NaN   \n",
       "4                        NaN                           NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_DEBT_MAX  ACTIVE_AMT_CREDIT_SUM_DEBT_MEAN  \\\n",
       "0                   245781.000000                    122890.500000   \n",
       "1                        0.000000                         0.000000   \n",
       "2                             NaN                              NaN   \n",
       "3                             NaN                              NaN   \n",
       "4                             NaN                              NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_DEBT_SUM  ACTIVE_AMT_CREDIT_SUM_DEBT_VAR  \\\n",
       "0                   245781.000000              30204149980.500000   \n",
       "1                        0.000000                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                             NaN                             NaN   \n",
       "4                             NaN                             NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_DEBT_MEDIAN  ACTIVE_AMT_CREDIT_SUM_OVERDUE_MEAN  \\\n",
       "0                      122890.500000                            0.000000   \n",
       "1                           0.000000                            0.000000   \n",
       "2                                NaN                                 NaN   \n",
       "3                                NaN                                 NaN   \n",
       "4                                NaN                                 NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_OVERDUE_MAX  ACTIVE_AMT_CREDIT_SUM_OVERDUE_SUM  \\\n",
       "0                           0.000000                           0.000000   \n",
       "1                           0.000000                           0.000000   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_OVERDUE_VAR  ACTIVE_AMT_CREDIT_SUM_LIMIT_MEAN  \\\n",
       "0                           0.000000                      15994.282500   \n",
       "1                                NaN                     810000.000000   \n",
       "2                                NaN                               NaN   \n",
       "3                                NaN                               NaN   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_LIMIT_SUM  ACTIVE_AMT_CREDIT_SUM_LIMIT_MAX  \\\n",
       "0                     31988.565000                     31988.565000   \n",
       "1                    810000.000000                    810000.000000   \n",
       "2                              NaN                              NaN   \n",
       "3                              NaN                              NaN   \n",
       "4                              NaN                              NaN   \n",
       "\n",
       "   ACTIVE_AMT_CREDIT_SUM_LIMIT_VAR  ACTIVE_AMT_CREDIT_SUM_LIMIT_MEDIAN  \\\n",
       "0                 511634145.379612                        15994.282500   \n",
       "1                              NaN                       810000.000000   \n",
       "2                              NaN                                 NaN   \n",
       "3                              NaN                                 NaN   \n",
       "4                              NaN                                 NaN   \n",
       "\n",
       "   ACTIVE_AMT_ANNUITY_MAX  ACTIVE_AMT_ANNUITY_MEAN  ACTIVE_AMT_ANNUITY_SUM  \\\n",
       "0                0.000000                 0.000000                0.000000   \n",
       "1                     NaN                      NaN                0.000000   \n",
       "2                     NaN                      NaN                     NaN   \n",
       "3                     NaN                      NaN                     NaN   \n",
       "4                     NaN                      NaN                     NaN   \n",
       "\n",
       "   ACTIVE_AMT_ANNUITY_VAR  ACTIVE_AMT_ANNUITY_MEDIAN  \\\n",
       "0                0.000000                   0.000000   \n",
       "1                     NaN                        NaN   \n",
       "2                     NaN                        NaN   \n",
       "3                     NaN                        NaN   \n",
       "4                     NaN                        NaN   \n",
       "\n",
       "   ACTIVE_CNT_CREDIT_PROLONG_SUM  ACTIVE_CNT_CREDIT_PROLONG_MEAN  \\\n",
       "0                       0.000000                        0.000000   \n",
       "1                       0.000000                        0.000000   \n",
       "2                            NaN                             NaN   \n",
       "3                            NaN                             NaN   \n",
       "4                            NaN                             NaN   \n",
       "\n",
       "   ACTIVE_CNT_CREDIT_PROLONG_MAX  CLOSED_DAYS_CREDIT_MIN  \\\n",
       "0                       0.000000            -1437.000000   \n",
       "1                       0.000000            -2586.000000   \n",
       "2                            NaN            -1326.000000   \n",
       "3                            NaN                     NaN   \n",
       "4                            NaN            -1149.000000   \n",
       "\n",
       "   CLOSED_DAYS_CREDIT_MAX  CLOSED_DAYS_CREDIT_MEAN  CLOSED_DAYS_CREDIT_VAR  \\\n",
       "0             -476.000000              -974.500000           123956.700000   \n",
       "1             -775.000000             -1665.666667           820590.333333   \n",
       "2             -408.000000              -867.000000           421362.000000   \n",
       "3                     NaN                      NaN                     NaN   \n",
       "4            -1149.000000             -1149.000000                     NaN   \n",
       "\n",
       "   CLOSED_DAYS_CREDIT_MEDIAN  CLOSED_DAYS_CREDIT_ENDDATE_MIN  \\\n",
       "0               -1082.000000                    -1072.000000   \n",
       "1               -1636.000000                    -2434.000000   \n",
       "2                -867.000000                     -595.000000   \n",
       "3                        NaN                             NaN   \n",
       "4               -1149.000000                     -783.000000   \n",
       "\n",
       "   CLOSED_DAYS_CREDIT_ENDDATE_MAX  CLOSED_DAYS_CREDIT_ENDDATE_MEAN  \\\n",
       "0                       85.000000                      -574.800000   \n",
       "1                     -420.000000                     -1131.333333   \n",
       "2                     -382.000000                      -488.500000   \n",
       "3                             NaN                              NaN   \n",
       "4                     -783.000000                      -783.000000   \n",
       "\n",
       "   CLOSED_DAYS_CREDIT_ENDDATE_VAR  CLOSED_DAYS_CREDIT_ENDDATE_MEDIAN  \\\n",
       "0                   353910.700000                        -911.000000   \n",
       "1                  1276305.333333                        -540.000000   \n",
       "2                    22684.500000                        -488.500000   \n",
       "3                             NaN                                NaN   \n",
       "4                             NaN                        -783.000000   \n",
       "\n",
       "   CLOSED_DAYS_CREDIT_UPDATE_MEAN  CLOSED_DAYS_CREDIT_UPDATE_MIN  \\\n",
       "0                     -661.333333                   -1185.000000   \n",
       "1                    -1073.666667                   -2131.000000   \n",
       "2                     -532.000000                    -682.000000   \n",
       "3                             NaN                            NaN   \n",
       "4                     -783.000000                    -783.000000   \n",
       "\n",
       "   CLOSED_DAYS_CREDIT_UPDATE_MAX  CLOSED_DAYS_CREDIT_UPDATE_VAR  \\\n",
       "0                     -34.000000                  251252.666667   \n",
       "1                    -540.000000                  838490.333333   \n",
       "2                    -382.000000                   45000.000000   \n",
       "3                            NaN                            NaN   \n",
       "4                    -783.000000                            NaN   \n",
       "\n",
       "   CLOSED_CREDIT_DAY_OVERDUE_MAX  CLOSED_CREDIT_DAY_OVERDUE_MEAN  \\\n",
       "0                       0.000000                        0.000000   \n",
       "1                       0.000000                        0.000000   \n",
       "2                       0.000000                        0.000000   \n",
       "3                            NaN                             NaN   \n",
       "4                       0.000000                        0.000000   \n",
       "\n",
       "   CLOSED_CREDIT_DAY_OVERDUE_SUM  CLOSED_CREDIT_DAY_OVERDUE_VAR  \\\n",
       "0                       0.000000                       0.000000   \n",
       "1                       0.000000                       0.000000   \n",
       "2                       0.000000                       0.000000   \n",
       "3                            NaN                            NaN   \n",
       "4                       0.000000                            NaN   \n",
       "\n",
       "   CLOSED_CREDIT_DAY_OVERDUE_MEDIAN  CLOSED_AMT_CREDIT_MAX_OVERDUE_MEAN  \\\n",
       "0                          0.000000                         2091.161250   \n",
       "1                          0.000000                            0.000000   \n",
       "2                          0.000000                            0.000000   \n",
       "3                               NaN                                 NaN   \n",
       "4                          0.000000                            0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_MAX_OVERDUE_MAX  CLOSED_AMT_CREDIT_MAX_OVERDUE_SUM  \\\n",
       "0                        5043.645000                        8364.645000   \n",
       "1                           0.000000                           0.000000   \n",
       "2                           0.000000                           0.000000   \n",
       "3                                NaN                                NaN   \n",
       "4                           0.000000                           0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_MAX_OVERDUE_VAR  CLOSED_AMT_CREDIT_SUM_MAX  \\\n",
       "0                     6325191.464006              135000.000000   \n",
       "1                           0.000000              112500.000000   \n",
       "2                                NaN               94537.800000   \n",
       "3                                NaN                        NaN   \n",
       "4                                NaN              146250.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_MEAN  CLOSED_AMT_CREDIT_SUM_SUM  \\\n",
       "0                63844.500000              383067.000000   \n",
       "1                69133.500000              207400.500000   \n",
       "2                94518.900000              189037.800000   \n",
       "3                         NaN                        NaN   \n",
       "4               146250.000000              146250.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_VAR  CLOSED_AMT_CREDIT_SUM_MEDIAN  \\\n",
       "0          2985326261.100000                  54130.500000   \n",
       "1          2045643396.750000                  72652.500000   \n",
       "2                 714.420000                  94518.900000   \n",
       "3                        NaN                           NaN   \n",
       "4                        NaN                 146250.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_DEBT_MAX  CLOSED_AMT_CREDIT_SUM_DEBT_MEAN  \\\n",
       "0                        0.000000                         0.000000   \n",
       "1                        0.000000                         0.000000   \n",
       "2                        0.000000                         0.000000   \n",
       "3                             NaN                              NaN   \n",
       "4                        0.000000                         0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_DEBT_SUM  CLOSED_AMT_CREDIT_SUM_DEBT_VAR  \\\n",
       "0                        0.000000                        0.000000   \n",
       "1                        0.000000                        0.000000   \n",
       "2                        0.000000                        0.000000   \n",
       "3                             NaN                             NaN   \n",
       "4                        0.000000                             NaN   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_DEBT_MEDIAN  CLOSED_AMT_CREDIT_SUM_OVERDUE_MEAN  \\\n",
       "0                           0.000000                            0.000000   \n",
       "1                           0.000000                            0.000000   \n",
       "2                           0.000000                            0.000000   \n",
       "3                                NaN                                 NaN   \n",
       "4                           0.000000                            0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_OVERDUE_MAX  CLOSED_AMT_CREDIT_SUM_OVERDUE_SUM  \\\n",
       "0                           0.000000                           0.000000   \n",
       "1                           0.000000                           0.000000   \n",
       "2                           0.000000                           0.000000   \n",
       "3                                NaN                                NaN   \n",
       "4                           0.000000                           0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_OVERDUE_VAR  CLOSED_AMT_CREDIT_SUM_LIMIT_MEAN  \\\n",
       "0                           0.000000                          0.000000   \n",
       "1                           0.000000                          0.000000   \n",
       "2                           0.000000                          0.000000   \n",
       "3                                NaN                               NaN   \n",
       "4                                NaN                          0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_LIMIT_SUM  CLOSED_AMT_CREDIT_SUM_LIMIT_MAX  \\\n",
       "0                         0.000000                         0.000000   \n",
       "1                         0.000000                         0.000000   \n",
       "2                         0.000000                         0.000000   \n",
       "3                              NaN                              NaN   \n",
       "4                         0.000000                         0.000000   \n",
       "\n",
       "   CLOSED_AMT_CREDIT_SUM_LIMIT_VAR  CLOSED_AMT_CREDIT_SUM_LIMIT_MEDIAN  \\\n",
       "0                         0.000000                            0.000000   \n",
       "1                         0.000000                            0.000000   \n",
       "2                         0.000000                            0.000000   \n",
       "3                              NaN                                 NaN   \n",
       "4                              NaN                            0.000000   \n",
       "\n",
       "   CLOSED_AMT_ANNUITY_MAX  CLOSED_AMT_ANNUITY_MEAN  CLOSED_AMT_ANNUITY_SUM  \\\n",
       "0                0.000000                 0.000000                0.000000   \n",
       "1                     NaN                      NaN                0.000000   \n",
       "2                     NaN                      NaN                0.000000   \n",
       "3                     NaN                      NaN                     NaN   \n",
       "4                     NaN                      NaN                0.000000   \n",
       "\n",
       "   CLOSED_AMT_ANNUITY_VAR  CLOSED_AMT_ANNUITY_MEDIAN  \\\n",
       "0                0.000000                   0.000000   \n",
       "1                     NaN                        NaN   \n",
       "2                     NaN                        NaN   \n",
       "3                     NaN                        NaN   \n",
       "4                     NaN                        NaN   \n",
       "\n",
       "   CLOSED_CNT_CREDIT_PROLONG_SUM  CLOSED_CNT_CREDIT_PROLONG_MEAN  \\\n",
       "0                       0.000000                        0.000000   \n",
       "1                       0.000000                        0.000000   \n",
       "2                       0.000000                        0.000000   \n",
       "3                            NaN                             NaN   \n",
       "4                       0.000000                        0.000000   \n",
       "\n",
       "   CLOSED_CNT_CREDIT_PROLONG_MAX  BURO_DEBT_CREDIT_RATIO  \\\n",
       "0                       0.000000                0.284122   \n",
       "1                       0.000000                0.000000   \n",
       "2                       0.000000                0.000000   \n",
       "3                            NaN                     NaN   \n",
       "4                       0.000000                0.000000   \n",
       "\n",
       "   BURO_LIMIT_USAGE_RATIO  BURO_OVERDUE_DEBT_RATIO  \\\n",
       "0                7.683402                 0.000000   \n",
       "1                0.000000                      NaN   \n",
       "2                     NaN                      NaN   \n",
       "3                     NaN                      NaN   \n",
       "4                     NaN                      NaN   \n",
       "\n",
       "   BURO_MAX_OVERDUE_TO_CREDIT  BURO_RECENT_CREDIT_DAYS  \\\n",
       "0                    0.005830               103.000000   \n",
       "1                    0.000000               606.000000   \n",
       "2                    0.000000               408.000000   \n",
       "3                         NaN                      NaN   \n",
       "4                    0.000000              1149.000000   \n",
       "\n",
       "   ACTIVE_DEBT_CREDIT_RATIO  ACTIVE_LIMIT_USAGE_RATIO  \\\n",
       "0                  0.509931                  7.683402   \n",
       "1                  0.000000                  0.000000   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   ACTIVE_OVERDUE_DEBT_RATIO  CC_MONTHS_BALANCE_MIN  CC_MONTHS_BALANCE_MAX  \\\n",
       "0                   0.000000                    NaN                    NaN   \n",
       "1                        NaN                    NaN                    NaN   \n",
       "2                        NaN                    NaN                    NaN   \n",
       "3                        NaN              -6.000000              -1.000000   \n",
       "4                        NaN                    NaN                    NaN   \n",
       "\n",
       "   CC_MONTHS_BALANCE_MEAN  CC_MONTHS_BALANCE_SUM  CC_MONTHS_BALANCE_VAR  \\\n",
       "0                     NaN                    NaN                    NaN   \n",
       "1                     NaN                    NaN                    NaN   \n",
       "2                     NaN                    NaN                    NaN   \n",
       "3               -3.500000             -21.000000               3.500000   \n",
       "4                     NaN                    NaN                    NaN   \n",
       "\n",
       "   CC_AMT_BALANCE_MIN  CC_AMT_BALANCE_MAX  CC_AMT_BALANCE_MEAN  \\\n",
       "0                 NaN                 NaN                  NaN   \n",
       "1                 NaN                 NaN                  NaN   \n",
       "2                 NaN                 NaN                  NaN   \n",
       "3            0.000000            0.000000             0.000000   \n",
       "4                 NaN                 NaN                  NaN   \n",
       "\n",
       "   CC_AMT_BALANCE_SUM  CC_AMT_BALANCE_VAR  CC_AMT_CREDIT_LIMIT_ACTUAL_MIN  \\\n",
       "0                 NaN                 NaN                             NaN   \n",
       "1                 NaN                 NaN                             NaN   \n",
       "2                 NaN                 NaN                             NaN   \n",
       "3            0.000000            0.000000                   270000.000000   \n",
       "4                 NaN                 NaN                             NaN   \n",
       "\n",
       "   CC_AMT_CREDIT_LIMIT_ACTUAL_MAX  CC_AMT_CREDIT_LIMIT_ACTUAL_MEAN  \\\n",
       "0                             NaN                              NaN   \n",
       "1                             NaN                              NaN   \n",
       "2                             NaN                              NaN   \n",
       "3                   270000.000000                    270000.000000   \n",
       "4                             NaN                              NaN   \n",
       "\n",
       "   CC_AMT_CREDIT_LIMIT_ACTUAL_SUM  CC_AMT_CREDIT_LIMIT_ACTUAL_VAR  \\\n",
       "0                             NaN                             NaN   \n",
       "1                             NaN                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                  1620000.000000                        0.000000   \n",
       "4                             NaN                             NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_ATM_CURRENT_MIN  CC_AMT_DRAWINGS_ATM_CURRENT_MAX  \\\n",
       "0                              NaN                              NaN   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "3                              NaN                              NaN   \n",
       "4                              NaN                              NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_ATM_CURRENT_MEAN  CC_AMT_DRAWINGS_ATM_CURRENT_SUM  \\\n",
       "0                               NaN                              NaN   \n",
       "1                               NaN                              NaN   \n",
       "2                               NaN                              NaN   \n",
       "3                               NaN                         0.000000   \n",
       "4                               NaN                              NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_ATM_CURRENT_VAR  CC_AMT_DRAWINGS_CURRENT_MIN  \\\n",
       "0                              NaN                          NaN   \n",
       "1                              NaN                          NaN   \n",
       "2                              NaN                          NaN   \n",
       "3                              NaN                     0.000000   \n",
       "4                              NaN                          NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_CURRENT_MAX  CC_AMT_DRAWINGS_CURRENT_MEAN  \\\n",
       "0                          NaN                           NaN   \n",
       "1                          NaN                           NaN   \n",
       "2                          NaN                           NaN   \n",
       "3                     0.000000                      0.000000   \n",
       "4                          NaN                           NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_CURRENT_SUM  CC_AMT_DRAWINGS_CURRENT_VAR  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                     0.000000                     0.000000   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_OTHER_CURRENT_MIN  CC_AMT_DRAWINGS_OTHER_CURRENT_MAX  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_OTHER_CURRENT_MEAN  CC_AMT_DRAWINGS_OTHER_CURRENT_SUM  \\\n",
       "0                                 NaN                                NaN   \n",
       "1                                 NaN                                NaN   \n",
       "2                                 NaN                                NaN   \n",
       "3                                 NaN                           0.000000   \n",
       "4                                 NaN                                NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_OTHER_CURRENT_VAR  CC_AMT_DRAWINGS_POS_CURRENT_MIN  \\\n",
       "0                                NaN                              NaN   \n",
       "1                                NaN                              NaN   \n",
       "2                                NaN                              NaN   \n",
       "3                                NaN                              NaN   \n",
       "4                                NaN                              NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_POS_CURRENT_MAX  CC_AMT_DRAWINGS_POS_CURRENT_MEAN  \\\n",
       "0                              NaN                               NaN   \n",
       "1                              NaN                               NaN   \n",
       "2                              NaN                               NaN   \n",
       "3                              NaN                               NaN   \n",
       "4                              NaN                               NaN   \n",
       "\n",
       "   CC_AMT_DRAWINGS_POS_CURRENT_SUM  CC_AMT_DRAWINGS_POS_CURRENT_VAR  \\\n",
       "0                              NaN                              NaN   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "3                         0.000000                              NaN   \n",
       "4                              NaN                              NaN   \n",
       "\n",
       "   CC_AMT_INST_MIN_REGULARITY_MIN  CC_AMT_INST_MIN_REGULARITY_MAX  \\\n",
       "0                             NaN                             NaN   \n",
       "1                             NaN                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                        0.000000                        0.000000   \n",
       "4                             NaN                             NaN   \n",
       "\n",
       "   CC_AMT_INST_MIN_REGULARITY_MEAN  CC_AMT_INST_MIN_REGULARITY_SUM  \\\n",
       "0                              NaN                             NaN   \n",
       "1                              NaN                             NaN   \n",
       "2                              NaN                             NaN   \n",
       "3                         0.000000                        0.000000   \n",
       "4                              NaN                             NaN   \n",
       "\n",
       "   CC_AMT_INST_MIN_REGULARITY_VAR  CC_AMT_PAYMENT_CURRENT_MIN  \\\n",
       "0                             NaN                         NaN   \n",
       "1                             NaN                         NaN   \n",
       "2                             NaN                         NaN   \n",
       "3                        0.000000                         NaN   \n",
       "4                             NaN                         NaN   \n",
       "\n",
       "   CC_AMT_PAYMENT_CURRENT_MAX  CC_AMT_PAYMENT_CURRENT_MEAN  \\\n",
       "0                         NaN                          NaN   \n",
       "1                         NaN                          NaN   \n",
       "2                         NaN                          NaN   \n",
       "3                         NaN                          NaN   \n",
       "4                         NaN                          NaN   \n",
       "\n",
       "   CC_AMT_PAYMENT_CURRENT_SUM  CC_AMT_PAYMENT_CURRENT_VAR  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "3                    0.000000                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "   CC_AMT_PAYMENT_TOTAL_CURRENT_MIN  CC_AMT_PAYMENT_TOTAL_CURRENT_MAX  \\\n",
       "0                               NaN                               NaN   \n",
       "1                               NaN                               NaN   \n",
       "2                               NaN                               NaN   \n",
       "3                          0.000000                          0.000000   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   CC_AMT_PAYMENT_TOTAL_CURRENT_MEAN  CC_AMT_PAYMENT_TOTAL_CURRENT_SUM  \\\n",
       "0                                NaN                               NaN   \n",
       "1                                NaN                               NaN   \n",
       "2                                NaN                               NaN   \n",
       "3                           0.000000                          0.000000   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   CC_AMT_PAYMENT_TOTAL_CURRENT_VAR  CC_AMT_RECEIVABLE_PRINCIPAL_MIN  \\\n",
       "0                               NaN                              NaN   \n",
       "1                               NaN                              NaN   \n",
       "2                               NaN                              NaN   \n",
       "3                          0.000000                         0.000000   \n",
       "4                               NaN                              NaN   \n",
       "\n",
       "   CC_AMT_RECEIVABLE_PRINCIPAL_MAX  CC_AMT_RECEIVABLE_PRINCIPAL_MEAN  \\\n",
       "0                              NaN                               NaN   \n",
       "1                              NaN                               NaN   \n",
       "2                              NaN                               NaN   \n",
       "3                         0.000000                          0.000000   \n",
       "4                              NaN                               NaN   \n",
       "\n",
       "   CC_AMT_RECEIVABLE_PRINCIPAL_SUM  CC_AMT_RECEIVABLE_PRINCIPAL_VAR  \\\n",
       "0                              NaN                              NaN   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "3                         0.000000                         0.000000   \n",
       "4                              NaN                              NaN   \n",
       "\n",
       "   CC_AMT_RECIVABLE_MIN  CC_AMT_RECIVABLE_MAX  CC_AMT_RECIVABLE_MEAN  \\\n",
       "0                   NaN                   NaN                    NaN   \n",
       "1                   NaN                   NaN                    NaN   \n",
       "2                   NaN                   NaN                    NaN   \n",
       "3              0.000000              0.000000               0.000000   \n",
       "4                   NaN                   NaN                    NaN   \n",
       "\n",
       "   CC_AMT_RECIVABLE_SUM  CC_AMT_RECIVABLE_VAR  CC_AMT_TOTAL_RECEIVABLE_MIN  \\\n",
       "0                   NaN                   NaN                          NaN   \n",
       "1                   NaN                   NaN                          NaN   \n",
       "2                   NaN                   NaN                          NaN   \n",
       "3              0.000000              0.000000                     0.000000   \n",
       "4                   NaN                   NaN                          NaN   \n",
       "\n",
       "   CC_AMT_TOTAL_RECEIVABLE_MAX  CC_AMT_TOTAL_RECEIVABLE_MEAN  \\\n",
       "0                          NaN                           NaN   \n",
       "1                          NaN                           NaN   \n",
       "2                          NaN                           NaN   \n",
       "3                     0.000000                      0.000000   \n",
       "4                          NaN                           NaN   \n",
       "\n",
       "   CC_AMT_TOTAL_RECEIVABLE_SUM  CC_AMT_TOTAL_RECEIVABLE_VAR  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                     0.000000                     0.000000   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_ATM_CURRENT_MIN  CC_CNT_DRAWINGS_ATM_CURRENT_MAX  \\\n",
       "0                              NaN                              NaN   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "3                              NaN                              NaN   \n",
       "4                              NaN                              NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_ATM_CURRENT_MEAN  CC_CNT_DRAWINGS_ATM_CURRENT_SUM  \\\n",
       "0                               NaN                              NaN   \n",
       "1                               NaN                              NaN   \n",
       "2                               NaN                              NaN   \n",
       "3                               NaN                         0.000000   \n",
       "4                               NaN                              NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_ATM_CURRENT_VAR  CC_CNT_DRAWINGS_CURRENT_MIN  \\\n",
       "0                              NaN                          NaN   \n",
       "1                              NaN                          NaN   \n",
       "2                              NaN                          NaN   \n",
       "3                              NaN                     0.000000   \n",
       "4                              NaN                          NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_CURRENT_MAX  CC_CNT_DRAWINGS_CURRENT_MEAN  \\\n",
       "0                          NaN                           NaN   \n",
       "1                          NaN                           NaN   \n",
       "2                          NaN                           NaN   \n",
       "3                     0.000000                      0.000000   \n",
       "4                          NaN                           NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_CURRENT_SUM  CC_CNT_DRAWINGS_CURRENT_VAR  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                     0.000000                     0.000000   \n",
       "4                          NaN                          NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_OTHER_CURRENT_MIN  CC_CNT_DRAWINGS_OTHER_CURRENT_MAX  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_OTHER_CURRENT_MEAN  CC_CNT_DRAWINGS_OTHER_CURRENT_SUM  \\\n",
       "0                                 NaN                                NaN   \n",
       "1                                 NaN                                NaN   \n",
       "2                                 NaN                                NaN   \n",
       "3                                 NaN                           0.000000   \n",
       "4                                 NaN                                NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_OTHER_CURRENT_VAR  CC_CNT_DRAWINGS_POS_CURRENT_MIN  \\\n",
       "0                                NaN                              NaN   \n",
       "1                                NaN                              NaN   \n",
       "2                                NaN                              NaN   \n",
       "3                                NaN                              NaN   \n",
       "4                                NaN                              NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_POS_CURRENT_MAX  CC_CNT_DRAWINGS_POS_CURRENT_MEAN  \\\n",
       "0                              NaN                               NaN   \n",
       "1                              NaN                               NaN   \n",
       "2                              NaN                               NaN   \n",
       "3                              NaN                               NaN   \n",
       "4                              NaN                               NaN   \n",
       "\n",
       "   CC_CNT_DRAWINGS_POS_CURRENT_SUM  CC_CNT_DRAWINGS_POS_CURRENT_VAR  \\\n",
       "0                              NaN                              NaN   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "3                         0.000000                              NaN   \n",
       "4                              NaN                              NaN   \n",
       "\n",
       "   CC_CNT_INSTALMENT_MATURE_CUM_MIN  CC_CNT_INSTALMENT_MATURE_CUM_MAX  \\\n",
       "0                               NaN                               NaN   \n",
       "1                               NaN                               NaN   \n",
       "2                               NaN                               NaN   \n",
       "3                          0.000000                          0.000000   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   CC_CNT_INSTALMENT_MATURE_CUM_MEAN  CC_CNT_INSTALMENT_MATURE_CUM_SUM  \\\n",
       "0                                NaN                               NaN   \n",
       "1                                NaN                               NaN   \n",
       "2                                NaN                               NaN   \n",
       "3                           0.000000                          0.000000   \n",
       "4                                NaN                               NaN   \n",
       "\n",
       "   CC_CNT_INSTALMENT_MATURE_CUM_VAR  CC_SK_DPD_MIN  CC_SK_DPD_MAX  \\\n",
       "0                               NaN            NaN            NaN   \n",
       "1                               NaN            NaN            NaN   \n",
       "2                               NaN            NaN            NaN   \n",
       "3                          0.000000       0.000000       0.000000   \n",
       "4                               NaN            NaN            NaN   \n",
       "\n",
       "   CC_SK_DPD_MEAN  CC_SK_DPD_SUM  CC_SK_DPD_VAR  CC_SK_DPD_DEF_MIN  \\\n",
       "0             NaN            NaN            NaN                NaN   \n",
       "1             NaN            NaN            NaN                NaN   \n",
       "2             NaN            NaN            NaN                NaN   \n",
       "3        0.000000       0.000000       0.000000           0.000000   \n",
       "4             NaN            NaN            NaN                NaN   \n",
       "\n",
       "   CC_SK_DPD_DEF_MAX  CC_SK_DPD_DEF_MEAN  CC_SK_DPD_DEF_SUM  \\\n",
       "0                NaN                 NaN                NaN   \n",
       "1                NaN                 NaN                NaN   \n",
       "2                NaN                 NaN                NaN   \n",
       "3           0.000000            0.000000           0.000000   \n",
       "4                NaN                 NaN                NaN   \n",
       "\n",
       "   CC_SK_DPD_DEF_VAR  CC_NAME_CONTRACT_STATUS_MODE  CC_COUNT  \\\n",
       "0                NaN                           NaN       NaN   \n",
       "1                NaN                           NaN       NaN   \n",
       "2                NaN                           NaN       NaN   \n",
       "3           0.000000                      0.000000  6.000000   \n",
       "4                NaN                           NaN       NaN   \n",
       "\n",
       "   CC_UTILIZATION_MEAN  CC_UTILIZATION_SUM  CC_PAYMENT_RATIO  \\\n",
       "0                  NaN                 NaN               NaN   \n",
       "1                  NaN                 NaN               NaN   \n",
       "2                  NaN                 NaN               NaN   \n",
       "3             0.000000            0.000000               NaN   \n",
       "4                  NaN                 NaN               NaN   \n",
       "\n",
       "   CC_MIN_PAY_REG_RATIO  CC_DRAWINGS_TO_LIMIT  CC_ATM_DRAW_SHARE  \\\n",
       "0                   NaN                   NaN                NaN   \n",
       "1                   NaN                   NaN                NaN   \n",
       "2                   NaN                   NaN                NaN   \n",
       "3                   NaN              0.000000                NaN   \n",
       "4                   NaN                   NaN                NaN   \n",
       "\n",
       "   CC_POS_DRAW_SHARE  CC_ANY_DPD_FLAG  CC_RECENT_ACTIVITY_FLAG  \\\n",
       "0                NaN              NaN                      NaN   \n",
       "1                NaN              NaN                      NaN   \n",
       "2                NaN              NaN                      NaN   \n",
       "3                NaN         0.000000                 1.000000   \n",
       "4                NaN              NaN                      NaN   \n",
       "\n",
       "   POS_MONTHS_BALANCE_MIN  POS_MONTHS_BALANCE_MAX  POS_MONTHS_BALANCE_MEAN  \\\n",
       "0              -19.000000               -1.000000               -10.000000   \n",
       "1              -77.000000              -18.000000               -43.785714   \n",
       "2              -27.000000              -24.000000               -25.500000   \n",
       "3              -20.000000               -1.000000                -9.619048   \n",
       "4              -77.000000               -1.000000               -33.636364   \n",
       "\n",
       "   POS_MONTHS_BALANCE_SIZE  POS_SK_DPD_MIN  POS_SK_DPD_MAX  POS_SK_DPD_MEAN  \\\n",
       "0                19.000000        0.000000        0.000000         0.000000   \n",
       "1                28.000000        0.000000        0.000000         0.000000   \n",
       "2                 4.000000        0.000000        0.000000         0.000000   \n",
       "3                21.000000        0.000000        0.000000         0.000000   \n",
       "4                66.000000        0.000000        0.000000         0.000000   \n",
       "\n",
       "   POS_SK_DPD_SUM  POS_SK_DPD_DEF_MAX  POS_SK_DPD_DEF_MEAN  \\\n",
       "0        0.000000            0.000000             0.000000   \n",
       "1        0.000000            0.000000             0.000000   \n",
       "2        0.000000            0.000000             0.000000   \n",
       "3        0.000000            0.000000             0.000000   \n",
       "4        0.000000            0.000000             0.000000   \n",
       "\n",
       "   POS_SK_DPD_DEF_SUM  POS_CNT_INSTALMENT_MIN  POS_CNT_INSTALMENT_MAX  \\\n",
       "0            0.000000               24.000000               24.000000   \n",
       "1            0.000000                6.000000               12.000000   \n",
       "2            0.000000                3.000000                4.000000   \n",
       "3            0.000000                1.000000               48.000000   \n",
       "4            0.000000               10.000000               24.000000   \n",
       "\n",
       "   POS_CNT_INSTALMENT_MEAN  POS_CNT_INSTALMENT_FUTURE_MIN  \\\n",
       "0                24.000000                       6.000000   \n",
       "1                10.107143                       0.000000   \n",
       "2                 3.750000                       0.000000   \n",
       "3                12.000000                       0.000000   \n",
       "4                15.333333                       0.000000   \n",
       "\n",
       "   POS_CNT_INSTALMENT_FUTURE_MAX  POS_CNT_INSTALMENT_FUTURE_MEAN  \\\n",
       "0                      24.000000                       15.000000   \n",
       "1                      12.000000                        5.785714   \n",
       "2                       4.000000                        2.250000   \n",
       "3                      48.000000                        8.571429   \n",
       "4                      24.000000                        8.969697   \n",
       "\n",
       "   POS_POS_IS_DPD_MEAN  POS_POS_IS_DPD_SUM  POS_POS_IS_DPD_UNDER_30_MEAN  \\\n",
       "0             0.000000            0.000000                      0.000000   \n",
       "1             0.000000            0.000000                      0.000000   \n",
       "2             0.000000            0.000000                      0.000000   \n",
       "3             0.000000            0.000000                      0.000000   \n",
       "4             0.000000            0.000000                      0.000000   \n",
       "\n",
       "   POS_POS_IS_DPD_UNDER_30_SUM  POS_POS_IS_DPD_OVER_30_MEAN  \\\n",
       "0                     0.000000                     0.000000   \n",
       "1                     0.000000                     0.000000   \n",
       "2                     0.000000                     0.000000   \n",
       "3                     0.000000                     0.000000   \n",
       "4                     0.000000                     0.000000   \n",
       "\n",
       "   POS_POS_IS_DPD_OVER_30_SUM  POS_POS_IS_DPD_OVER_120_MEAN  \\\n",
       "0                    0.000000                      0.000000   \n",
       "1                    0.000000                      0.000000   \n",
       "2                    0.000000                      0.000000   \n",
       "3                    0.000000                      0.000000   \n",
       "4                    0.000000                      0.000000   \n",
       "\n",
       "   POS_POS_IS_DPD_OVER_120_SUM  POS_POS_IS_SEVERE_DPD_MEAN  \\\n",
       "0                     0.000000                    0.000000   \n",
       "1                     0.000000                    0.000000   \n",
       "2                     0.000000                    0.000000   \n",
       "3                     0.000000                    0.000000   \n",
       "4                     0.000000                    0.000000   \n",
       "\n",
       "   POS_POS_IS_SEVERE_DPD_SUM  POS_INSTALMENT_PROGRESS_MIN  \\\n",
       "0                   0.000000                     0.000000   \n",
       "1                   0.000000                     0.000000   \n",
       "2                   0.000000                     0.000000   \n",
       "3                   0.000000                     0.000000   \n",
       "4                   0.000000                     0.000000   \n",
       "\n",
       "   POS_INSTALMENT_PROGRESS_MAX  POS_INSTALMENT_PROGRESS_MEAN  \\\n",
       "0                    18.000000                      9.000000   \n",
       "1                    11.000000                      4.321429   \n",
       "2                     3.000000                      1.500000   \n",
       "3                     9.000000                      3.428571   \n",
       "4                    17.000000                      6.363636   \n",
       "\n",
       "   POS_INSTALMENT_PROGRESS_SUM  POS_INSTALMENT_COMPLETION_RATIO_MIN  \\\n",
       "0                   171.000000                             0.000000   \n",
       "1                   121.000000                             0.000000   \n",
       "2                     6.000000                             0.000000   \n",
       "3                    72.000000                             0.000000   \n",
       "4                   420.000000                             0.000000   \n",
       "\n",
       "   POS_INSTALMENT_COMPLETION_RATIO_MAX  POS_INSTALMENT_COMPLETION_RATIO_MEAN  \\\n",
       "0                             0.750000                              0.375000   \n",
       "1                             1.000000                              0.455357   \n",
       "2                             1.000000                              0.437500   \n",
       "3                             1.000000                              0.428571   \n",
       "4                             1.000000                              0.442439   \n",
       "\n",
       "   POS_NAME_CONTRACT_STATUS_MODE  POS_COUNT  POS_ACTIVE_COUNT  \\\n",
       "0                       0.000000  19.000000          1.000000   \n",
       "1                       0.000000  28.000000          3.000000   \n",
       "2                       0.000000   4.000000          1.000000   \n",
       "3                       0.000000  21.000000          3.000000   \n",
       "4                       0.000000  66.000000          5.000000   \n",
       "\n",
       "   POS_RECENT_SK_DPD_MAX  POS_RECENT_SK_DPD_MEAN  POS_RECENT_POS_IS_DPD_MEAN  \\\n",
       "0               0.000000                0.000000                    0.000000   \n",
       "1                    NaN                     NaN                         NaN   \n",
       "2                    NaN                     NaN                         NaN   \n",
       "3               0.000000                0.000000                    0.000000   \n",
       "4               0.000000                0.000000                    0.000000   \n",
       "\n",
       "   POS_RECENT_POS_IS_DPD_SUM  POS_RECENT_POS_IS_DPD_OVER_30_MEAN  \\\n",
       "0                   0.000000                            0.000000   \n",
       "1                        NaN                                 NaN   \n",
       "2                        NaN                                 NaN   \n",
       "3                   0.000000                            0.000000   \n",
       "4                   0.000000                            0.000000   \n",
       "\n",
       "   POS_RECENT_POS_IS_DPD_OVER_30_SUM  INSTAL_NUM_INSTALMENT_VERSION_NUNIQUE  \\\n",
       "0                           0.000000                               2.000000   \n",
       "1                                NaN                               2.000000   \n",
       "2                                NaN                               2.000000   \n",
       "3                           0.000000                               2.000000   \n",
       "4                           0.000000                               2.000000   \n",
       "\n",
       "   INSTAL_DPD_MAX  INSTAL_DPD_MEAN  INSTAL_DPD_SUM  INSTAL_DBD_MAX  \\\n",
       "0        0.000000         0.000000        0.000000       31.000000   \n",
       "1        0.000000         0.000000        0.000000       14.000000   \n",
       "2        0.000000         0.000000        0.000000       11.000000   \n",
       "3        0.000000         0.000000        0.000000       77.000000   \n",
       "4       12.000000         0.954545       63.000000       31.000000   \n",
       "\n",
       "   INSTAL_DBD_MEAN  INSTAL_DBD_SUM  INSTAL_PAYMENT_PERC_MIN  \\\n",
       "0        20.421053      388.000000                 1.000000   \n",
       "1         7.160000      179.000000                 1.000000   \n",
       "2         7.666667       23.000000                 1.000000   \n",
       "3        19.375000      310.000000                 1.000000   \n",
       "4         4.590909      303.000000                 0.000050   \n",
       "\n",
       "   INSTAL_PAYMENT_PERC_MAX  INSTAL_PAYMENT_PERC_MEAN  INSTAL_PAYMENT_PERC_VAR  \\\n",
       "0                 1.000000                  1.000000                 0.000000   \n",
       "1                 1.000000                  1.000000                 0.000000   \n",
       "2                 1.000000                  1.000000                 0.000000   \n",
       "3                 1.000000                  1.000000                 0.000000   \n",
       "4                 1.000000                  0.954545                 0.043995   \n",
       "\n",
       "   INSTAL_PAYMENT_DIFF_MAX  INSTAL_PAYMENT_DIFF_MEAN  INSTAL_PAYMENT_DIFF_SUM  \\\n",
       "0                 0.000000                  0.000000                 0.000000   \n",
       "1                 0.000000                  0.000000                 0.000000   \n",
       "2                 0.000000                  0.000000                 0.000000   \n",
       "3                 0.000000                  0.000000                 0.000000   \n",
       "4             22655.655000                452.384318             29857.365000   \n",
       "\n",
       "   INSTAL_PAYMENT_DIFF_VAR  INSTAL_AMT_INSTALMENT_MIN  \\\n",
       "0                 0.000000                9251.775000   \n",
       "1                 0.000000                6662.970000   \n",
       "2                 0.000000                5357.250000   \n",
       "3                 0.000000                2482.920000   \n",
       "4           8084829.772595                1821.780000   \n",
       "\n",
       "   INSTAL_AMT_INSTALMENT_MAX  INSTAL_AMT_INSTALMENT_MEAN  \\\n",
       "0               53093.745000                11559.247105   \n",
       "1              560835.360000                64754.586000   \n",
       "2               10573.965000                 7096.155000   \n",
       "3              691786.890000                62947.088438   \n",
       "4               22678.785000                12666.444545   \n",
       "\n",
       "   INSTAL_AMT_INSTALMENT_SUM  INSTAL_AMT_PAYMENT_MIN  INSTAL_AMT_PAYMENT_MAX  \\\n",
       "0              219625.695000             9251.775000            53093.745000   \n",
       "1             1618864.650000             6662.970000           560835.360000   \n",
       "2               21288.465000             5357.250000            10573.965000   \n",
       "3             1007153.415000             2482.920000           691786.890000   \n",
       "4              835985.340000                0.180000            22678.785000   \n",
       "\n",
       "   INSTAL_AMT_PAYMENT_MEAN  INSTAL_AMT_PAYMENT_SUM  \\\n",
       "0             11559.247105           219625.695000   \n",
       "1             64754.586000          1618864.650000   \n",
       "2              7096.155000            21288.465000   \n",
       "3             62947.088438          1007153.415000   \n",
       "4             12214.060227           806127.975000   \n",
       "\n",
       "   INSTAL_DAYS_ENTRY_PAYMENT_MAX  INSTAL_DAYS_ENTRY_PAYMENT_MEAN  \\\n",
       "0                     -49.000000                     -315.421053   \n",
       "1                    -544.000000                    -1385.320000   \n",
       "2                    -727.000000                     -761.666667   \n",
       "3                     -12.000000                     -271.625000   \n",
       "4                     -14.000000                    -1032.242424   \n",
       "\n",
       "   INSTAL_DAYS_ENTRY_PAYMENT_SUM  INSTAL_DAYS_INSTALMENT_MAX  \\\n",
       "0                   -5993.000000                  -25.000000   \n",
       "1                  -34633.000000                 -536.000000   \n",
       "2                   -2285.000000                 -724.000000   \n",
       "3                   -4346.000000                  -11.000000   \n",
       "4                  -68128.000000                  -14.000000   \n",
       "\n",
       "   INSTAL_DAYS_INSTALMENT_MEAN  INSTAL_DAYS_INSTALMENT_SUM  \\\n",
       "0                  -295.000000                -5605.000000   \n",
       "1                 -1378.160000               -34454.000000   \n",
       "2                  -754.000000                -2262.000000   \n",
       "3                  -252.250000                -4036.000000   \n",
       "4                 -1028.606061               -67888.000000   \n",
       "\n",
       "   INSTAL_INS_IS_DPD_MEAN  INSTAL_INS_IS_DPD_SUM  \\\n",
       "0                0.000000               0.000000   \n",
       "1                0.000000               0.000000   \n",
       "2                0.000000               0.000000   \n",
       "3                0.000000               0.000000   \n",
       "4                0.242424              16.000000   \n",
       "\n",
       "   INSTAL_INS_IS_DPD_UNDER_30_MEAN  INSTAL_INS_IS_DPD_UNDER_30_SUM  \\\n",
       "0                         0.000000                        0.000000   \n",
       "1                         0.000000                        0.000000   \n",
       "2                         0.000000                        0.000000   \n",
       "3                         0.000000                        0.000000   \n",
       "4                         0.242424                       16.000000   \n",
       "\n",
       "   INSTAL_INS_IS_DPD_OVER_30_MEAN  INSTAL_INS_IS_DPD_OVER_30_SUM  \\\n",
       "0                        0.000000                       0.000000   \n",
       "1                        0.000000                       0.000000   \n",
       "2                        0.000000                       0.000000   \n",
       "3                        0.000000                       0.000000   \n",
       "4                        0.000000                       0.000000   \n",
       "\n",
       "   INSTAL_INS_IS_EARLY_PAYMENT_MEAN  INSTAL_INS_IS_EARLY_PAYMENT_SUM  \\\n",
       "0                          1.000000                        19.000000   \n",
       "1                          0.480000                        12.000000   \n",
       "2                          0.666667                         2.000000   \n",
       "3                          0.437500                         7.000000   \n",
       "4                          0.242424                        16.000000   \n",
       "\n",
       "   INSTAL_PAYMENT_CONSISTENCY_MIN  INSTAL_PAYMENT_CONSISTENCY_MAX  \\\n",
       "0                        1.000000                        1.000000   \n",
       "1                        1.000000                        1.000000   \n",
       "2                        1.000000                        1.000000   \n",
       "3                        1.000000                        1.000000   \n",
       "4                        0.883609                        1.000000   \n",
       "\n",
       "   INSTAL_PAYMENT_CONSISTENCY_MEAN  INSTAL_COUNT  INSTAL_ACCOUNT_COUNT  \\\n",
       "0                         1.000000     19.000000              1.000000   \n",
       "1                         1.000000     25.000000              3.000000   \n",
       "2                         1.000000      3.000000              1.000000   \n",
       "3                         1.000000     16.000000              3.000000   \n",
       "4                         0.961271     66.000000              5.000000   \n",
       "\n",
       "   INSTAL_RECENT_PAYMENT_PERC_MEAN  INSTAL_RECENT_PAYMENT_PERC_MIN  \\\n",
       "0                         1.000000                        1.000000   \n",
       "1                              NaN                             NaN   \n",
       "2                              NaN                             NaN   \n",
       "3                         1.000000                        1.000000   \n",
       "4                         1.000000                        1.000000   \n",
       "\n",
       "   INSTAL_RECENT_DPD_MAX  INSTAL_RECENT_DPD_MEAN  \\\n",
       "0               0.000000                0.000000   \n",
       "1                    NaN                     NaN   \n",
       "2                    NaN                     NaN   \n",
       "3               0.000000                0.000000   \n",
       "4               0.000000                0.000000   \n",
       "\n",
       "   INSTAL_RECENT_INS_IS_DPD_MEAN  INSTAL_RECENT_INS_IS_DPD_SUM  \\\n",
       "0                       0.000000                      0.000000   \n",
       "1                            NaN                           NaN   \n",
       "2                            NaN                           NaN   \n",
       "3                       0.000000                      0.000000   \n",
       "4                       0.000000                      0.000000   \n",
       "\n",
       "   INSTAL_RECENT_INS_IS_EARLY_PAYMENT_MEAN  \n",
       "0                                 1.000000  \n",
       "1                                      NaN  \n",
       "2                                      NaN  \n",
       "3                                 0.181818  \n",
       "4                                 0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644a9d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:42.116831Z",
     "iopub.status.busy": "2025-10-15T15:38:42.116467Z",
     "iopub.status.idle": "2025-10-15T15:38:53.216147Z",
     "shell.execute_reply": "2025-10-15T15:38:53.215067Z"
    },
    "papermill": {
     "duration": 11.124348,
     "end_time": "2025-10-15T15:38:53.217784",
     "exception": false,
     "start_time": "2025-10-15T15:38:42.093436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Unique_values</th>\n",
       "      <th>Percentage_of_null</th>\n",
       "      <th>Percentage_of_mode</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ACTIVE_AMT_ANNUITY_VAR</td>\n",
       "      <td>18542</td>\n",
       "      <td>88.743020</td>\n",
       "      <td>88.743020</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>CLOSED_AMT_ANNUITY_VAR</td>\n",
       "      <td>19909</td>\n",
       "      <td>85.495940</td>\n",
       "      <td>85.495940</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>ACTIVE_AMT_CREDIT_MAX_OVERDUE_VAR</td>\n",
       "      <td>15252</td>\n",
       "      <td>85.121640</td>\n",
       "      <td>85.121640</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>ACTIVE_LIMIT_USAGE_RATIO</td>\n",
       "      <td>42717</td>\n",
       "      <td>84.781485</td>\n",
       "      <td>84.781485</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>BURO_LIMIT_USAGE_RATIO</td>\n",
       "      <td>44645</td>\n",
       "      <td>84.113532</td>\n",
       "      <td>84.113532</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NAME_EDUCATION_TYPE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.019196</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NAME_FAMILY_STATUS</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.877895</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NAME_HOUSING_TYPE</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.734565</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>nn_oof_single_past</td>\n",
       "      <td>303361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SK_ID_CURR</td>\n",
       "      <td>307507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature  Unique_values  Percentage_of_null  \\\n",
       "295             ACTIVE_AMT_ANNUITY_VAR          18542           88.743020   \n",
       "345             CLOSED_AMT_ANNUITY_VAR          19909           85.495940   \n",
       "272  ACTIVE_AMT_CREDIT_MAX_OVERDUE_VAR          15252           85.121640   \n",
       "356           ACTIVE_LIMIT_USAGE_RATIO          42717           84.781485   \n",
       "351             BURO_LIMIT_USAGE_RATIO          44645           84.113532   \n",
       "..                                 ...            ...                 ...   \n",
       "13                 NAME_EDUCATION_TYPE              5            0.000000   \n",
       "14                  NAME_FAMILY_STATUS              6            0.000000   \n",
       "15                   NAME_HOUSING_TYPE              6            0.000000   \n",
       "176                 nn_oof_single_past         303361            0.000000   \n",
       "0                           SK_ID_CURR         307507            0.000000   \n",
       "\n",
       "     Percentage_of_mode     Type  \n",
       "295           88.743020  float64  \n",
       "345           85.495940  float64  \n",
       "272           85.121640  float64  \n",
       "356           84.781485  float64  \n",
       "351           84.113532  float64  \n",
       "..                  ...      ...  \n",
       "13            71.019196    int64  \n",
       "14            63.877895    int64  \n",
       "15            88.734565    int64  \n",
       "176            0.016260  float64  \n",
       "0              0.000325    int64  \n",
       "\n",
       "[561 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_statics(df):\n",
    "    # è¯»å…¥æ•°æ®\n",
    "    stats = []\n",
    "    for col in df.columns:\n",
    "        stats.append((col, df[col].nunique(), \n",
    "                      (df[col].isnull()).sum() * 100 / df.shape[0],\n",
    "                      df[col].value_counts(normalize=True, dropna=False).values[0] * 100, \n",
    "                      df[col].dtype))\n",
    "\n",
    "    stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique_values', 'Percentage_of_null',\n",
    "                                            'Percentage_of_mode', 'Type'])\n",
    "    stats_df.sort_values('Unique_values', ascending=False, inplace=True)\n",
    "    return stats_df\n",
    "sts_df = simple_statics(train_df)\n",
    "sts_df.sort_values(by=['Percentage_of_null'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb0d181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:53.266175Z",
     "iopub.status.busy": "2025-10-15T15:38:53.265460Z",
     "iopub.status.idle": "2025-10-15T15:38:53.280645Z",
     "shell.execute_reply": "2025-10-15T15:38:53.279491Z"
    },
    "papermill": {
     "duration": 0.040582,
     "end_time": "2025-10-15T15:38:53.282710",
     "exception": false,
     "start_time": "2025-10-15T15:38:53.242128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Unique_values</th>\n",
       "      <th>Percentage_of_null</th>\n",
       "      <th>Percentage_of_mode</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>pos_bal_preds_TARGET_std</td>\n",
       "      <td>234812</td>\n",
       "      <td>5.990108</td>\n",
       "      <td>5.990108</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>POS_INSTALMENT_PROGRESS_SUM</td>\n",
       "      <td>2019</td>\n",
       "      <td>5.875313</td>\n",
       "      <td>5.875313</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>POS_POS_IS_SEVERE_DPD_MEAN</td>\n",
       "      <td>1258</td>\n",
       "      <td>5.875313</td>\n",
       "      <td>81.152949</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>POS_POS_IS_DPD_OVER_120_MEAN</td>\n",
       "      <td>1701</td>\n",
       "      <td>5.875313</td>\n",
       "      <td>92.718540</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>POS_POS_IS_DPD_OVER_30_MEAN</td>\n",
       "      <td>1836</td>\n",
       "      <td>5.875313</td>\n",
       "      <td>91.791732</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NAME_INCOME_TYPE</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.631670</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>WALLSMATERIAL_MODE</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.841119</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>cnt_cut</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.940548</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNT_CHILDREN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.037105</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FLAG_DOCUMENT_4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.991870</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature  Unique_values  Percentage_of_null  \\\n",
       "161      pos_bal_preds_TARGET_std         234812            5.990108   \n",
       "499   POS_INSTALMENT_PROGRESS_SUM           2019            5.875313   \n",
       "494    POS_POS_IS_SEVERE_DPD_MEAN           1258            5.875313   \n",
       "492  POS_POS_IS_DPD_OVER_120_MEAN           1701            5.875313   \n",
       "490   POS_POS_IS_DPD_OVER_30_MEAN           1836            5.875313   \n",
       "..                            ...            ...                 ...   \n",
       "12               NAME_INCOME_TYPE              8            0.000000   \n",
       "89             WALLSMATERIAL_MODE              8            0.000000   \n",
       "179                       cnt_cut             10            0.000000   \n",
       "6                    CNT_CHILDREN             15            0.000000   \n",
       "98                FLAG_DOCUMENT_4              2            0.000000   \n",
       "\n",
       "     Percentage_of_mode     Type  \n",
       "161            5.990108  float64  \n",
       "499            5.875313  float64  \n",
       "494           81.152949  float64  \n",
       "492           92.718540  float64  \n",
       "490           91.791732  float64  \n",
       "..                  ...      ...  \n",
       "12            51.631670    int64  \n",
       "89            50.841119    int64  \n",
       "179           25.940548  float64  \n",
       "6             70.037105    int64  \n",
       "98            99.991870    int64  \n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_df[sts_df['Percentage_of_null']<10.0].sort_values(by=['Percentage_of_null'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d769920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:53.329858Z",
     "iopub.status.busy": "2025-10-15T15:38:53.329473Z",
     "iopub.status.idle": "2025-10-15T15:38:53.769301Z",
     "shell.execute_reply": "2025-10-15T15:38:53.768068Z"
    },
    "papermill": {
     "duration": 0.465485,
     "end_time": "2025-10-15T15:38:53.771214",
     "exception": false,
     "start_time": "2025-10-15T15:38:53.305729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='TARGET'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yflag = 'TARGET'\n",
    "plt.figure(figsize=(10,6))\n",
    "train_df['TARGET'].value_counts(dropna=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ead965d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:53.819934Z",
     "iopub.status.busy": "2025-10-15T15:38:53.819129Z",
     "iopub.status.idle": "2025-10-15T15:38:53.835189Z",
     "shell.execute_reply": "2025-10-15T15:38:53.834032Z"
    },
    "papermill": {
     "duration": 0.041719,
     "end_time": "2025-10-15T15:38:53.837214",
     "exception": false,
     "start_time": "2025-10-15T15:38:53.795495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    282682\n",
       "1     24825\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['TARGET'] = train_df['TARGET'].map({0.0:0,1.0:1})\n",
    "train_df['TARGET'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8aedf1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:53.886567Z",
     "iopub.status.busy": "2025-10-15T15:38:53.886235Z",
     "iopub.status.idle": "2025-10-15T15:38:55.939641Z",
     "shell.execute_reply": "2025-10-15T15:38:55.938480Z"
    },
    "papermill": {
     "duration": 2.079323,
     "end_time": "2025-10-15T15:38:55.941648",
     "exception": false,
     "start_time": "2025-10-15T15:38:53.862325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float&intå‹å˜é‡å…± 559\n",
      "intç±»å‹å˜é‡å…± 55\n"
     ]
    }
   ],
   "source": [
    "col = train_df.columns.difference([yflag,'SK_ID_CURR'])\n",
    "# ç­›é€‰floatçš„æ•°å€¼ç±»å‹å˜é‡\n",
    "num_list = train_df[col].select_dtypes(include=['float','int']).columns.tolist()\n",
    "# ç­›é€‰intå­—ç¬¦å‹çš„æ•°å€¼ç±»å‹å˜é‡\n",
    "int_list = train_df[col].select_dtypes(include=['int']).columns.tolist()\n",
    "print('float&intå‹å˜é‡å…±',len(num_list))\n",
    "print('intç±»å‹å˜é‡å…±',len(int_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c1829",
   "metadata": {
    "papermill": {
     "duration": 0.02296,
     "end_time": "2025-10-15T15:38:55.987802",
     "exception": false,
     "start_time": "2025-10-15T15:38:55.964842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**IV_Calculate and Feature Selection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f22c2102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:56.036047Z",
     "iopub.status.busy": "2025-10-15T15:38:56.035660Z",
     "iopub.status.idle": "2025-10-15T15:38:56.044202Z",
     "shell.execute_reply": "2025-10-15T15:38:56.043133Z"
    },
    "papermill": {
     "duration": 0.035066,
     "end_time": "2025-10-15T15:38:56.045751",
     "exception": false,
     "start_time": "2025-10-15T15:38:56.010685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_iv(df0, var_iv, y_flag, breaks_list, stop_limit0):\n",
    "    \"\"\"\n",
    "    åˆ†ç®±å¹¶è®¡ç®—IVå€¼\n",
    "    :param df0: DFæ ¼å¼çš„æ•°æ®\n",
    "    :param var_iv: éœ€è¦è®¡ç®—ivçš„åˆ—çš„åˆ—è¡¨\n",
    "    :param y_flag: yæ ‡ç­¾\n",
    "    :return iv_df: variableå’Œivå€¼\n",
    "    :return bins_base: å­—å…¸ï¼Œåˆ†ç®±å€¼\n",
    "    \"\"\"\n",
    "    iv_list = []\n",
    "    bins_base = sc.woebin(df0[var_iv + [y_flag]], y=y_flag, breaks_list=breaks_list, method='tree', stop_limit=stop_limit0)\n",
    "    # åˆ†ç®±å¯è§†åŒ–å›¾\n",
    "    # bins_show = sc.woebin_plot(bins_base)\n",
    "    for col, iv_df_i in bins_base.items():\n",
    "        iv_df_i['bad_distr'] = iv_df_i['bad']/iv_df_i['bad'].sum() #è¾¹é™…åå æ¯”\n",
    "        iv_df_i['good_distr'] = iv_df_i['good']/iv_df_i['good'].sum() #è¾¹é™…å¥½å æ¯”\n",
    "        iv_df_i = iv_df_i.rename(columns={'variable':'å˜é‡å','bin':'åˆ†ç®±','count':'åˆ†ç®±å®¢æˆ·æ•°','count_distr':'åˆ†ç®±å®¢æˆ·æ•°å æ¯”',\n",
    "                                         'good':'å¥½å®¢æˆ·æ•°','bad':'åå®¢æˆ·æ•°','badprob':'åŒºé—´åè´¦ç‡','bad_distr':'è¾¹é™…åå®¢æˆ·å æ¯”',\n",
    "                                         'good_distr':'è¾¹é™…å¥½å®¢æˆ·å æ¯”'})\n",
    "        iv_df_i = iv_df_i[['å˜é‡å','åˆ†ç®±','åˆ†ç®±å®¢æˆ·æ•°','å¥½å®¢æˆ·æ•°','åå®¢æˆ·æ•°','åˆ†ç®±å®¢æˆ·æ•°å æ¯”','è¾¹é™…å¥½å®¢æˆ·å æ¯”','è¾¹é™…åå®¢æˆ·å æ¯”',\n",
    "                           'åŒºé—´åè´¦ç‡','woe','bin_iv','total_iv']]\n",
    "        bins_base[col] = iv_df_i\n",
    "        iv_list.append((col,iv_df_i['total_iv'][0])) \n",
    "    iv_df = pd.DataFrame.from_records(iv_list,columns=['variable','iv_train'])\n",
    "    iv_df = iv_df.sort_values(by=['iv_train'], ascending=False)\n",
    "    return iv_df, bins_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1e0c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:38:56.093371Z",
     "iopub.status.busy": "2025-10-15T15:38:56.092349Z",
     "iopub.status.idle": "2025-10-15T15:54:02.895643Z",
     "shell.execute_reply": "2025-10-15T15:54:02.893913Z"
    },
    "papermill": {
     "duration": 906.829118,
     "end_time": "2025-10-15T15:54:02.897790",
     "exception": false,
     "start_time": "2025-10-15T15:38:56.068672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n",
      "Binning on 307507 rows and 560 columns in 00:15:05\n"
     ]
    }
   ],
   "source": [
    "iv_table, bins_df = cal_iv(train_df, num_list, yflag ,breaks_list={}, stop_limit0=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10ab91be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:54:02.947625Z",
     "iopub.status.busy": "2025-10-15T15:54:02.947229Z",
     "iopub.status.idle": "2025-10-15T15:54:02.965837Z",
     "shell.execute_reply": "2025-10-15T15:54:02.964456Z"
    },
    "papermill": {
     "duration": 0.046265,
     "end_time": "2025-10-15T15:54:02.967768",
     "exception": false,
     "start_time": "2025-10-15T15:54:02.921503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>iv_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>nn_oof_single_past</td>\n",
       "      <td>0.633566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>prapp_preds_TARGET_mean.1</td>\n",
       "      <td>0.402925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>buro_preds_TARGET_mean</td>\n",
       "      <td>0.363674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>prapp_preds_TARGET_median.1</td>\n",
       "      <td>0.348302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.328647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>REGION_RATING_CLIENT_W_CITY</td>\n",
       "      <td>0.051204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>CLOSED_AMT_CREDIT_SUM_MEDIAN</td>\n",
       "      <td>0.050860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>BURO_DAYS_CREDIT_UPDATE_VAR</td>\n",
       "      <td>0.050420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>CLOSED_DAYS_CREDIT_MAX</td>\n",
       "      <td>0.050401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>INSTAL_DPD_MEAN</td>\n",
       "      <td>0.050310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         variable  iv_train\n",
       "543            nn_oof_single_past  0.633566\n",
       "194     prapp_preds_TARGET_mean.1  0.402925\n",
       "383        buro_preds_TARGET_mean  0.363674\n",
       "279   prapp_preds_TARGET_median.1  0.348302\n",
       "76                   EXT_SOURCE_3  0.328647\n",
       "..                            ...       ...\n",
       "330   REGION_RATING_CLIENT_W_CITY  0.051204\n",
       "181  CLOSED_AMT_CREDIT_SUM_MEDIAN  0.050860\n",
       "343   BURO_DAYS_CREDIT_UPDATE_VAR  0.050420\n",
       "512        CLOSED_DAYS_CREDIT_MAX  0.050401\n",
       "47                INSTAL_DPD_MEAN  0.050310\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_table[iv_table['iv_train']>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20d46d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:54:03.020096Z",
     "iopub.status.busy": "2025-10-15T15:54:03.019717Z",
     "iopub.status.idle": "2025-10-15T15:54:03.035750Z",
     "shell.execute_reply": "2025-10-15T15:54:03.034608Z"
    },
    "papermill": {
     "duration": 0.044356,
     "end_time": "2025-10-15T15:54:03.037571",
     "exception": false,
     "start_time": "2025-10-15T15:54:02.993215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>å˜é‡å</th>\n",
       "      <th>åˆ†ç®±</th>\n",
       "      <th>åˆ†ç®±å®¢æˆ·æ•°</th>\n",
       "      <th>å¥½å®¢æˆ·æ•°</th>\n",
       "      <th>åå®¢æˆ·æ•°</th>\n",
       "      <th>åˆ†ç®±å®¢æˆ·æ•°å æ¯”</th>\n",
       "      <th>è¾¹é™…å¥½å®¢æˆ·å æ¯”</th>\n",
       "      <th>è¾¹é™…åå®¢æˆ·å æ¯”</th>\n",
       "      <th>åŒºé—´åè´¦ç‡</th>\n",
       "      <th>woe</th>\n",
       "      <th>bin_iv</th>\n",
       "      <th>total_iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[-inf,40000.0)</td>\n",
       "      <td>16247</td>\n",
       "      <td>14614</td>\n",
       "      <td>1633</td>\n",
       "      <td>0.052835</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>0.065780</td>\n",
       "      <td>0.100511</td>\n",
       "      <td>0.240910</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[40000.0,60000.0)</td>\n",
       "      <td>29216</td>\n",
       "      <td>26606</td>\n",
       "      <td>2610</td>\n",
       "      <td>0.095009</td>\n",
       "      <td>0.094120</td>\n",
       "      <td>0.105136</td>\n",
       "      <td>0.089335</td>\n",
       "      <td>0.110685</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[60000.0,80000.0)</td>\n",
       "      <td>36512</td>\n",
       "      <td>33409</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.118736</td>\n",
       "      <td>0.118186</td>\n",
       "      <td>0.124995</td>\n",
       "      <td>0.084986</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[80000.0,160000.0)</td>\n",
       "      <td>136337</td>\n",
       "      <td>125314</td>\n",
       "      <td>11023</td>\n",
       "      <td>0.443362</td>\n",
       "      <td>0.443304</td>\n",
       "      <td>0.444028</td>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[160000.0,220000.0)</td>\n",
       "      <td>41462</td>\n",
       "      <td>38186</td>\n",
       "      <td>3276</td>\n",
       "      <td>0.134833</td>\n",
       "      <td>0.135085</td>\n",
       "      <td>0.131964</td>\n",
       "      <td>0.079012</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[220000.0,240000.0)</td>\n",
       "      <td>16082</td>\n",
       "      <td>14923</td>\n",
       "      <td>1159</td>\n",
       "      <td>0.052298</td>\n",
       "      <td>0.052791</td>\n",
       "      <td>0.046687</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>-0.122875</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[240000.0,300000.0)</td>\n",
       "      <td>16132</td>\n",
       "      <td>15021</td>\n",
       "      <td>1111</td>\n",
       "      <td>0.052461</td>\n",
       "      <td>0.053137</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.068869</td>\n",
       "      <td>-0.171717</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INCOME_PER_CHILD</td>\n",
       "      <td>[300000.0,inf)</td>\n",
       "      <td>15519</td>\n",
       "      <td>14609</td>\n",
       "      <td>910</td>\n",
       "      <td>0.050467</td>\n",
       "      <td>0.051680</td>\n",
       "      <td>0.036657</td>\n",
       "      <td>0.058638</td>\n",
       "      <td>-0.343477</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.012417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                å˜é‡å                   åˆ†ç®±   åˆ†ç®±å®¢æˆ·æ•°    å¥½å®¢æˆ·æ•°   åå®¢æˆ·æ•°  åˆ†ç®±å®¢æˆ·æ•°å æ¯”  \\\n",
       "0  INCOME_PER_CHILD       [-inf,40000.0)   16247   14614   1633 0.052835   \n",
       "1  INCOME_PER_CHILD    [40000.0,60000.0)   29216   26606   2610 0.095009   \n",
       "2  INCOME_PER_CHILD    [60000.0,80000.0)   36512   33409   3103 0.118736   \n",
       "3  INCOME_PER_CHILD   [80000.0,160000.0)  136337  125314  11023 0.443362   \n",
       "4  INCOME_PER_CHILD  [160000.0,220000.0)   41462   38186   3276 0.134833   \n",
       "5  INCOME_PER_CHILD  [220000.0,240000.0)   16082   14923   1159 0.052298   \n",
       "6  INCOME_PER_CHILD  [240000.0,300000.0)   16132   15021   1111 0.052461   \n",
       "7  INCOME_PER_CHILD       [300000.0,inf)   15519   14609    910 0.050467   \n",
       "\n",
       "   è¾¹é™…å¥½å®¢æˆ·å æ¯”  è¾¹é™…åå®¢æˆ·å æ¯”    åŒºé—´åè´¦ç‡       woe   bin_iv  total_iv  \n",
       "0 0.051698 0.065780 0.100511  0.240910 0.003393  0.012417  \n",
       "1 0.094120 0.105136 0.089335  0.110685 0.001219  0.012417  \n",
       "2 0.118186 0.124995 0.084986  0.056015 0.000381  0.012417  \n",
       "3 0.443304 0.444028 0.080851  0.001633 0.000001  0.012417  \n",
       "4 0.135085 0.131964 0.079012 -0.023374 0.000073  0.012417  \n",
       "5 0.052791 0.046687 0.072068 -0.122875 0.000750  0.012417  \n",
       "6 0.053137 0.044753 0.068869 -0.171717 0.001440  0.012417  \n",
       "7 0.051680 0.036657 0.058638 -0.343477 0.005160  0.012417  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_df['INCOME_PER_CHILD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edf167ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:54:03.088646Z",
     "iopub.status.busy": "2025-10-15T15:54:03.087844Z",
     "iopub.status.idle": "2025-10-15T15:54:03.351832Z",
     "shell.execute_reply": "2025-10-15T15:54:03.350623Z"
    },
    "papermill": {
     "duration": 0.291578,
     "end_time": "2025-10-15T15:54:03.353913",
     "exception": false,
     "start_time": "2025-10-15T15:54:03.062335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 315)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_select = iv_table[iv_table['iv_train']>0.02]\n",
    "cols =iv_select[\"variable\"].tolist()\n",
    "cols = cols+[\"TARGET\"]\n",
    "new_df = train_df[cols]\n",
    "# new_df.to_csv(\"selected_features.csv\", index=False)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff44c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:54:03.417261Z",
     "iopub.status.busy": "2025-10-15T15:54:03.416060Z",
     "iopub.status.idle": "2025-10-15T15:54:04.919656Z",
     "shell.execute_reply": "2025-10-15T15:54:04.918292Z"
    },
    "papermill": {
     "duration": 1.537017,
     "end_time": "2025-10-15T15:54:04.921458",
     "exception": false,
     "start_time": "2025-10-15T15:54:03.384441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307507, 315)\n",
      "(48744, 315)\n"
     ]
    }
   ],
   "source": [
    "test = test_df.reset_index()\n",
    "test_id = test['SK_ID_CURR']\n",
    "train_data = new_df.copy()\n",
    "features = new_df.columns.difference([\"TARGET\"]).tolist()\n",
    "X = train_data[features].values\n",
    "y = train_data[\"TARGET\"].astype('int32')\n",
    "test_data = test[cols]\n",
    "X_test = test_data[features].values\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0222f8",
   "metadata": {
    "papermill": {
     "duration": 0.024237,
     "end_time": "2025-10-15T15:54:04.969935",
     "exception": false,
     "start_time": "2025-10-15T15:54:04.945698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b01fe9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:54:05.020005Z",
     "iopub.status.busy": "2025-10-15T15:54:05.019627Z",
     "iopub.status.idle": "2025-10-15T15:54:07.484814Z",
     "shell.execute_reply": "2025-10-15T15:54:07.483497Z"
    },
    "papermill": {
     "duration": 2.492623,
     "end_time": "2025-10-15T15:54:07.486820",
     "exception": false,
     "start_time": "2025-10-15T15:54:04.994197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = new_df.columns.difference([\"TARGET\"]).tolist()\n",
    "X = train_data[features].values\n",
    "y = train_data[\"TARGET\"].astype('int32')\n",
    "X_test = test_data[features].values\n",
    "train = train_df[train_df['TARGET'].isnull()==False]\n",
    "test = train_df[train_df['TARGET'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9b083a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:54:07.539698Z",
     "iopub.status.busy": "2025-10-15T15:54:07.539350Z",
     "iopub.status.idle": "2025-10-15T16:50:28.147823Z",
     "shell.execute_reply": "2025-10-15T16:50:28.146793Z"
    },
    "papermill": {
     "duration": 3380.637803,
     "end_time": "2025-10-15T16:50:28.150274",
     "exception": false,
     "start_time": "2025-10-15T15:54:07.512471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 15:54:07,561] A new study created in memory with name: no-name-1f3a6e5c-746b-496a-a060-2a03b7304b75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.780226\tvalid's auc: 0.77607\n",
      "[200]\ttraining's auc: 0.786981\tvalid's auc: 0.781527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.786981\tvalid's auc: 0.781527\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7869814626015174)]), 'valid': OrderedDict([('auc', 0.7815267959609229)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.778033\tvalid's auc: 0.782575\n",
      "[200]\ttraining's auc: 0.784677\tvalid's auc: 0.789462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.784677\tvalid's auc: 0.789462\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7846770289281153)]), 'valid': OrderedDict([('auc', 0.7894622992035392)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.780658\tvalid's auc: 0.775431\n",
      "[200]\ttraining's auc: 0.787537\tvalid's auc: 0.780849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.787537\tvalid's auc: 0.780849\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7875374813563436)]), 'valid': OrderedDict([('auc', 0.7808485634049924)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.77842\tvalid's auc: 0.780511\n",
      "[200]\ttraining's auc: 0.785101\tvalid's auc: 0.78692\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.785101\tvalid's auc: 0.78692\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7851012543127212)]), 'valid': OrderedDict([('auc', 0.7869202216563062)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.780225\tvalid's auc: 0.776067\n",
      "[200]\ttraining's auc: 0.786463\tvalid's auc: 0.781509\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.786443\tvalid's auc: 0.781522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 15:55:58,497] Trial 0 finished with value: 0.7840559728479592 and parameters: {'num_leaves': 2, 'learning_rate': 0.1628801346586687, 'lambda_l1': 2.2982771847087946, 'lambda_l2': 0.9121895932560898, 'bagging_freq': 4, 'bagging_fraction': 0.5788539819791355, 'feature_fraction': 0.687047845222509, 'max_depth': 3, 'min_sum_hessian_in_leaf': 2.143223368683566, 'min_split_gain': 3.3768686504709295, 'min_data_in_leaf': 3861, 'max_bin': 17}. Best is trial 0 with value: 0.7840559728479592.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7864434472809673)]), 'valid': OrderedDict([('auc', 0.7815219840140357)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.795885\tvalid's auc: 0.78651\n",
      "[200]\ttraining's auc: 0.805378\tvalid's auc: 0.791198\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.805378\tvalid's auc: 0.791198\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8053782371045571)]), 'valid': OrderedDict([('auc', 0.7911975333783591)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79451\tvalid's auc: 0.793578\n",
      "[200]\ttraining's auc: 0.803535\tvalid's auc: 0.79818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.803535\tvalid's auc: 0.79818\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8035348051006941)]), 'valid': OrderedDict([('auc', 0.7981796911115663)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796666\tvalid's auc: 0.783853\n",
      "[200]\ttraining's auc: 0.806005\tvalid's auc: 0.788553\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.806005\tvalid's auc: 0.788553\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8060048177220023)]), 'valid': OrderedDict([('auc', 0.7885531642111734)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.795105\tvalid's auc: 0.790759\n",
      "[200]\ttraining's auc: 0.804484\tvalid's auc: 0.795285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.804484\tvalid's auc: 0.795285\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8044838846944753)]), 'valid': OrderedDict([('auc', 0.7952854714856264)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796561\tvalid's auc: 0.786386\n",
      "[200]\ttraining's auc: 0.80598\tvalid's auc: 0.791393\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.80598\tvalid's auc: 0.791393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 15:58:04,377] Trial 1 finished with value: 0.7929218173329626 and parameters: {'num_leaves': 10, 'learning_rate': 0.11278259533951628, 'lambda_l1': 0.3204936606144263, 'lambda_l2': 0.2545308521342491, 'bagging_freq': 4, 'bagging_fraction': 0.7596117546688642, 'feature_fraction': 0.8971267471982048, 'max_depth': 3, 'min_sum_hessian_in_leaf': 3.7690154479208475, 'min_split_gain': 4.608264298450646, 'min_data_in_leaf': 1118, 'max_bin': 16}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8059804147681012)]), 'valid': OrderedDict([('auc', 0.7913932264780875)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.772692\tvalid's auc: 0.766079\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's auc: 0.772692\tvalid's auc: 0.766079\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7726916009403818)]), 'valid': OrderedDict([('auc', 0.766078544647775)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.770899\tvalid's auc: 0.771694\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's auc: 0.770899\tvalid's auc: 0.771694\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7708985517962891)]), 'valid': OrderedDict([('auc', 0.7716944037628238)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.7722\tvalid's auc: 0.764\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's auc: 0.7722\tvalid's auc: 0.764\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7721997948833756)]), 'valid': OrderedDict([('auc', 0.7640002552179677)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.77032\tvalid's auc: 0.770802\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's auc: 0.77032\tvalid's auc: 0.770802\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7703203539632432)]), 'valid': OrderedDict([('auc', 0.7708022130575555)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.77162\tvalid's auc: 0.767415\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's auc: 0.77162\tvalid's auc: 0.767415\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7716196963686508)]), 'valid': OrderedDict([('auc', 0.7674153487886266)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:00:46,866] Trial 2 finished with value: 0.7679981530949497 and parameters: {'num_leaves': 5, 'learning_rate': 0.19942627005125105, 'lambda_l1': 0.9201994816533315, 'lambda_l2': 0.5532802231935925, 'bagging_freq': 9, 'bagging_fraction': 0.7890137542833551, 'feature_fraction': 0.46281124199623763, 'max_depth': 3, 'min_sum_hessian_in_leaf': 2.1394970353151885, 'min_split_gain': 8.670606370122568, 'min_data_in_leaf': 2727, 'max_bin': 4}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.792363\tvalid's auc: 0.783462\n",
      "[200]\ttraining's auc: 0.800667\tvalid's auc: 0.788302\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.800667\tvalid's auc: 0.788302\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8006667457539619)]), 'valid': OrderedDict([('auc', 0.7883019365389519)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.790104\tvalid's auc: 0.791253\n",
      "[200]\ttraining's auc: 0.798374\tvalid's auc: 0.797596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.798374\tvalid's auc: 0.797596\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7983742310614149)]), 'valid': OrderedDict([('auc', 0.7975958493685595)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.793085\tvalid's auc: 0.782381\n",
      "[200]\ttraining's auc: 0.800943\tvalid's auc: 0.7879\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.800943\tvalid's auc: 0.7879\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8009433620888301)]), 'valid': OrderedDict([('auc', 0.7878998147639106)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.791075\tvalid's auc: 0.788707\n",
      "[200]\ttraining's auc: 0.799123\tvalid's auc: 0.794468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.799123\tvalid's auc: 0.794468\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7991229930162398)]), 'valid': OrderedDict([('auc', 0.7944678584248506)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.792158\tvalid's auc: 0.783756\n",
      "[200]\ttraining's auc: 0.800381\tvalid's auc: 0.789032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.800381\tvalid's auc: 0.789032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:04:10,371] Trial 3 finished with value: 0.7914594549119149 and parameters: {'num_leaves': 10, 'learning_rate': 0.08956777811421235, 'lambda_l1': 8.896660727867916, 'lambda_l2': 3.490214798346491, 'bagging_freq': 8, 'bagging_fraction': 0.8332119324900177, 'feature_fraction': 0.5582965764203494, 'max_depth': 3, 'min_sum_hessian_in_leaf': 2.448018748912628, 'min_split_gain': 6.197696019927, 'min_data_in_leaf': 4385, 'max_bin': 29}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8003811345073987)]), 'valid': OrderedDict([('auc', 0.7890318154633018)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.782239\tvalid's auc: 0.777492\n",
      "[200]\ttraining's auc: 0.79018\tvalid's auc: 0.783785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.79018\tvalid's auc: 0.783785\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7901797481439256)]), 'valid': OrderedDict([('auc', 0.7837850859050302)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.780533\tvalid's auc: 0.783163\n",
      "[200]\ttraining's auc: 0.788331\tvalid's auc: 0.790168\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.788331\tvalid's auc: 0.790168\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7883306035747769)]), 'valid': OrderedDict([('auc', 0.790168115450102)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.782622\tvalid's auc: 0.775643\n",
      "[200]\ttraining's auc: 0.790842\tvalid's auc: 0.7818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.790842\tvalid's auc: 0.7818\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.790841719243677)]), 'valid': OrderedDict([('auc', 0.7817995709602138)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.78064\tvalid's auc: 0.781691\n",
      "[200]\ttraining's auc: 0.788807\tvalid's auc: 0.788779\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.788807\tvalid's auc: 0.788779\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7888066527154801)]), 'valid': OrderedDict([('auc', 0.7887794581883572)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.782029\tvalid's auc: 0.776852\n",
      "[200]\ttraining's auc: 0.790157\tvalid's auc: 0.783089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.790157\tvalid's auc: 0.783089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:06:19,626] Trial 4 finished with value: 0.7855243434780376 and parameters: {'num_leaves': 9, 'learning_rate': 0.06884908046197354, 'lambda_l1': 5.386987348739207, 'lambda_l2': 5.852142483005456, 'bagging_freq': 10, 'bagging_fraction': 0.9685464768990265, 'feature_fraction': 0.8165152038614982, 'max_depth': 2, 'min_sum_hessian_in_leaf': 2.14183597833502, 'min_split_gain': 7.578293601669682, 'min_data_in_leaf': 2823, 'max_bin': 22}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7901574577444372)]), 'valid': OrderedDict([('auc', 0.7830894868864847)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:06:27,751] Trial 5 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.792474\tvalid's auc: 0.783958\n",
      "[200]\ttraining's auc: 0.797185\tvalid's auc: 0.786595\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[160]\ttraining's auc: 0.797185\tvalid's auc: 0.786595\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7971849300316792)]), 'valid': OrderedDict([('auc', 0.7865945571099863)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.790706\tvalid's auc: 0.791922\n",
      "[200]\ttraining's auc: 0.794936\tvalid's auc: 0.795316\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[160]\ttraining's auc: 0.794936\tvalid's auc: 0.795316\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7949361335579573)]), 'valid': OrderedDict([('auc', 0.795315693146149)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.792906\tvalid's auc: 0.783319\n",
      "[200]\ttraining's auc: 0.797716\tvalid's auc: 0.786431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[168]\ttraining's auc: 0.797716\tvalid's auc: 0.786431\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.797716455069455)]), 'valid': OrderedDict([('auc', 0.7864314991982223)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.791176\tvalid's auc: 0.789438\n",
      "[200]\ttraining's auc: 0.795791\tvalid's auc: 0.792531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[157]\ttraining's auc: 0.795791\tvalid's auc: 0.792531\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7957911225687433)]), 'valid': OrderedDict([('auc', 0.7925313190636422)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.792573\tvalid's auc: 0.784451\n",
      "[200]\ttraining's auc: 0.797317\tvalid's auc: 0.787447\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[174]\ttraining's auc: 0.797317\tvalid's auc: 0.787447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:08:45,293] Trial 6 finished with value: 0.7896640327029603 and parameters: {'num_leaves': 6, 'learning_rate': 0.12486658351638635, 'lambda_l1': 9.409310464312592, 'lambda_l2': 2.3349253878590592, 'bagging_freq': 9, 'bagging_fraction': 0.9516088082927923, 'feature_fraction': 0.6472832400626295, 'max_depth': 3, 'min_sum_hessian_in_leaf': 2.340534216924779, 'min_split_gain': 6.763750472704012, 'min_data_in_leaf': 565, 'max_bin': 11}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.7973172839736744)]), 'valid': OrderedDict([('auc', 0.7874470949968015)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:08:53,604] Trial 7 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796491\tvalid's auc: 0.786696\n",
      "[200]\ttraining's auc: 0.803705\tvalid's auc: 0.790139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.803705\tvalid's auc: 0.790139\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8037047261138166)]), 'valid': OrderedDict([('auc', 0.7901391135974355)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.794277\tvalid's auc: 0.795057\n",
      "[200]\ttraining's auc: 0.801886\tvalid's auc: 0.798212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.801886\tvalid's auc: 0.798212\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8018859449875276)]), 'valid': OrderedDict([('auc', 0.7982117816027615)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796437\tvalid's auc: 0.785419\n",
      "[200]\ttraining's auc: 0.80443\tvalid's auc: 0.78945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.80443\tvalid's auc: 0.78945\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8044297887339203)]), 'valid': OrderedDict([('auc', 0.7894496369164596)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.794499\tvalid's auc: 0.792643\n",
      "[200]\ttraining's auc: 0.801805\tvalid's auc: 0.795412\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.801805\tvalid's auc: 0.795412\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8018054166969588)]), 'valid': OrderedDict([('auc', 0.7954124107182426)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796593\tvalid's auc: 0.787517\n",
      "[200]\ttraining's auc: 0.804425\tvalid's auc: 0.790723\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.804425\tvalid's auc: 0.790723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:10:45,107] Trial 8 finished with value: 0.7927871211668359 and parameters: {'num_leaves': 5, 'learning_rate': 0.17799027147038537, 'lambda_l1': 0.3257228833234632, 'lambda_l2': 0.1972072594922827, 'bagging_freq': 10, 'bagging_fraction': 0.5758069324829704, 'feature_fraction': 0.8369976372682881, 'max_depth': 3, 'min_sum_hessian_in_leaf': 2.7171350931308296, 'min_split_gain': 2.617552574092265, 'min_data_in_leaf': 3295, 'max_bin': 20}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8044251875747747)]), 'valid': OrderedDict([('auc', 0.79072266299928)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:10:53,345] Trial 9 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:11:01,028] Trial 10 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:11:08,945] Trial 11 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801002\tvalid's auc: 0.78828\n",
      "[200]\ttraining's auc: 0.807864\tvalid's auc: 0.789753\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[188]\ttraining's auc: 0.80734\tvalid's auc: 0.789853\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8073399092905239)]), 'valid': OrderedDict([('auc', 0.7898530244459684)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798402\tvalid's auc: 0.796525\n",
      "[200]\ttraining's auc: 0.805413\tvalid's auc: 0.797916\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[189]\ttraining's auc: 0.80496\tvalid's auc: 0.797934\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8049598316919045)]), 'valid': OrderedDict([('auc', 0.7979337257614237)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801275\tvalid's auc: 0.786982\n",
      "[200]\ttraining's auc: 0.808429\tvalid's auc: 0.788819\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.808409\tvalid's auc: 0.788819\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8084092200629794)]), 'valid': OrderedDict([('auc', 0.788818670697714)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799425\tvalid's auc: 0.793148\n",
      "[200]\ttraining's auc: 0.806164\tvalid's auc: 0.795131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.806126\tvalid's auc: 0.795168\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8061255640277446)]), 'valid': OrderedDict([('auc', 0.7951677840824644)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801348\tvalid's auc: 0.788156\n",
      "[200]\ttraining's auc: 0.807732\tvalid's auc: 0.789983\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[179]\ttraining's auc: 0.806708\tvalid's auc: 0.790265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:12:56,829] Trial 12 finished with value: 0.7924076093420785 and parameters: {'num_leaves': 7, 'learning_rate': 0.19647553656087194, 'lambda_l1': 0.38258456669354035, 'lambda_l2': 0.33919583687478794, 'bagging_freq': 4, 'bagging_fraction': 0.5057589887637018, 'feature_fraction': 0.8319335514792452, 'max_depth': 3, 'min_sum_hessian_in_leaf': 2.9272066317779766, 'min_split_gain': 4.554498144880043, 'min_data_in_leaf': 1668, 'max_bin': 18}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8067081787631085)]), 'valid': OrderedDict([('auc', 0.7902648417228224)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796167\tvalid's auc: 0.78512\n",
      "[200]\ttraining's auc: 0.803903\tvalid's auc: 0.788786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.803903\tvalid's auc: 0.788786\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8039026255935527)]), 'valid': OrderedDict([('auc', 0.7887856201824965)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.793922\tvalid's auc: 0.793684\n",
      "[200]\ttraining's auc: 0.801293\tvalid's auc: 0.797794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[189]\ttraining's auc: 0.800737\tvalid's auc: 0.797815\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.800736609983208)]), 'valid': OrderedDict([('auc', 0.7978152424525137)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796148\tvalid's auc: 0.783448\n",
      "[200]\ttraining's auc: 0.804262\tvalid's auc: 0.787918\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.804262\tvalid's auc: 0.787918\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8042616350144769)]), 'valid': OrderedDict([('auc', 0.7879175417963954)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.794138\tvalid's auc: 0.7908\n",
      "[200]\ttraining's auc: 0.80178\tvalid's auc: 0.795212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[198]\ttraining's auc: 0.801721\tvalid's auc: 0.79522\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8017214954728646)]), 'valid': OrderedDict([('auc', 0.7952197717402317)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.795988\tvalid's auc: 0.787433\n",
      "[200]\ttraining's auc: 0.803569\tvalid's auc: 0.79126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.803569\tvalid's auc: 0.79126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:14:52,101] Trial 13 finished with value: 0.7921996678936774 and parameters: {'num_leaves': 10, 'learning_rate': 0.12944326372577084, 'lambda_l1': 0.543819013696297, 'lambda_l2': 0.16320060615419252, 'bagging_freq': 7, 'bagging_fraction': 0.6506491679215456, 'feature_fraction': 0.9558439452035696, 'max_depth': 3, 'min_sum_hessian_in_leaf': 3.7719948195920376, 'min_split_gain': 4.174097285852428, 'min_data_in_leaf': 3557, 'max_bin': 13}. Best is trial 1 with value: 0.7929218173329626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8035691956311695)]), 'valid': OrderedDict([('auc', 0.7912601632967492)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:14:59,500] Trial 14 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:15:07,065] Trial 15 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:15:14,712] Trial 16 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:15:22,278] Trial 17 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:15:29,793] Trial 18 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:15:37,283] Trial 19 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801478\tvalid's auc: 0.789382\n",
      "[200]\ttraining's auc: 0.809271\tvalid's auc: 0.792098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.809271\tvalid's auc: 0.792098\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8092712675745185)]), 'valid': OrderedDict([('auc', 0.792097670231408)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798539\tvalid's auc: 0.796068\n",
      "[200]\ttraining's auc: 0.806825\tvalid's auc: 0.799152\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[190]\ttraining's auc: 0.806163\tvalid's auc: 0.799159\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8061630965722003)]), 'valid': OrderedDict([('auc', 0.799158686214293)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801252\tvalid's auc: 0.787414\n",
      "[200]\ttraining's auc: 0.809244\tvalid's auc: 0.790593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[190]\ttraining's auc: 0.808761\tvalid's auc: 0.790667\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8087606174780956)]), 'valid': OrderedDict([('auc', 0.7906665178963941)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799798\tvalid's auc: 0.793511\n",
      "[200]\ttraining's auc: 0.807394\tvalid's auc: 0.796015\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[198]\ttraining's auc: 0.80728\tvalid's auc: 0.796081\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8072797502712135)]), 'valid': OrderedDict([('auc', 0.7960805481301044)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800968\tvalid's auc: 0.788514\n",
      "[200]\ttraining's auc: 0.809285\tvalid's auc: 0.7915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[197]\ttraining's auc: 0.809184\tvalid's auc: 0.791509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:17:39,708] Trial 20 finished with value: 0.7939025815576662 and parameters: {'num_leaves': 7, 'learning_rate': 0.17941269636981214, 'lambda_l1': 0.7422705241983562, 'lambda_l2': 0.6123796811316293, 'bagging_freq': 3, 'bagging_fraction': 0.7134902724105877, 'feature_fraction': 0.9991813161497434, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.966774240609794, 'min_split_gain': 3.8460950882995504, 'min_data_in_leaf': 3148, 'max_bin': 26}. Best is trial 20 with value: 0.7939025815576662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8091844876585134)]), 'valid': OrderedDict([('auc', 0.7915094853161319)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800639\tvalid's auc: 0.788224\n",
      "[200]\ttraining's auc: 0.808603\tvalid's auc: 0.79042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808603\tvalid's auc: 0.79042\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8086028641490678)]), 'valid': OrderedDict([('auc', 0.7904204290745906)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79844\tvalid's auc: 0.797097\n",
      "[200]\ttraining's auc: 0.806474\tvalid's auc: 0.800268\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.806474\tvalid's auc: 0.800268\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8064738007637401)]), 'valid': OrderedDict([('auc', 0.8002676784433747)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801165\tvalid's auc: 0.787336\n",
      "[200]\ttraining's auc: 0.809165\tvalid's auc: 0.789889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[180]\ttraining's auc: 0.808114\tvalid's auc: 0.789977\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081137684235734)]), 'valid': OrderedDict([('auc', 0.7899774792587307)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799228\tvalid's auc: 0.793354\n",
      "[200]\ttraining's auc: 0.807015\tvalid's auc: 0.796534\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[198]\ttraining's auc: 0.80697\tvalid's auc: 0.796588\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8069701006102618)]), 'valid': OrderedDict([('auc', 0.7965875034966001)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801117\tvalid's auc: 0.788843\n",
      "[200]\ttraining's auc: 0.809209\tvalid's auc: 0.791751\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[188]\ttraining's auc: 0.808422\tvalid's auc: 0.791941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:19:41,245] Trial 21 finished with value: 0.7938388189760375 and parameters: {'num_leaves': 7, 'learning_rate': 0.17268605495852812, 'lambda_l1': 0.33850667025750064, 'lambda_l2': 0.6265418805453724, 'bagging_freq': 3, 'bagging_fraction': 0.7128620526362355, 'feature_fraction': 0.9860307878377191, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.9990213922620725, 'min_split_gain': 3.877219645717136, 'min_data_in_leaf': 3201, 'max_bin': 26}. Best is trial 20 with value: 0.7939025815576662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8084217049793488)]), 'valid': OrderedDict([('auc', 0.791941004606891)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799685\tvalid's auc: 0.787789\n",
      "[200]\ttraining's auc: 0.808155\tvalid's auc: 0.79066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808155\tvalid's auc: 0.79066\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081547457821056)]), 'valid': OrderedDict([('auc', 0.7906597647173492)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.797743\tvalid's auc: 0.795562\n",
      "[200]\ttraining's auc: 0.806125\tvalid's auc: 0.79884\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.806125\tvalid's auc: 0.79884\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.806124720085637)]), 'valid': OrderedDict([('auc', 0.7988402251385929)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800216\tvalid's auc: 0.786897\n",
      "[200]\ttraining's auc: 0.808407\tvalid's auc: 0.790095\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[197]\ttraining's auc: 0.808299\tvalid's auc: 0.79019\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8082985853972777)]), 'valid': OrderedDict([('auc', 0.7901904708365378)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798371\tvalid's auc: 0.792496\n",
      "[200]\ttraining's auc: 0.806812\tvalid's auc: 0.796151\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.806772\tvalid's auc: 0.796167\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8067720499324693)]), 'valid': OrderedDict([('auc', 0.7961673521641729)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79974\tvalid's auc: 0.788314\n",
      "[200]\ttraining's auc: 0.808346\tvalid's auc: 0.791873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808346\tvalid's auc: 0.791873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:21:42,562] Trial 22 finished with value: 0.7935462587429613 and parameters: {'num_leaves': 8, 'learning_rate': 0.14963046506545535, 'lambda_l1': 0.8480943533472511, 'lambda_l2': 0.6406693249397022, 'bagging_freq': 3, 'bagging_fraction': 0.7140854223438806, 'feature_fraction': 0.9945452201849208, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.941587086373919, 'min_split_gain': 4.101273062537142, 'min_data_in_leaf': 2955, 'max_bin': 26}. Best is trial 20 with value: 0.7939025815576662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8083464552647677)]), 'valid': OrderedDict([('auc', 0.7918734808581537)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799095\tvalid's auc: 0.787861\n",
      "[200]\ttraining's auc: 0.806184\tvalid's auc: 0.791393\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[195]\ttraining's auc: 0.806117\tvalid's auc: 0.791448\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8061173679952999)]), 'valid': OrderedDict([('auc', 0.7914479054711313)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.796829\tvalid's auc: 0.795909\n",
      "[200]\ttraining's auc: 0.804094\tvalid's auc: 0.800124\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.804094\tvalid's auc: 0.800124\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8040935592905452)]), 'valid': OrderedDict([('auc', 0.8001237557253144)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798414\tvalid's auc: 0.786579\n",
      "[200]\ttraining's auc: 0.805898\tvalid's auc: 0.789535\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[191]\ttraining's auc: 0.805591\tvalid's auc: 0.789624\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8055911123960958)]), 'valid': OrderedDict([('auc', 0.7896241712362938)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.797471\tvalid's auc: 0.792311\n",
      "[200]\ttraining's auc: 0.804594\tvalid's auc: 0.795915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.804581\tvalid's auc: 0.795931\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8045813148238531)]), 'valid': OrderedDict([('auc', 0.7959308195432269)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798963\tvalid's auc: 0.788418\n",
      "[200]\ttraining's auc: 0.806516\tvalid's auc: 0.792221\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.806516\tvalid's auc: 0.792221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:23:43,531] Trial 23 finished with value: 0.7938694669440736 and parameters: {'num_leaves': 7, 'learning_rate': 0.14368216426122757, 'lambda_l1': 0.7220986188138794, 'lambda_l2': 1.0903169379967599, 'bagging_freq': 3, 'bagging_fraction': 0.7035624888608945, 'feature_fraction': 0.9996519571994871, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.9816850081785224, 'min_split_gain': 5.358112740699693, 'min_data_in_leaf': 2968, 'max_bin': 26}. Best is trial 20 with value: 0.7939025815576662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8065164390098175)]), 'valid': OrderedDict([('auc', 0.7922206827444012)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.80109\tvalid's auc: 0.788296\n",
      "[200]\ttraining's auc: 0.805824\tvalid's auc: 0.790374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[156]\ttraining's auc: 0.805418\tvalid's auc: 0.790393\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8054183930552626)]), 'valid': OrderedDict([('auc', 0.7903926028282845)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798817\tvalid's auc: 0.796945\n",
      "[200]\ttraining's auc: 0.804325\tvalid's auc: 0.799559\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[190]\ttraining's auc: 0.804291\tvalid's auc: 0.799614\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8042906024365611)]), 'valid': OrderedDict([('auc', 0.7996140840563178)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800818\tvalid's auc: 0.787097\n",
      "[200]\ttraining's auc: 0.806373\tvalid's auc: 0.78938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[194]\ttraining's auc: 0.806239\tvalid's auc: 0.789445\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8062394436628819)]), 'valid': OrderedDict([('auc', 0.7894447455949963)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799167\tvalid's auc: 0.793341\n",
      "[200]\ttraining's auc: 0.80467\tvalid's auc: 0.795628\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[181]\ttraining's auc: 0.804649\tvalid's auc: 0.795631\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8046494718733201)]), 'valid': OrderedDict([('auc', 0.7956309313061816)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800999\tvalid's auc: 0.789402\n",
      "[200]\ttraining's auc: 0.805258\tvalid's auc: 0.791004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[153]\ttraining's auc: 0.805014\tvalid's auc: 0.791054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:25:41,455] Trial 24 finished with value: 0.7932273655911172 and parameters: {'num_leaves': 7, 'learning_rate': 0.17551676455260773, 'lambda_l1': 2.6650896813984275, 'lambda_l2': 1.213949678339392, 'bagging_freq': 3, 'bagging_fraction': 0.7031380898516422, 'feature_fraction': 0.9949067058849044, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.975299868417147, 'min_split_gain': 5.708421831285195, 'min_data_in_leaf': 2320, 'max_bin': 26}. Best is trial 20 with value: 0.7939025815576662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8050144418729609)]), 'valid': OrderedDict([('auc', 0.7910544641698056)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801293\tvalid's auc: 0.789268\n",
      "[200]\ttraining's auc: 0.80385\tvalid's auc: 0.790823\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[143]\ttraining's auc: 0.80385\tvalid's auc: 0.790823\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8038501042373668)]), 'valid': OrderedDict([('auc', 0.7908228961308497)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798629\tvalid's auc: 0.795683\n",
      "[200]\ttraining's auc: 0.801806\tvalid's auc: 0.797648\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[149]\ttraining's auc: 0.801806\tvalid's auc: 0.797648\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.801806450900405)]), 'valid': OrderedDict([('auc', 0.797648032041187)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801687\tvalid's auc: 0.788602\n",
      "[200]\ttraining's auc: 0.804499\tvalid's auc: 0.790063\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[149]\ttraining's auc: 0.804499\tvalid's auc: 0.790063\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8044985683258974)]), 'valid': OrderedDict([('auc', 0.7900631931658014)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799935\tvalid's auc: 0.794029\n",
      "[200]\ttraining's auc: 0.803171\tvalid's auc: 0.795374\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[156]\ttraining's auc: 0.80309\tvalid's auc: 0.795406\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8030896132398102)]), 'valid': OrderedDict([('auc', 0.7954056241433063)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800772\tvalid's auc: 0.789978\n",
      "[200]\ttraining's auc: 0.803722\tvalid's auc: 0.791411\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[145]\ttraining's auc: 0.803674\tvalid's auc: 0.791444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:27:44,839] Trial 25 finished with value: 0.7930768323231073 and parameters: {'num_leaves': 7, 'learning_rate': 0.1790797868594109, 'lambda_l1': 0.7239217680035381, 'lambda_l2': 0.9087215392574699, 'bagging_freq': 2, 'bagging_fraction': 0.8024508713984388, 'feature_fraction': 0.9497175002033085, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.677463123168174, 'min_split_gain': 6.904441708473126, 'min_data_in_leaf': 3522, 'max_bin': 30}. Best is trial 20 with value: 0.7939025815576662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8036742122737613)]), 'valid': OrderedDict([('auc', 0.7914444161343925)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:27:53,028] Trial 26 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:28:00,849] Trial 27 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802265\tvalid's auc: 0.789365\n",
      "[200]\ttraining's auc: 0.808902\tvalid's auc: 0.792167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808902\tvalid's auc: 0.792167\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8089018691209022)]), 'valid': OrderedDict([('auc', 0.79216655363924)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799511\tvalid's auc: 0.796685\n",
      "[200]\ttraining's auc: 0.805792\tvalid's auc: 0.799541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[197]\ttraining's auc: 0.80568\tvalid's auc: 0.799683\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8056803710565704)]), 'valid': OrderedDict([('auc', 0.7996833486456062)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801776\tvalid's auc: 0.787115\n",
      "[200]\ttraining's auc: 0.808063\tvalid's auc: 0.790102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[182]\ttraining's auc: 0.80804\tvalid's auc: 0.790176\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8080404197347258)]), 'valid': OrderedDict([('auc', 0.7901755617467169)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800334\tvalid's auc: 0.794389\n",
      "[200]\ttraining's auc: 0.807114\tvalid's auc: 0.797174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[195]\ttraining's auc: 0.807059\tvalid's auc: 0.79718\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8070589625419021)]), 'valid': OrderedDict([('auc', 0.7971801335825948)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.80154\tvalid's auc: 0.789157\n",
      "[200]\ttraining's auc: 0.807985\tvalid's auc: 0.791544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[198]\ttraining's auc: 0.807932\tvalid's auc: 0.791562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:30:05,639] Trial 28 finished with value: 0.7941535872554286 and parameters: {'num_leaves': 8, 'learning_rate': 0.17394485982143426, 'lambda_l1': 0.48042040909566036, 'lambda_l2': 3.7922237067444557, 'bagging_freq': 2, 'bagging_fraction': 0.7668808692515962, 'feature_fraction': 0.9530037214990389, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.839712174761281, 'min_split_gain': 5.077954923075134, 'min_data_in_leaf': 2615, 'max_bin': 24}. Best is trial 28 with value: 0.7941535872554286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8079319111986483)]), 'valid': OrderedDict([('auc', 0.7915623386629856)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:30:13,357] Trial 29 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803179\tvalid's auc: 0.790118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:30:36,740] Trial 30 pruned. Trial was pruned at iteration 188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800241\tvalid's auc: 0.787913\n",
      "[200]\ttraining's auc: 0.808827\tvalid's auc: 0.790865\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808827\tvalid's auc: 0.790865\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.808827215122809)]), 'valid': OrderedDict([('auc', 0.7908647833417148)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798168\tvalid's auc: 0.796356\n",
      "[200]\ttraining's auc: 0.806914\tvalid's auc: 0.800046\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[186]\ttraining's auc: 0.805993\tvalid's auc: 0.800185\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8059932842150465)]), 'valid': OrderedDict([('auc', 0.8001853361239378)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800258\tvalid's auc: 0.786301\n",
      "[200]\ttraining's auc: 0.808948\tvalid's auc: 0.789175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[189]\ttraining's auc: 0.808176\tvalid's auc: 0.789441\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081759494211909)]), 'valid': OrderedDict([('auc', 0.7894413576512879)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798703\tvalid's auc: 0.793677\n",
      "[200]\ttraining's auc: 0.807197\tvalid's auc: 0.795921\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[198]\ttraining's auc: 0.807104\tvalid's auc: 0.795928\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.807104475832165)]), 'valid': OrderedDict([('auc', 0.7959275954748187)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799935\tvalid's auc: 0.789088\n",
      "[200]\ttraining's auc: 0.808892\tvalid's auc: 0.791971\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808892\tvalid's auc: 0.791971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:32:39,959] Trial 31 finished with value: 0.7936780674258201 and parameters: {'num_leaves': 7, 'learning_rate': 0.1678402323844264, 'lambda_l1': 0.6854666896500581, 'lambda_l2': 0.8773382258212937, 'bagging_freq': 3, 'bagging_fraction': 0.7278717683459197, 'feature_fraction': 0.965940040164086, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.837792637899831, 'min_split_gain': 2.842958305576198, 'min_data_in_leaf': 3643, 'max_bin': 25}. Best is trial 28 with value: 0.7941535872554286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8088918367924387)]), 'valid': OrderedDict([('auc', 0.7919712645373422)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:32:50,363] Trial 32 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801693\tvalid's auc: 0.789472\n",
      "[200]\ttraining's auc: 0.806469\tvalid's auc: 0.791291\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[187]\ttraining's auc: 0.806239\tvalid's auc: 0.791375\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.806239178683783)]), 'valid': OrderedDict([('auc', 0.7913752886224941)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.798488\tvalid's auc: 0.79602\n",
      "[200]\ttraining's auc: 0.802816\tvalid's auc: 0.797895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[163]\ttraining's auc: 0.802816\tvalid's auc: 0.797895\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8028155611467364)]), 'valid': OrderedDict([('auc', 0.7978947027551457)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800825\tvalid's auc: 0.78701\n",
      "[200]\ttraining's auc: 0.80639\tvalid's auc: 0.789288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.80639\tvalid's auc: 0.789288\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8063895607939435)]), 'valid': OrderedDict([('auc', 0.7892880701203885)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799224\tvalid's auc: 0.793724\n",
      "[200]\ttraining's auc: 0.8043\tvalid's auc: 0.796293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[179]\ttraining's auc: 0.8043\tvalid's auc: 0.796293\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8042997746494082)]), 'valid': OrderedDict([('auc', 0.7962931407071804)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801465\tvalid's auc: 0.788096\n",
      "[200]\ttraining's auc: 0.805579\tvalid's auc: 0.790454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[170]\ttraining's auc: 0.805573\tvalid's auc: 0.790462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:34:44,161] Trial 33 finished with value: 0.7930625645077256 and parameters: {'num_leaves': 8, 'learning_rate': 0.18316966833164605, 'lambda_l1': 0.3593167937837444, 'lambda_l2': 4.046355710412208, 'bagging_freq': 4, 'bagging_fraction': 0.6489588838806752, 'feature_fraction': 0.9941049198456955, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.951030157790464, 'min_split_gain': 5.6402285809501835, 'min_data_in_leaf': 3053, 'max_bin': 21}. Best is trial 28 with value: 0.7941535872554286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8055726171390548)]), 'valid': OrderedDict([('auc', 0.7904616203334193)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:34:53,948] Trial 34 pruned. Trial was pruned at iteration 28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803787\tvalid's auc: 0.789374\n",
      "[200]\ttraining's auc: 0.810199\tvalid's auc: 0.7912\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[195]\ttraining's auc: 0.810199\tvalid's auc: 0.7912\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.810198903879479)]), 'valid': OrderedDict([('auc', 0.791199809779766)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801409\tvalid's auc: 0.797302\n",
      "[200]\ttraining's auc: 0.808262\tvalid's auc: 0.799982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[196]\ttraining's auc: 0.808146\tvalid's auc: 0.800082\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081456367158493)]), 'valid': OrderedDict([('auc', 0.8000824670049599)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803888\tvalid's auc: 0.787845\n",
      "[200]\ttraining's auc: 0.810671\tvalid's auc: 0.789985\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.810671\tvalid's auc: 0.789985\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8106705770084685)]), 'valid': OrderedDict([('auc', 0.7899847645845811)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802146\tvalid's auc: 0.795509\n",
      "[200]\ttraining's auc: 0.809174\tvalid's auc: 0.797773\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[189]\ttraining's auc: 0.808757\tvalid's auc: 0.797826\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8087573647157458)]), 'valid': OrderedDict([('auc', 0.7978255315152865)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803713\tvalid's auc: 0.790741\n",
      "[200]\ttraining's auc: 0.810359\tvalid's auc: 0.792891\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.810359\tvalid's auc: 0.792891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:37:02,790] Trial 35 finished with value: 0.7943966640713775 and parameters: {'num_leaves': 8, 'learning_rate': 0.1968586896571731, 'lambda_l1': 1.01723715206363, 'lambda_l2': 1.1306409221009894, 'bagging_freq': 2, 'bagging_fraction': 0.8175866252072161, 'feature_fraction': 0.9599480347182683, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.758396451335359, 'min_split_gain': 4.367362998039098, 'min_data_in_leaf': 3288, 'max_bin': 30}. Best is trial 35 with value: 0.7943966640713775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8103591445514229)]), 'valid': OrderedDict([('auc', 0.7928907474722947)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802698\tvalid's auc: 0.788336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:37:22,396] Trial 36 pruned. Trial was pruned at iteration 127.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802066\tvalid's auc: 0.789071\n",
      "[200]\ttraining's auc: 0.808562\tvalid's auc: 0.791159\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[184]\ttraining's auc: 0.808188\tvalid's auc: 0.791193\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081879853796269)]), 'valid': OrderedDict([('auc', 0.7911931159483988)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799663\tvalid's auc: 0.796448\n",
      "[200]\ttraining's auc: 0.806217\tvalid's auc: 0.798999\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.806217\tvalid's auc: 0.798999\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8062174969196144)]), 'valid': OrderedDict([('auc', 0.7989994236144513)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802076\tvalid's auc: 0.786408\n",
      "[200]\ttraining's auc: 0.80881\tvalid's auc: 0.789748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.80881\tvalid's auc: 0.789748\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.808810116509944)]), 'valid': OrderedDict([('auc', 0.7897482569011808)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800746\tvalid's auc: 0.795167\n",
      "[200]\ttraining's auc: 0.807233\tvalid's auc: 0.797789\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[182]\ttraining's auc: 0.807078\tvalid's auc: 0.797869\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8070776918090211)]), 'valid': OrderedDict([('auc', 0.7978685523441221)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801559\tvalid's auc: 0.787867\n",
      "[200]\ttraining's auc: 0.808168\tvalid's auc: 0.791162\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.808168\tvalid's auc: 0.791162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:40:40,945] Trial 37 finished with value: 0.7937942708725056 and parameters: {'num_leaves': 9, 'learning_rate': 0.1851967399051144, 'lambda_l1': 1.0180385790285011, 'lambda_l2': 1.230127083843065, 'bagging_freq': 2, 'bagging_fraction': 0.8108211332177541, 'feature_fraction': 0.5250999863498009, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.157344436268221, 'min_split_gain': 4.495535460890756, 'min_data_in_leaf': 2790, 'max_bin': 28}. Best is trial 35 with value: 0.7943966640713775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081682903225482)]), 'valid': OrderedDict([('auc', 0.7911620055543752)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:40:46,711] Trial 38 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:40:54,576] Trial 39 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.804679\tvalid's auc: 0.789188\n",
      "[200]\ttraining's auc: 0.810436\tvalid's auc: 0.790926\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[158]\ttraining's auc: 0.810362\tvalid's auc: 0.790947\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8103623142180543)]), 'valid': OrderedDict([('auc', 0.7909468335407833)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802303\tvalid's auc: 0.796722\n",
      "[200]\ttraining's auc: 0.808835\tvalid's auc: 0.7993\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[168]\ttraining's auc: 0.808827\tvalid's auc: 0.799303\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8088271209394591)]), 'valid': OrderedDict([('auc', 0.7993030471129058)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.804748\tvalid's auc: 0.788217\n",
      "[200]\ttraining's auc: 0.811157\tvalid's auc: 0.790218\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[161]\ttraining's auc: 0.810877\tvalid's auc: 0.790322\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8108766624033638)]), 'valid': OrderedDict([('auc', 0.7903223477032022)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.80339\tvalid's auc: 0.795055\n",
      "[200]\ttraining's auc: 0.810437\tvalid's auc: 0.797008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[170]\ttraining's auc: 0.810353\tvalid's auc: 0.797008\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8103526232182403)]), 'valid': OrderedDict([('auc', 0.7970084599555028)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.804582\tvalid's auc: 0.789571\n",
      "[200]\ttraining's auc: 0.810601\tvalid's auc: 0.792187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[155]\ttraining's auc: 0.810574\tvalid's auc: 0.792199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:43:11,709] Trial 40 finished with value: 0.7939558609782719 and parameters: {'num_leaves': 9, 'learning_rate': 0.19978358960499337, 'lambda_l1': 1.790905273479833, 'lambda_l2': 1.0883936503960903, 'bagging_freq': 3, 'bagging_fraction': 0.9972475193817582, 'feature_fraction': 0.9637896357108776, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.412284289682494, 'min_split_gain': 3.116958421323967, 'min_data_in_leaf': 2111, 'max_bin': 24}. Best is trial 35 with value: 0.7943966640713775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8105737845621196)]), 'valid': OrderedDict([('auc', 0.7921986165789648)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803963\tvalid's auc: 0.788388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:43:33,555] Trial 41 pruned. Trial was pruned at iteration 148.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.804627\tvalid's auc: 0.790559\n",
      "[200]\ttraining's auc: 0.808423\tvalid's auc: 0.79171\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[148]\ttraining's auc: 0.808398\tvalid's auc: 0.791747\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8083981814642403)]), 'valid': OrderedDict([('auc', 0.7917465237364454)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.80189\tvalid's auc: 0.797114\n",
      "[200]\ttraining's auc: 0.805066\tvalid's auc: 0.798836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[135]\ttraining's auc: 0.80498\tvalid's auc: 0.798842\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8049800448192511)]), 'valid': OrderedDict([('auc', 0.798842337667598)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.804176\tvalid's auc: 0.788142\n",
      "[200]\ttraining's auc: 0.807897\tvalid's auc: 0.789427\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[154]\ttraining's auc: 0.807897\tvalid's auc: 0.789427\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8078970107441308)]), 'valid': OrderedDict([('auc', 0.7894266943744175)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803003\tvalid's auc: 0.795295\n",
      "[200]\ttraining's auc: 0.806414\tvalid's auc: 0.796644\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[143]\ttraining's auc: 0.806414\tvalid's auc: 0.796644\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.806413835276089)]), 'valid': OrderedDict([('auc', 0.7966437198496166)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.803949\tvalid's auc: 0.791225\n",
      "[200]\ttraining's auc: 0.807461\tvalid's auc: 0.792561\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[142]\ttraining's auc: 0.807347\tvalid's auc: 0.792655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:45:42,978] Trial 42 finished with value: 0.7938628576961777 and parameters: {'num_leaves': 8, 'learning_rate': 0.19932291949351816, 'lambda_l1': 1.6867564758643836, 'lambda_l2': 2.3513804223964923, 'bagging_freq': 4, 'bagging_fraction': 0.9258549504313809, 'feature_fraction': 0.8910816158218311, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.808581684347336, 'min_split_gain': 4.964155107021757, 'min_data_in_leaf': 2499, 'max_bin': 30}. Best is trial 35 with value: 0.7943966640713775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8073471643219836)]), 'valid': OrderedDict([('auc', 0.792655012852811)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:45:51,232] Trial 43 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801626\tvalid's auc: 0.789245\n",
      "[200]\ttraining's auc: 0.805894\tvalid's auc: 0.791351\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[163]\ttraining's auc: 0.805888\tvalid's auc: 0.791355\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8058881192647099)]), 'valid': OrderedDict([('auc', 0.7913551501292962)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799691\tvalid's auc: 0.795928\n",
      "[200]\ttraining's auc: 0.803814\tvalid's auc: 0.798345\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[161]\ttraining's auc: 0.803814\tvalid's auc: 0.798345\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8038137191831467)]), 'valid': OrderedDict([('auc', 0.7983446286839295)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802321\tvalid's auc: 0.786332\n",
      "[200]\ttraining's auc: 0.806093\tvalid's auc: 0.78797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[155]\ttraining's auc: 0.806093\tvalid's auc: 0.78797\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8060933009180169)]), 'valid': OrderedDict([('auc', 0.7879703559556773)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800683\tvalid's auc: 0.793646\n",
      "[200]\ttraining's auc: 0.804756\tvalid's auc: 0.795457\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[164]\ttraining's auc: 0.804756\tvalid's auc: 0.795457\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8047561214654002)]), 'valid': OrderedDict([('auc', 0.7954574871133452)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802033\tvalid's auc: 0.790051\n",
      "[200]\ttraining's auc: 0.806134\tvalid's auc: 0.791531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[157]\ttraining's auc: 0.806111\tvalid's auc: 0.791543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:47:55,504] Trial 44 finished with value: 0.7929342030271033 and parameters: {'num_leaves': 8, 'learning_rate': 0.17417803986549948, 'lambda_l1': 1.3765666073252225, 'lambda_l2': 1.0503308625109289, 'bagging_freq': 3, 'bagging_fraction': 0.830123718519231, 'feature_fraction': 0.9714242451052896, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.829709781099211, 'min_split_gain': 5.813314053871258, 'min_data_in_leaf': 2180, 'max_bin': 22}. Best is trial 35 with value: 0.7943966640713775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8061110520630876)]), 'valid': OrderedDict([('auc', 0.7915433932532682)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:48:03,806] Trial 45 pruned. Trial was pruned at iteration 7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:48:11,753] Trial 46 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:48:19,525] Trial 47 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802279\tvalid's auc: 0.789464\n",
      "[200]\ttraining's auc: 0.808533\tvalid's auc: 0.79139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[175]\ttraining's auc: 0.807488\tvalid's auc: 0.791425\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8074878475090074)]), 'valid': OrderedDict([('auc', 0.7914251378946183)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.800025\tvalid's auc: 0.796773\n",
      "[200]\ttraining's auc: 0.806645\tvalid's auc: 0.799016\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[191]\ttraining's auc: 0.806293\tvalid's auc: 0.799227\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8062930021303473)]), 'valid': OrderedDict([('auc', 0.7992267110732376)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.801757\tvalid's auc: 0.78725\n",
      "[200]\ttraining's auc: 0.808125\tvalid's auc: 0.789831\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.808125\tvalid's auc: 0.789831\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8081246542339673)]), 'valid': OrderedDict([('auc', 0.7898309355526894)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.799781\tvalid's auc: 0.793466\n",
      "[200]\ttraining's auc: 0.806521\tvalid's auc: 0.795818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\ttraining's auc: 0.806507\tvalid's auc: 0.795845\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.80650719460979)]), 'valid': OrderedDict([('auc', 0.7958446567603336)])})\n",
      "train 246006 valid 61501\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.802257\tvalid's auc: 0.788378\n",
      "[200]\ttraining's auc: 0.807502\tvalid's auc: 0.79028\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[176]\ttraining's auc: 0.807452\tvalid's auc: 0.790352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:50:20,478] Trial 48 finished with value: 0.7933358088575382 and parameters: {'num_leaves': 9, 'learning_rate': 0.19973887027664539, 'lambda_l1': 1.2531294230017207, 'lambda_l2': 0.31166914393436845, 'bagging_freq': 4, 'bagging_fraction': 0.6807084019062599, 'feature_fraction': 0.6242324247487955, 'max_depth': 3, 'min_sum_hessian_in_leaf': 4.722558948393728, 'min_split_gain': 4.684487806604208, 'min_data_in_leaf': 3021, 'max_bin': 29}. Best is trial 35 with value: 0.7943966640713775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('auc', 0.8074516058475142)]), 'valid': OrderedDict([('auc', 0.7903516030068125)])})\n",
      "train 246005 valid 61502\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-15 16:50:28,142] Trial 49 pruned. Trial was pruned at iteration 5.\n"
     ]
    }
   ],
   "source": [
    "def fit_lgbm_with_pruning(trial, train, val, devices=(-1,), seed=42, cat_features=None, num_rounds=200):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒLightGBMæ¨¡å‹ï¼ˆé€‚é… LightGBM v4+: ç”¨ callbacks å®ç°æ—©åœä¸æ—¥å¿—ï¼›æ”¯æŒ Optuna å‰ªæï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = val\n",
    "    metric = 'auc'\n",
    "\n",
    "    # ---- Optuna é‡‡æ ·ï¼ˆæ¨èçš„ APIï¼Œé¿å…å¼ƒç”¨è­¦å‘Šï¼‰----\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.2, log=True),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.1, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0.1, 10.0, log=True),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 2, 10),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 4),\n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 2.0, 5.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 2.0, 10.0),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 500, 5000),\n",
    "        'max_bin': trial.suggest_int('max_bin', 2, 30),\n",
    "        'metric': metric,\n",
    "        'verbosity': -1,\n",
    "        'seed': seed,\n",
    "    }\n",
    "\n",
    "    # ---- è®¾å¤‡é€‰æ‹© ----\n",
    "    device = devices[0]\n",
    "    if device != -1:\n",
    "        print(f'using gpu device_id {device}...')\n",
    "        params.update({'device': 'gpu', 'gpu_device_id': device})\n",
    "\n",
    "    # ---- æ•°æ®é›† ----\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "    dvalid = lgb.Dataset(X_valid,  label=y_valid,  categorical_feature=cat_features)\n",
    "\n",
    "    # èµ·å›ºå®šåå­—ï¼Œåç»­ best_score/å‰ªæéƒ½ç”¨ 'valid'\n",
    "    valid_sets = [dtrain, dvalid]\n",
    "    valid_names = ['training', 'valid']\n",
    "\n",
    "    # ---- callbacksï¼šæ—©åœ + æ—¥å¿— + å‰ªæ ----\n",
    "    early_stop_rounds = 100\n",
    "    log_period = 100\n",
    "    pruning_cb = optuna.integration.LightGBMPruningCallback(trial, metric=metric, valid_name='valid')\n",
    "\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=early_stop_rounds),\n",
    "        lgb.log_evaluation(period=log_period),\n",
    "        pruning_cb,\n",
    "    ]\n",
    "\n",
    "    print('training LGB:')\n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=num_rounds,\n",
    "        valid_sets=valid_sets,\n",
    "        valid_names=valid_names,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # é¢„æµ‹\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "    # è®°å½•åˆ†æ•°ï¼ˆæŒ‰æˆ‘ä»¬ç»™çš„ valid åç§°å–ï¼‰\n",
    "    # model.best_score ç»“æ„ï¼š{'training': {'auc': ...}, 'valid': {'auc': ...}}\n",
    "    print('best_score', model.best_score)\n",
    "    log = {\n",
    "        'train/auc': model.best_score['training'][metric],\n",
    "        'valid/auc': model.best_score['valid'][metric],\n",
    "    }\n",
    "    return model, y_pred_valid, log\n",
    "\n",
    "\n",
    "\n",
    "def objective_with_prune(trial: Trial, fast_check=False):\n",
    "    \"\"\"\n",
    "    ç›®æ ‡å‡½æ•°\n",
    "    \"\"\"\n",
    "    folds = 5\n",
    "    seed = 42\n",
    "    shuffle = True\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=shuffle, random_state=seed) # 5æŠ˜Kfold\n",
    "\n",
    "    X_train, y_train = X, y\n",
    "    y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "    gc.collect()\n",
    "\n",
    "    models0 = [] # æ¨¡å‹å¯¹è±¡åˆ—è¡¨\n",
    "    valid_score = 0 \n",
    "    \n",
    "    # 5æŠ˜äº¤å‰éªŒè¯\n",
    "    for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "        train_data = X_train[train_idx, :], y_train[train_idx]\n",
    "        valid_data = X_train[valid_idx, :], y_train[valid_idx]\n",
    "\n",
    "        print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "        model, y_pred_valid, log = fit_lgbm_with_pruning(trial, train_data,\n",
    "                                                         valid_data,\n",
    "                                                         num_rounds=200)\n",
    "        y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "        models0.append(model)\n",
    "        gc.collect()\n",
    "        valid_score += log[\"valid/auc\"] \n",
    "        if fast_check:\n",
    "            break\n",
    "    valid_score /= len(models0)\n",
    "    return valid_score\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"maximize\")\n",
    "study.optimize(objective_with_prune, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc5f9f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T16:50:28.285687Z",
     "iopub.status.busy": "2025-10-15T16:50:28.285226Z",
     "iopub.status.idle": "2025-10-15T16:50:28.294185Z",
     "shell.execute_reply": "2025-10-15T16:50:28.292937Z"
    },
    "papermill": {
     "duration": 0.077118,
     "end_time": "2025-10-15T16:50:28.296038",
     "exception": false,
     "start_time": "2025-10-15T16:50:28.218920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 8,\n",
       " 'learning_rate': 0.1968586896571731,\n",
       " 'lambda_l1': 1.01723715206363,\n",
       " 'lambda_l2': 1.1306409221009894,\n",
       " 'bagging_freq': 2,\n",
       " 'bagging_fraction': 0.8175866252072161,\n",
       " 'feature_fraction': 0.9599480347182683,\n",
       " 'max_depth': 3,\n",
       " 'min_sum_hessian_in_leaf': 4.758396451335359,\n",
       " 'min_split_gain': 4.367362998039098,\n",
       " 'min_data_in_leaf': 3288,\n",
       " 'max_bin': 30}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = study.best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bd10f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T16:50:28.428619Z",
     "iopub.status.busy": "2025-10-15T16:50:28.427557Z",
     "iopub.status.idle": "2025-10-15T16:50:54.511036Z",
     "shell.execute_reply": "2025-10-15T16:50:54.510254Z"
    },
    "papermill": {
     "duration": 26.151392,
     "end_time": "2025-10-15T16:50:54.513480",
     "exception": false,
     "start_time": "2025-10-15T16:50:28.362088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246005, 314)\n",
      "(61502, 314)\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttraining's auc: 0.781481\tvalid's auc: 0.776002\n",
      "[40]\ttraining's auc: 0.791282\tvalid's auc: 0.783971\n",
      "[60]\ttraining's auc: 0.796696\tvalid's auc: 0.787213\n",
      "[80]\ttraining's auc: 0.801057\tvalid's auc: 0.789503\n",
      "[100]\ttraining's auc: 0.803613\tvalid's auc: 0.790898\n",
      "[120]\ttraining's auc: 0.805801\tvalid's auc: 0.791523\n",
      "[140]\ttraining's auc: 0.807446\tvalid's auc: 0.791687\n",
      "[160]\ttraining's auc: 0.808703\tvalid's auc: 0.791891\n",
      "[180]\ttraining's auc: 0.809714\tvalid's auc: 0.792191\n",
      "[200]\ttraining's auc: 0.810564\tvalid's auc: 0.7922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[181]\ttraining's auc: 0.809821\tvalid's auc: 0.792261\n",
      "best iteration 181\n",
      "best_score {'training/auc': 0.8098210795377683, 'valid/auc': 0.7922612000437912}\n"
     ]
    }
   ],
   "source": [
    "params['seed'] = 42\n",
    "params['objective'] = 'binary'\n",
    "params['boosting'] = \"gbdt\"\n",
    "params['metric'] = 'auc'\n",
    "params['verbosity'] = -1\n",
    "early_stop = 100\n",
    "log_period = 20\n",
    "num_rounds = 200\n",
    "\n",
    "# åˆ‡åˆ†\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "\n",
    "# Datasetï¼ˆå¦‚æœæœ‰ç±»åˆ«åˆ—ï¼Œä¼ å…¥åˆ—åæˆ–ç´¢å¼•åˆ—è¡¨ï¼‰\n",
    "d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=None)\n",
    "d_valid = lgb.Dataset(X_valid,  label=y_valid,  categorical_feature=None)\n",
    "\n",
    "valid_sets  = [d_train, d_valid]\n",
    "valid_names = ['training', 'valid']\n",
    "\n",
    "print('training LGB:')\n",
    "model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=d_train,\n",
    "    num_boost_round=num_rounds,\n",
    "    valid_sets=valid_sets,\n",
    "    valid_names=valid_names,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=early_stop),\n",
    "        lgb.log_evaluation(period=log_period)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('best iteration', model.best_iteration)\n",
    "\n",
    "# é¢„æµ‹\n",
    "y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "# åˆ†æ•°ï¼ˆç”¨æˆ‘ä»¬èµ·çš„åå­— 'training' å’Œ 'valid'ï¼‰\n",
    "train_auc = model.best_score['training']['auc']\n",
    "valid_auc = model.best_score['valid']['auc']\n",
    "print('best_score', {'training/auc': train_auc, 'valid/auc': valid_auc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f8765a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T16:50:54.648276Z",
     "iopub.status.busy": "2025-10-15T16:50:54.647187Z",
     "iopub.status.idle": "2025-10-15T16:50:54.655690Z",
     "shell.execute_reply": "2025-10-15T16:50:54.654575Z"
    },
    "papermill": {
     "duration": 0.078309,
     "end_time": "2025-10-15T16:50:54.657510",
     "exception": false,
     "start_time": "2025-10-15T16:50:54.579201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# é€šè¿‡æ¨¡å‹å¯¹è±¡é¢„æµ‹ç»“æœ\n",
    "def pred(X_test, models):\n",
    "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'predicting {i}-th model')\n",
    "        y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        y_test_pred_total += y_pred_test\n",
    "    y_test_pred_total /= len(models)\n",
    "    return y_test_pred_total\n",
    "\n",
    "# å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§\n",
    "def plot_feature_importance(model,features):\n",
    "    importance_df = pd.DataFrame(model.feature_importance(),\n",
    "                                 index=features,\n",
    "                                 columns=['importance']).sort_values('importance').sort_values(by='importance',ascending=False).head(20)\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    importance_df.plot.barh(ax=ax)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52ad60ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T16:50:54.790662Z",
     "iopub.status.busy": "2025-10-15T16:50:54.790316Z",
     "iopub.status.idle": "2025-10-15T16:50:55.180579Z",
     "shell.execute_reply": "2025-10-15T16:50:55.179184Z"
    },
    "papermill": {
     "duration": 0.460504,
     "end_time": "2025-10-15T16:50:55.182690",
     "exception": false,
     "start_time": "2025-10-15T16:50:54.722186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# å±•ç¤ºæ’åå‰20çš„ç‰¹å¾é‡è¦æ€§\n",
    "plot_feature_importance(model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecf01fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T16:50:55.320706Z",
     "iopub.status.busy": "2025-10-15T16:50:55.320376Z",
     "iopub.status.idle": "2025-10-15T16:50:55.846907Z",
     "shell.execute_reply": "2025-10-15T16:50:55.845532Z"
    },
    "papermill": {
     "duration": 0.598708,
     "end_time": "2025-10-15T16:50:55.849193",
     "exception": false,
     "start_time": "2025-10-15T16:50:55.250485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "# å¦‚æœæœ‰æµ‹è¯•é›† IDï¼š\n",
    "submission = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': y_test_pred})\n",
    "submission.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394c2c0",
   "metadata": {
    "papermill": {
     "duration": 0.067072,
     "end_time": "2025-10-15T16:50:55.984361",
     "exception": false,
     "start_time": "2025-10-15T16:50:55.917289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Method2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "478140e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T16:50:56.121428Z",
     "iopub.status.busy": "2025-10-15T16:50:56.121077Z",
     "iopub.status.idle": "2025-10-15T17:51:01.343116Z",
     "shell.execute_reply": "2025-10-15T17:51:01.341789Z"
    },
    "papermill": {
     "duration": 3605.295103,
     "end_time": "2025-10-15T17:51:01.347721",
     "exception": false,
     "start_time": "2025-10-15T16:50:56.052618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251015_165057\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       21.11 GB / 31.35 GB (67.3%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-10-15 16:51:13,224\tINFO worker.py:1852 -- Started a local Ray instance.\n",
      "\t\tContext path: \"/kaggle/working/AutogluonModels/ag-20251015_165057/ds_sub_fit/sub_fit_ho\"\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Running DyStack sub-fit ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Beginning AutoGluon training ... Time limit = 877s\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20251015_165057/ds_sub_fit/sub_fit_ho\"\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Train Data Rows:    273339\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Train Data Columns: 314\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Label Column:       TARGET\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Problem Type:       binary\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Preprocessing data ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Using Feature Generators to preprocess the data ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tAvailable Memory:                    19484.05 MB\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tTrain Data (Original)  Memory Usage: 654.82 MB (3.4% of available memory)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tStage 1 Generators:\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tStage 2 Generators:\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tStage 3 Generators:\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tStage 4 Generators:\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tStage 5 Generators:\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tUnused Original Features (Count: 6): ['DAYS_EMPLOYED_PERC', 'CLOSED_CREDIT_DAY_OVERDUE_MEDIAN', 'CLOSED_AMT_CREDIT_SUM_OVERDUE_SUM', 'CLOSED_CREDIT_DAY_OVERDUE_MEAN', 'CLOSED_CREDIT_DAY_OVERDUE_MAX', 'POS_MONTHS_BALANCE_SIZE']\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t('float', []) : 6 | ['DAYS_EMPLOYED_PERC', 'CLOSED_CREDIT_DAY_OVERDUE_MEDIAN', 'CLOSED_AMT_CREDIT_SUM_OVERDUE_SUM', 'CLOSED_CREDIT_DAY_OVERDUE_MEAN', 'CLOSED_CREDIT_DAY_OVERDUE_MAX', ...]\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t('float', []) : 291 | ['nn_oof_single_past', 'prapp_preds_TARGET_mean.1', 'buro_preds_TARGET_mean', 'prapp_preds_TARGET_median.1', 'EXT_SOURCE_3', ...]\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t('int', [])   :  17 | ['DAYS_BIRTH', 'OCCUPATION_TYPE', 'NAME_INCOME_TYPE', 'ORGANIZATION_TYPE', 'REGION_RATING_CLIENT_W_CITY', ...]\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t('float', [])     : 291 | ['nn_oof_single_past', 'prapp_preds_TARGET_mean.1', 'buro_preds_TARGET_mean', 'prapp_preds_TARGET_median.1', 'EXT_SOURCE_3', ...]\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t('int', [])       :  12 | ['DAYS_BIRTH', 'OCCUPATION_TYPE', 'NAME_INCOME_TYPE', 'ORGANIZATION_TYPE', 'REGION_RATING_CLIENT_W_CITY', ...]\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\t('int', ['bool']) :   5 | ['CODE_GENDER', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_3', 'REG_CITY_NOT_LIVE_CITY']\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t12.3s = Fit runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t308 features in original data used to generate 308 features in processed data.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tTrain Data (Processed) Memory Usage: 633.18 MB (3.3% of available memory)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Data preprocessing and feature engineering runtime = 13.06s ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m User-specified model hyperparameters to be fit:\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m {\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m }\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 575.56s of the 863.54s of remaining time.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.92% memory usage per fold, 61.84%/80.00% total).\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=30.92%)\n",
      "\u001B[36m(_ray_fit pid=522)\u001B[0m \tRan out of time, early stopping on iteration 241. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=522)\u001B[0m \t[241]\tvalid_set's binary_logloss: 0.23349\n",
      "\u001B[36m(_ray_fit pid=595)\u001B[0m \tRan out of time, early stopping on iteration 240. Best iteration is:\u001B[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=595)\u001B[0m \t[239]\tvalid_set's binary_logloss: 0.233768\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=669)\u001B[0m \tRan out of time, early stopping on iteration 228. Best iteration is:\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=669)\u001B[0m \t[228]\tvalid_set's binary_logloss: 0.23367\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=743)\u001B[0m \tRan out of time, early stopping on iteration 237. Best iteration is:\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=743)\u001B[0m \t[226]\tvalid_set's binary_logloss: 0.233282\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.7946\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t486.99s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t8.22s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 68.40s of the 356.38s of remaining time.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.35% memory usage per fold, 46.70%/80.00% total).\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=23.35%)\n",
      "\u001B[36m(_ray_fit pid=745)\u001B[0m \tRan out of time, early stopping on iteration 237. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=745)\u001B[0m \t[237]\tvalid_set's binary_logloss: 0.236672\n",
      "\u001B[36m(_ray_fit pid=903)\u001B[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=903)\u001B[0m \t[1]\tvalid_set's binary_logloss: 0.276717\n",
      "\u001B[36m(_ray_fit pid=976)\u001B[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=976)\u001B[0m \t[1]\tvalid_set's binary_logloss: 0.276669\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=1049)\u001B[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=1049)\u001B[0m \t[1]\tvalid_set's binary_logloss: 0.276662\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=1126)\u001B[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=1126)\u001B[0m \t[1]\tvalid_set's binary_logloss: 0.276665\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.7429\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t110.16s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.8s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 236.64s of remaining time.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.7946\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t9.92s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.22s\t = Validation runtime\n",
      "\u001B[36m(_ray_fit pid=1124)\u001B[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1124)\u001B[0m \t[1]\tvalid_set's binary_logloss: 0.276657\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 226.42s of the 226.11s of remaining time.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 54.89% memory usage per fold, 54.89%/80.00% total).\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=2, gpus=0, memory=54.89%)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "\u001B[36m(_ray_fit pid=1248)\u001B[0m \tRan out of time, early stopping on iteration 19. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1248)\u001B[0m \t[19]\tvalid_set's binary_logloss: 0.245073\n",
      "\u001B[36m(_ray_fit pid=1326)\u001B[0m \tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1326)\u001B[0m \t[28]\tvalid_set's binary_logloss: 0.239385\n",
      "\u001B[36m(_ray_fit pid=1403)\u001B[0m \tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1403)\u001B[0m \t[28]\tvalid_set's binary_logloss: 0.239718\n",
      "\u001B[36m(_ray_fit pid=1480)\u001B[0m \tRan out of time, early stopping on iteration 30. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1480)\u001B[0m \t[30]\tvalid_set's binary_logloss: 0.237653\n",
      "\u001B[36m(_ray_fit pid=1557)\u001B[0m \tRan out of time, early stopping on iteration 30. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1557)\u001B[0m \t[30]\tvalid_set's binary_logloss: 0.23965\n",
      "\u001B[36m(_ray_fit pid=1633)\u001B[0m \tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1633)\u001B[0m \t[29]\tvalid_set's binary_logloss: 0.241113\n",
      "\u001B[36m(_ray_fit pid=1710)\u001B[0m \tRan out of time, early stopping on iteration 26. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1710)\u001B[0m \t[26]\tvalid_set's binary_logloss: 0.239892\n",
      "\u001B[36m(_ray_fit pid=1787)\u001B[0m \tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\u001B[36m(_ray_fit pid=1787)\u001B[0m \t[29]\tvalid_set's binary_logloss: 0.239804\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.7916\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t230.05s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.92s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -16.72s of remaining time.\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.7946\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t5.04s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m \t0.06s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m AutoGluon training complete, total runtime = 900.77s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4142.6 rows/s (34168 batch size)\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20251015_165057/ds_sub_fit/sub_fit_ho\")\n",
      "\u001B[36m(_dystack pid=223)\u001B[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMXT_BAG_L1       0.799035   0.794632     roc_auc       10.961648       8.220298 486.987495                10.961648                8.220298         486.987495            1       True          1\n",
      "1  WeightedEnsemble_L3       0.799035   0.794632     roc_auc       10.964049       8.284066 492.027794                 0.002401                0.063768           5.040299            3       True          5\n",
      "2  WeightedEnsemble_L2       0.799035   0.794632     roc_auc       10.964144       8.442022 496.909621                 0.002496                0.221723           9.922126            2       True          3\n",
      "3    LightGBMXT_BAG_L2       0.797271   0.791556     roc_auc       12.545137       9.934696 827.193925                 0.961160                0.915260         230.045599            2       True          4\n",
      "4      LightGBM_BAG_L1       0.755004   0.742880     roc_auc        0.622328       0.799138 110.160830                 0.622328                0.799138         110.160830            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t945s\t = DyStack   runtime |\t2655s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2655s\n",
      "AutoGluon will save models to \"/kaggle/working/AutogluonModels/ag-20251015_165057\"\n",
      "Train Data Rows:    307507\n",
      "Train Data Columns: 314\n",
      "Label Column:       TARGET\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19268.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 736.67 MB (3.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 5): ['DAYS_EMPLOYED_PERC', 'CLOSED_AMT_CREDIT_SUM_OVERDUE_SUM', 'CLOSED_CNT_CREDIT_PROLONG_SUM', 'CLOSED_CREDIT_DAY_OVERDUE_MAX', 'POS_MONTHS_BALANCE_SIZE']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 5 | ['DAYS_EMPLOYED_PERC', 'CLOSED_AMT_CREDIT_SUM_OVERDUE_SUM', 'CLOSED_CNT_CREDIT_PROLONG_SUM', 'CLOSED_CREDIT_DAY_OVERDUE_MAX', 'POS_MONTHS_BALANCE_SIZE']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 292 | ['nn_oof_single_past', 'prapp_preds_TARGET_mean.1', 'buro_preds_TARGET_mean', 'prapp_preds_TARGET_median.1', 'EXT_SOURCE_3', ...]\n",
      "\t\t('int', [])   :  17 | ['DAYS_BIRTH', 'OCCUPATION_TYPE', 'NAME_INCOME_TYPE', 'ORGANIZATION_TYPE', 'REGION_RATING_CLIENT_W_CITY', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 292 | ['nn_oof_single_past', 'prapp_preds_TARGET_mean.1', 'buro_preds_TARGET_mean', 'prapp_preds_TARGET_median.1', 'EXT_SOURCE_3', ...]\n",
      "\t\t('int', [])       :  12 | ['DAYS_BIRTH', 'OCCUPATION_TYPE', 'NAME_INCOME_TYPE', 'ORGANIZATION_TYPE', 'REGION_RATING_CLIENT_W_CITY', ...]\n",
      "\t\t('int', ['bool']) :   5 | ['CODE_GENDER', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_3', 'REG_CITY_NOT_LIVE_CITY']\n",
      "\t10.7s = Fit runtime\n",
      "\t309 features in original data used to generate 309 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 714.68 MB (3.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.78s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1761.58s of the 2643.01s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.99% memory usage per fold, 49.98%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=24.99%)\n",
      "\t0.7971\t = Validation score   (roc_auc)\n",
      "\t1176.12s\t = Training   runtime\n",
      "\t18.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 571.29s of the 1452.73s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.98% memory usage per fold, 49.96%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=24.98%)\n",
      "\t0.7947\t = Validation score   (roc_auc)\n",
      "\t482.81s\t = Training   runtime\n",
      "\t7.15s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 76.48s of the 957.92s of remaining time.\n",
      "\tWarning: Model is expected to require 897.6s to train, which exceeds the maximum time limit of 70.9s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 56.45s of the 937.88s of remaining time.\n",
      "\tWarning: Model is expected to require 803.8s to train, which exceeds the maximum time limit of 51.3s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 38.47s of the 919.91s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 28.88% memory usage per fold, 57.76%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=28.88%)\n",
      "\t0.66\t = Validation score   (roc_auc)\n",
      "\t64.9s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 845.02s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.682, 'LightGBM_BAG_L1': 0.318}\n",
      "\t0.7977\t = Validation score   (roc_auc)\n",
      "\t5.76s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 839.15s of the 838.89s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 26.75% memory usage per fold, 53.50%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=26.75%)\n",
      "\t0.7972\t = Validation score   (roc_auc)\n",
      "\t430.01s\t = Training   runtime\n",
      "\t4.64s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 398.80s of the 398.53s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 26.76% memory usage per fold, 53.52%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=26.76%)\n",
      "\t0.7971\t = Validation score   (roc_auc)\n",
      "\t324.04s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 64.14s of the 63.88s of remaining time.\n",
      "\tWarning: Model is expected to require 962.0s to train, which exceeds the maximum time limit of 58.8s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 43.72s of the 43.45s of remaining time.\n",
      "\tWarning: Model is expected to require 840.1s to train, which exceeds the maximum time limit of 38.5s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L2.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 25.12s of the 24.86s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.25% memory usage per fold, 60.51%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=2, gpus=0, memory=30.25%)\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 9.39s of remaining time.\n",
      "2025-10-15 17:50:56,207\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.357, 'LightGBMXT_BAG_L2': 0.286, 'LightGBM_BAG_L2': 0.214, 'LightGBM_BAG_L1': 0.143}\n",
      "\t0.7979\t = Validation score   (roc_auc)\n",
      "\t9.65s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2656.65s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1187.9 rows/s (38439 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/AutogluonModels/ag-20251015_165057\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor,TabularDataset\n",
    "train_Dataset=TabularDataset(train_data)\n",
    "test_Dataset=TabularDataset(test_data)\n",
    "predictor = TabularPredictor(label='TARGET',problem_type='binary',eval_metric='roc_auc').fit(train_Dataset,presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e90e2f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:51:01.520568Z",
     "iopub.status.busy": "2025-10-15T17:51:01.519076Z",
     "iopub.status.idle": "2025-10-15T17:51:32.329680Z",
     "shell.execute_reply": "2025-10-15T17:51:32.328320Z"
    },
    "papermill": {
     "duration": 30.898014,
     "end_time": "2025-10-15T17:51:32.331591",
     "exception": false,
     "start_time": "2025-10-15T17:51:01.433577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = predictor.predict_proba(test_Dataset)\n",
    "y_pred = y_pred.drop(y_pred.columns[0], axis=1)\n",
    "y_pred.index=test_id\n",
    "y_pred = y_pred.rename(columns={y_pred.columns[0]: 'TARGET'})\n",
    "y_pred.to_csv('submission2.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 860599,
     "sourceId": 9120,
     "sourceType": "competition"
    },
    {
     "datasetId": 8482786,
     "sourceId": 13371164,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9687.28224,
   "end_time": "2025-10-15T17:51:38.150269",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-15T15:10:10.868029",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
